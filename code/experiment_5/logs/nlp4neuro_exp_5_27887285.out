Using device: cuda

========== Processing Fish 9 ==========
Fish 9: Neural data shape: (3047, 12499)

--- Fish 9: Run 1 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=367.0371, Val Loss=1.7638
Epoch [2/5]: Train Loss=28.2005, Val Loss=1.4757
Epoch [3/5]: Train Loss=17.5517, Val Loss=1.4719
Epoch [4/5]: Train Loss=12.5957, Val Loss=1.4607
Epoch [5/5]: Train Loss=10.4011, Val Loss=1.4349
GPT2 Test CPC Loss: 1.4377
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7096, Val Loss=0.0814
Epoch [2/5]: Train Loss=0.0172, Val Loss=0.0055
Epoch [3/5]: Train Loss=0.0014, Val Loss=0.0021
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0012
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0008
LSTM Test CPC Loss: 0.0019
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.4057, Val Loss=4.4426
Epoch [2/5]: Train Loss=2.4154, Val Loss=2.6707
Epoch [3/5]: Train Loss=1.3620, Val Loss=1.9146
Epoch [4/5]: Train Loss=0.8619, Val Loss=1.5236
Epoch [5/5]: Train Loss=0.5675, Val Loss=1.3137
Reservoir Test CPC Loss: 1.2377
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.2060, Val Loss=1.5417
Epoch [2/5]: Train Loss=4.6805, Val Loss=1.5368
Epoch [3/5]: Train Loss=3.5232, Val Loss=1.5345
Epoch [4/5]: Train Loss=2.5112, Val Loss=1.5258
Epoch [5/5]: Train Loss=1.9695, Val Loss=1.5212
BERT Test CPC Loss: 1.5210

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=265.6557, Val Loss=2.8300
Epoch [2/5]: Train Loss=21.3619, Val Loss=3.3824
Epoch [3/5]: Train Loss=14.7136, Val Loss=3.3856
Epoch [4/5]: Train Loss=11.3442, Val Loss=2.8256
Epoch [5/5]: Train Loss=8.9793, Val Loss=2.8215
GPT2 Test CPC Loss: 2.8108
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4185, Val Loss=0.6458
Epoch [2/5]: Train Loss=0.3206, Val Loss=0.1404
Epoch [3/5]: Train Loss=0.0430, Val Loss=0.0486
Epoch [4/5]: Train Loss=0.0085, Val Loss=0.0299
Epoch [5/5]: Train Loss=0.0029, Val Loss=0.0282
LSTM Test CPC Loss: 0.0277
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.3904, Val Loss=10.7354
Epoch [2/5]: Train Loss=6.7442, Val Loss=6.8919
Epoch [3/5]: Train Loss=4.0074, Val Loss=5.0058
Epoch [4/5]: Train Loss=2.5642, Val Loss=3.8462
Epoch [5/5]: Train Loss=1.7284, Val Loss=3.1475
Reservoir Test CPC Loss: 2.8405
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0418, Val Loss=2.2856
Epoch [2/5]: Train Loss=4.4847, Val Loss=2.2874
Epoch [3/5]: Train Loss=3.5083, Val Loss=2.2881
Epoch [4/5]: Train Loss=2.8574, Val Loss=2.2901
Epoch [5/5]: Train Loss=2.5606, Val Loss=2.2903
BERT Test CPC Loss: 2.2902

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=301.4777, Val Loss=4.0149
Epoch [2/5]: Train Loss=20.6227, Val Loss=3.5207
Epoch [3/5]: Train Loss=15.3078, Val Loss=3.2412
Epoch [4/5]: Train Loss=12.3909, Val Loss=3.0999
Epoch [5/5]: Train Loss=10.2658, Val Loss=3.0984
GPT2 Test CPC Loss: 3.1043
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4658, Val Loss=0.7872
Epoch [2/5]: Train Loss=0.4404, Val Loss=0.2857
Epoch [3/5]: Train Loss=0.0873, Val Loss=0.1323
Epoch [4/5]: Train Loss=0.0170, Val Loss=0.0539
Epoch [5/5]: Train Loss=0.0057, Val Loss=0.0516
LSTM Test CPC Loss: 0.0695
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.0637, Val Loss=11.2155
Epoch [2/5]: Train Loss=8.1419, Val Loss=7.4503
Epoch [3/5]: Train Loss=4.9426, Val Loss=5.2389
Epoch [4/5]: Train Loss=3.1615, Val Loss=3.9092
Epoch [5/5]: Train Loss=2.1373, Val Loss=3.1061
Reservoir Test CPC Loss: 3.3167
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.9055, Val Loss=2.7000
Epoch [2/5]: Train Loss=4.5189, Val Loss=2.7008
Epoch [3/5]: Train Loss=3.6502, Val Loss=2.7021
Epoch [4/5]: Train Loss=3.1522, Val Loss=2.7029
Epoch [5/5]: Train Loss=2.9283, Val Loss=2.7039
BERT Test CPC Loss: 2.7040

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=557.5388, Val Loss=3.3239
Epoch [2/5]: Train Loss=42.8939, Val Loss=2.9690
Epoch [3/5]: Train Loss=27.7903, Val Loss=2.9504
Epoch [4/5]: Train Loss=20.8854, Val Loss=2.9512
Epoch [5/5]: Train Loss=16.8919, Val Loss=2.9490
GPT2 Test CPC Loss: 2.9440
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8981, Val Loss=1.3028
Epoch [2/5]: Train Loss=0.8331, Val Loss=0.7965
Epoch [3/5]: Train Loss=0.3331, Val Loss=0.5341
Epoch [4/5]: Train Loss=0.1221, Val Loss=0.1431
Epoch [5/5]: Train Loss=0.0229, Val Loss=0.0728
LSTM Test CPC Loss: 0.0740
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.0430, Val Loss=14.1786
Epoch [2/5]: Train Loss=9.3269, Val Loss=9.3975
Epoch [3/5]: Train Loss=5.7361, Val Loss=6.6562
Epoch [4/5]: Train Loss=3.7384, Val Loss=5.1152
Epoch [5/5]: Train Loss=2.5026, Val Loss=4.0742
Reservoir Test CPC Loss: 3.8707
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.6725, Val Loss=2.9932
Epoch [2/5]: Train Loss=4.4532, Val Loss=2.9937
Epoch [3/5]: Train Loss=3.6936, Val Loss=2.9937
Epoch [4/5]: Train Loss=3.3051, Val Loss=2.9938
Epoch [5/5]: Train Loss=3.1522, Val Loss=2.9942
BERT Test CPC Loss: 2.9942

--- Fish 9: Run 2 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=314.4896, Val Loss=1.5295
Epoch [2/5]: Train Loss=22.4684, Val Loss=1.4501
Epoch [3/5]: Train Loss=13.3938, Val Loss=1.4275
Epoch [4/5]: Train Loss=10.0672, Val Loss=1.4175
Epoch [5/5]: Train Loss=8.0803, Val Loss=1.4147
GPT2 Test CPC Loss: 1.4162
[Model: LSTM]
Epoch [1/5]: Train Loss=0.4978, Val Loss=0.0433
Epoch [2/5]: Train Loss=0.0089, Val Loss=0.0032
Epoch [3/5]: Train Loss=0.0010, Val Loss=0.0016
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0010
Epoch [5/5]: Train Loss=0.0002, Val Loss=0.0006
LSTM Test CPC Loss: 0.0009
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.2789, Val Loss=3.2876
Epoch [2/5]: Train Loss=2.3467, Val Loss=2.0450
Epoch [3/5]: Train Loss=1.3054, Val Loss=1.5224
Epoch [4/5]: Train Loss=0.8086, Val Loss=1.2014
Epoch [5/5]: Train Loss=0.5232, Val Loss=1.0410
Reservoir Test CPC Loss: 0.9833
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0737, Val Loss=1.5381
Epoch [2/5]: Train Loss=4.6959, Val Loss=1.5345
Epoch [3/5]: Train Loss=3.6289, Val Loss=1.5349
Epoch [4/5]: Train Loss=2.7156, Val Loss=1.5302
Epoch [5/5]: Train Loss=2.1000, Val Loss=1.5262
BERT Test CPC Loss: 1.5258

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=423.2050, Val Loss=2.4350
Epoch [2/5]: Train Loss=29.2916, Val Loss=2.2785
Epoch [3/5]: Train Loss=19.7431, Val Loss=2.2473
Epoch [4/5]: Train Loss=15.1529, Val Loss=2.2367
Epoch [5/5]: Train Loss=12.1854, Val Loss=2.2393
GPT2 Test CPC Loss: 2.2424
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6030, Val Loss=0.7839
Epoch [2/5]: Train Loss=0.4112, Val Loss=0.2014
Epoch [3/5]: Train Loss=0.0682, Val Loss=0.0479
Epoch [4/5]: Train Loss=0.0123, Val Loss=0.0224
Epoch [5/5]: Train Loss=0.0040, Val Loss=0.0132
LSTM Test CPC Loss: 0.0495
[Model: Reservoir]
Epoch [1/5]: Train Loss=14.0364, Val Loss=9.2288
Epoch [2/5]: Train Loss=6.5292, Val Loss=6.0890
Epoch [3/5]: Train Loss=4.0613, Val Loss=4.4756
Epoch [4/5]: Train Loss=2.6621, Val Loss=3.4713
Epoch [5/5]: Train Loss=1.8161, Val Loss=2.8252
Reservoir Test CPC Loss: 2.6573
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.9064, Val Loss=2.2870
Epoch [2/5]: Train Loss=4.5687, Val Loss=2.2901
Epoch [3/5]: Train Loss=3.5549, Val Loss=2.2919
Epoch [4/5]: Train Loss=2.8302, Val Loss=2.2925
Epoch [5/5]: Train Loss=2.5215, Val Loss=2.2943
BERT Test CPC Loss: 2.2942

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=826.6766, Val Loss=3.2799
Epoch [2/5]: Train Loss=47.4383, Val Loss=2.6361
Epoch [3/5]: Train Loss=29.7719, Val Loss=2.6464
Epoch [4/5]: Train Loss=21.2513, Val Loss=2.6588
Epoch [5/5]: Train Loss=16.6310, Val Loss=2.6724
GPT2 Test CPC Loss: 2.6701
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6969, Val Loss=1.0177
Epoch [2/5]: Train Loss=0.6316, Val Loss=0.4764
Epoch [3/5]: Train Loss=0.1901, Val Loss=0.1958
Epoch [4/5]: Train Loss=0.0375, Val Loss=0.0718
Epoch [5/5]: Train Loss=0.0096, Val Loss=0.0410
LSTM Test CPC Loss: 0.0693
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.1977, Val Loss=12.7055
Epoch [2/5]: Train Loss=8.8781, Val Loss=7.9270
Epoch [3/5]: Train Loss=5.2704, Val Loss=5.6244
Epoch [4/5]: Train Loss=3.2958, Val Loss=4.1589
Epoch [5/5]: Train Loss=2.1859, Val Loss=3.3129
Reservoir Test CPC Loss: 3.3872
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.4327, Val Loss=2.7042
Epoch [2/5]: Train Loss=4.3558, Val Loss=2.7048
Epoch [3/5]: Train Loss=3.5204, Val Loss=2.7046
Epoch [4/5]: Train Loss=3.0483, Val Loss=2.7051
Epoch [5/5]: Train Loss=2.8625, Val Loss=2.7054
BERT Test CPC Loss: 2.7054

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=413.9259, Val Loss=3.1634
Epoch [2/5]: Train Loss=17.5016, Val Loss=2.9958
Epoch [3/5]: Train Loss=12.8536, Val Loss=2.9520
Epoch [4/5]: Train Loss=10.4871, Val Loss=2.9580
Epoch [5/5]: Train Loss=8.9714, Val Loss=2.9505
GPT2 Test CPC Loss: 2.9493
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0795, Val Loss=1.6200
Epoch [2/5]: Train Loss=0.9916, Val Loss=1.0469
Epoch [3/5]: Train Loss=0.3732, Val Loss=0.3231
Epoch [4/5]: Train Loss=0.0656, Val Loss=0.1108
Epoch [5/5]: Train Loss=0.0136, Val Loss=0.0603
LSTM Test CPC Loss: 0.0977
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.2633, Val Loss=12.4780
Epoch [2/5]: Train Loss=8.8263, Val Loss=8.8457
Epoch [3/5]: Train Loss=5.7798, Val Loss=6.7301
Epoch [4/5]: Train Loss=3.9378, Val Loss=5.3480
Epoch [5/5]: Train Loss=2.7449, Val Loss=4.4129
Reservoir Test CPC Loss: 4.1308
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7926, Val Loss=2.9917
Epoch [2/5]: Train Loss=4.5272, Val Loss=2.9924
Epoch [3/5]: Train Loss=3.7624, Val Loss=2.9928
Epoch [4/5]: Train Loss=3.3602, Val Loss=2.9932
Epoch [5/5]: Train Loss=3.1829, Val Loss=2.9934
BERT Test CPC Loss: 2.9934

--- Fish 9: Run 3 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=274.8964, Val Loss=1.5202
Epoch [2/5]: Train Loss=22.2437, Val Loss=1.4421
Epoch [3/5]: Train Loss=14.5801, Val Loss=1.4405
Epoch [4/5]: Train Loss=10.6931, Val Loss=1.4419
Epoch [5/5]: Train Loss=8.3642, Val Loss=1.4207
GPT2 Test CPC Loss: 1.4231
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7130, Val Loss=0.0803
Epoch [2/5]: Train Loss=0.0187, Val Loss=0.0055
Epoch [3/5]: Train Loss=0.0015, Val Loss=0.0020
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0012
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0009
LSTM Test CPC Loss: 0.0018
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.2380, Val Loss=5.7477
Epoch [2/5]: Train Loss=3.3516, Val Loss=3.5357
Epoch [3/5]: Train Loss=1.8919, Val Loss=2.6286
Epoch [4/5]: Train Loss=1.1960, Val Loss=2.1415
Epoch [5/5]: Train Loss=0.8130, Val Loss=1.7751
Reservoir Test CPC Loss: 1.6443
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.1443, Val Loss=1.5338
Epoch [2/5]: Train Loss=4.7184, Val Loss=1.5337
Epoch [3/5]: Train Loss=3.6646, Val Loss=1.5303
Epoch [4/5]: Train Loss=2.7041, Val Loss=1.5255
Epoch [5/5]: Train Loss=2.0822, Val Loss=1.5220
BERT Test CPC Loss: 1.5219

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=364.8220, Val Loss=2.3310
Epoch [2/5]: Train Loss=25.3674, Val Loss=2.2191
Epoch [3/5]: Train Loss=15.7342, Val Loss=2.2088
Epoch [4/5]: Train Loss=11.7871, Val Loss=2.2085
Epoch [5/5]: Train Loss=9.5438, Val Loss=2.2087
GPT2 Test CPC Loss: 2.2085
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2586, Val Loss=0.4771
Epoch [2/5]: Train Loss=0.1838, Val Loss=0.1245
Epoch [3/5]: Train Loss=0.0182, Val Loss=0.0833
Epoch [4/5]: Train Loss=0.0044, Val Loss=0.0316
Epoch [5/5]: Train Loss=0.0018, Val Loss=0.0273
LSTM Test CPC Loss: 0.0423
[Model: Reservoir]
Epoch [1/5]: Train Loss=13.8659, Val Loss=8.9277
Epoch [2/5]: Train Loss=6.4693, Val Loss=6.1397
Epoch [3/5]: Train Loss=4.0808, Val Loss=4.5236
Epoch [4/5]: Train Loss=2.7164, Val Loss=3.5822
Epoch [5/5]: Train Loss=1.8752, Val Loss=2.8895
Reservoir Test CPC Loss: 2.9656
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7834, Val Loss=2.2871
Epoch [2/5]: Train Loss=4.4525, Val Loss=2.2900
Epoch [3/5]: Train Loss=3.3838, Val Loss=2.2918
Epoch [4/5]: Train Loss=2.6959, Val Loss=2.2938
Epoch [5/5]: Train Loss=2.4734, Val Loss=2.2950
BERT Test CPC Loss: 2.2949

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=315.3376, Val Loss=2.6760
Epoch [2/5]: Train Loss=21.4493, Val Loss=2.6516
Epoch [3/5]: Train Loss=13.4716, Val Loss=2.6507
Epoch [4/5]: Train Loss=10.0533, Val Loss=2.6536
Epoch [5/5]: Train Loss=8.1175, Val Loss=2.6546
GPT2 Test CPC Loss: 2.6534
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6998, Val Loss=1.1342
Epoch [2/5]: Train Loss=0.6012, Val Loss=0.4452
Epoch [3/5]: Train Loss=0.1668, Val Loss=0.1598
Epoch [4/5]: Train Loss=0.0263, Val Loss=0.0588
Epoch [5/5]: Train Loss=0.0071, Val Loss=0.0423
LSTM Test CPC Loss: 0.0627
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.0231, Val Loss=11.9782
Epoch [2/5]: Train Loss=8.6598, Val Loss=7.5553
Epoch [3/5]: Train Loss=5.1880, Val Loss=5.3252
Epoch [4/5]: Train Loss=3.2987, Val Loss=4.1092
Epoch [5/5]: Train Loss=2.2186, Val Loss=3.2649
Reservoir Test CPC Loss: 3.3614
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0907, Val Loss=2.7000
Epoch [2/5]: Train Loss=4.5887, Val Loss=2.7022
Epoch [3/5]: Train Loss=3.7268, Val Loss=2.7030
Epoch [4/5]: Train Loss=3.1930, Val Loss=2.7036
Epoch [5/5]: Train Loss=2.9279, Val Loss=2.7041
BERT Test CPC Loss: 2.7042

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=614.4723, Val Loss=3.6097
Epoch [2/5]: Train Loss=50.2426, Val Loss=3.6264
Epoch [3/5]: Train Loss=31.3561, Val Loss=3.1865
Epoch [4/5]: Train Loss=23.3650, Val Loss=3.0444
Epoch [5/5]: Train Loss=18.9911, Val Loss=2.9992
GPT2 Test CPC Loss: 2.9953
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1834, Val Loss=1.4799
Epoch [2/5]: Train Loss=1.0536, Val Loss=1.0227
Epoch [3/5]: Train Loss=0.5440, Val Loss=0.5244
Epoch [4/5]: Train Loss=0.2044, Val Loss=0.2214
Epoch [5/5]: Train Loss=0.0592, Val Loss=0.1451
LSTM Test CPC Loss: 0.1796
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.1985, Val Loss=12.9369
Epoch [2/5]: Train Loss=8.1376, Val Loss=8.5064
Epoch [3/5]: Train Loss=4.9747, Val Loss=6.0239
Epoch [4/5]: Train Loss=3.1953, Val Loss=4.4885
Epoch [5/5]: Train Loss=2.1684, Val Loss=3.5139
Reservoir Test CPC Loss: 3.5470
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.6216, Val Loss=2.9917
Epoch [2/5]: Train Loss=4.4553, Val Loss=2.9931
Epoch [3/5]: Train Loss=3.6474, Val Loss=2.9935
Epoch [4/5]: Train Loss=3.2403, Val Loss=2.9939
Epoch [5/5]: Train Loss=3.1100, Val Loss=2.9942
BERT Test CPC Loss: 2.9942

--- Fish 9: Run 4 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=338.2322, Val Loss=6.3182
Epoch [2/5]: Train Loss=24.7809, Val Loss=3.1771
Epoch [3/5]: Train Loss=15.4605, Val Loss=2.7665
Epoch [4/5]: Train Loss=11.2194, Val Loss=2.1931
Epoch [5/5]: Train Loss=8.4345, Val Loss=1.8506
GPT2 Test CPC Loss: 1.9161
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6986, Val Loss=0.0771
Epoch [2/5]: Train Loss=0.0131, Val Loss=0.0052
Epoch [3/5]: Train Loss=0.0012, Val Loss=0.0028
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0017
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0013
LSTM Test CPC Loss: 0.0051
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.1212, Val Loss=3.9059
Epoch [2/5]: Train Loss=2.5698, Val Loss=2.1121
Epoch [3/5]: Train Loss=1.3793, Val Loss=1.5006
Epoch [4/5]: Train Loss=0.8243, Val Loss=1.1364
Epoch [5/5]: Train Loss=0.5273, Val Loss=0.9991
Reservoir Test CPC Loss: 1.0183
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4977, Val Loss=1.5367
Epoch [2/5]: Train Loss=4.7754, Val Loss=1.5388
Epoch [3/5]: Train Loss=3.7019, Val Loss=1.5322
Epoch [4/5]: Train Loss=2.8324, Val Loss=1.5277
Epoch [5/5]: Train Loss=2.1379, Val Loss=1.5193
BERT Test CPC Loss: 1.5190

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=267.3851, Val Loss=2.5253
Epoch [2/5]: Train Loss=19.1052, Val Loss=2.3317
Epoch [3/5]: Train Loss=13.4529, Val Loss=2.2817
Epoch [4/5]: Train Loss=10.7942, Val Loss=2.2710
Epoch [5/5]: Train Loss=8.9425, Val Loss=2.2593
GPT2 Test CPC Loss: 2.2607
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1953, Val Loss=0.4359
Epoch [2/5]: Train Loss=0.1545, Val Loss=0.0986
Epoch [3/5]: Train Loss=0.0137, Val Loss=0.0539
Epoch [4/5]: Train Loss=0.0033, Val Loss=0.0274
Epoch [5/5]: Train Loss=0.0014, Val Loss=0.0272
LSTM Test CPC Loss: 0.0135
[Model: Reservoir]
Epoch [1/5]: Train Loss=12.5081, Val Loss=8.1466
Epoch [2/5]: Train Loss=5.8221, Val Loss=5.4899
Epoch [3/5]: Train Loss=3.5805, Val Loss=4.0066
Epoch [4/5]: Train Loss=2.3386, Val Loss=3.1604
Epoch [5/5]: Train Loss=1.5892, Val Loss=2.5633
Reservoir Test CPC Loss: 2.2142
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.9335, Val Loss=2.2914
Epoch [2/5]: Train Loss=4.4486, Val Loss=2.2941
Epoch [3/5]: Train Loss=3.4480, Val Loss=2.2954
Epoch [4/5]: Train Loss=2.7733, Val Loss=2.2962
Epoch [5/5]: Train Loss=2.4950, Val Loss=2.2973
BERT Test CPC Loss: 2.2973

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=308.4501, Val Loss=2.7788
Epoch [2/5]: Train Loss=20.3031, Val Loss=2.6634
Epoch [3/5]: Train Loss=14.8549, Val Loss=2.7152
Epoch [4/5]: Train Loss=11.8667, Val Loss=2.6570
Epoch [5/5]: Train Loss=9.9781, Val Loss=2.6888
GPT2 Test CPC Loss: 2.6877
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6215, Val Loss=0.9159
Epoch [2/5]: Train Loss=0.4172, Val Loss=0.2959
Epoch [3/5]: Train Loss=0.0691, Val Loss=0.1429
Epoch [4/5]: Train Loss=0.0112, Val Loss=0.0674
Epoch [5/5]: Train Loss=0.0037, Val Loss=0.0575
LSTM Test CPC Loss: 0.0654
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.6653, Val Loss=11.4026
Epoch [2/5]: Train Loss=7.7361, Val Loss=7.1916
Epoch [3/5]: Train Loss=4.4833, Val Loss=4.9792
Epoch [4/5]: Train Loss=2.7955, Val Loss=3.7771
Epoch [5/5]: Train Loss=1.8474, Val Loss=2.9382
Reservoir Test CPC Loss: 3.0717
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.8073, Val Loss=2.7027
Epoch [2/5]: Train Loss=4.4372, Val Loss=2.7033
Epoch [3/5]: Train Loss=3.4732, Val Loss=2.7040
Epoch [4/5]: Train Loss=2.9653, Val Loss=2.7048
Epoch [5/5]: Train Loss=2.8264, Val Loss=2.7051
BERT Test CPC Loss: 2.7051

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=326.6789, Val Loss=4.1994
Epoch [2/5]: Train Loss=26.7898, Val Loss=3.2365
Epoch [3/5]: Train Loss=17.3511, Val Loss=3.0280
Epoch [4/5]: Train Loss=12.9607, Val Loss=2.9553
Epoch [5/5]: Train Loss=10.4600, Val Loss=2.9426
GPT2 Test CPC Loss: 2.9456
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7374, Val Loss=1.2039
Epoch [2/5]: Train Loss=0.6574, Val Loss=0.6665
Epoch [3/5]: Train Loss=0.2114, Val Loss=0.2296
Epoch [4/5]: Train Loss=0.0652, Val Loss=0.0669
Epoch [5/5]: Train Loss=0.0107, Val Loss=0.0534
LSTM Test CPC Loss: 0.0744
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.8496, Val Loss=14.5741
Epoch [2/5]: Train Loss=9.5261, Val Loss=9.3951
Epoch [3/5]: Train Loss=5.5264, Val Loss=6.6387
Epoch [4/5]: Train Loss=3.4312, Val Loss=4.9100
Epoch [5/5]: Train Loss=2.2481, Val Loss=3.8762
Reservoir Test CPC Loss: 3.4739
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0023, Val Loss=2.9914
Epoch [2/5]: Train Loss=4.5645, Val Loss=2.9919
Epoch [3/5]: Train Loss=3.8019, Val Loss=2.9924
Epoch [4/5]: Train Loss=3.3851, Val Loss=2.9927
Epoch [5/5]: Train Loss=3.1923, Val Loss=2.9931
BERT Test CPC Loss: 2.9931

--- Fish 9: Run 5 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=401.7029, Val Loss=1.8139
Epoch [2/5]: Train Loss=31.7967, Val Loss=1.6588
Epoch [3/5]: Train Loss=21.7412, Val Loss=1.6866
Epoch [4/5]: Train Loss=16.4886, Val Loss=1.6491
Epoch [5/5]: Train Loss=13.4152, Val Loss=1.6116
GPT2 Test CPC Loss: 1.6328
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6546, Val Loss=0.0995
Epoch [2/5]: Train Loss=0.0166, Val Loss=0.0055
Epoch [3/5]: Train Loss=0.0013, Val Loss=0.0024
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0018
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0012
LSTM Test CPC Loss: 0.0020
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.0581, Val Loss=4.8931
Epoch [2/5]: Train Loss=2.5177, Val Loss=2.9343
Epoch [3/5]: Train Loss=1.4048, Val Loss=2.1569
Epoch [4/5]: Train Loss=0.8660, Val Loss=1.6790
Epoch [5/5]: Train Loss=0.5552, Val Loss=1.4120
Reservoir Test CPC Loss: 1.1060
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.1871, Val Loss=1.5269
Epoch [2/5]: Train Loss=4.7192, Val Loss=1.5261
Epoch [3/5]: Train Loss=3.6163, Val Loss=1.5207
Epoch [4/5]: Train Loss=2.6582, Val Loss=1.5147
Epoch [5/5]: Train Loss=2.0786, Val Loss=1.5078
BERT Test CPC Loss: 1.5075

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=498.3990, Val Loss=6.3605
Epoch [2/5]: Train Loss=41.4885, Val Loss=2.9556
Epoch [3/5]: Train Loss=25.2912, Val Loss=2.3461
Epoch [4/5]: Train Loss=18.2655, Val Loss=2.2265
Epoch [5/5]: Train Loss=14.6530, Val Loss=2.2298
GPT2 Test CPC Loss: 2.2334
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1722, Val Loss=0.4388
Epoch [2/5]: Train Loss=0.1694, Val Loss=0.0970
Epoch [3/5]: Train Loss=0.0220, Val Loss=0.0218
Epoch [4/5]: Train Loss=0.0036, Val Loss=0.0112
Epoch [5/5]: Train Loss=0.0017, Val Loss=0.0095
LSTM Test CPC Loss: 0.0281
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.4838, Val Loss=10.9191
Epoch [2/5]: Train Loss=7.2732, Val Loss=7.1771
Epoch [3/5]: Train Loss=4.5035, Val Loss=5.2680
Epoch [4/5]: Train Loss=2.9252, Val Loss=4.0264
Epoch [5/5]: Train Loss=1.9966, Val Loss=3.2316
Reservoir Test CPC Loss: 3.0076
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0720, Val Loss=2.2916
Epoch [2/5]: Train Loss=4.4299, Val Loss=2.2916
Epoch [3/5]: Train Loss=3.4046, Val Loss=2.2933
Epoch [4/5]: Train Loss=2.7477, Val Loss=2.2939
Epoch [5/5]: Train Loss=2.4978, Val Loss=2.2949
BERT Test CPC Loss: 2.2948

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=562.6621, Val Loss=2.7512
Epoch [2/5]: Train Loss=28.1577, Val Loss=2.7000
Epoch [3/5]: Train Loss=19.7203, Val Loss=2.6677
Epoch [4/5]: Train Loss=15.6345, Val Loss=2.6647
Epoch [5/5]: Train Loss=13.2066, Val Loss=2.6642
GPT2 Test CPC Loss: 2.6621
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9028, Val Loss=1.1035
Epoch [2/5]: Train Loss=0.7376, Val Loss=0.5897
Epoch [3/5]: Train Loss=0.2569, Val Loss=0.2746
Epoch [4/5]: Train Loss=0.0583, Val Loss=0.1463
Epoch [5/5]: Train Loss=0.0144, Val Loss=0.0911
LSTM Test CPC Loss: 0.0760
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.5756, Val Loss=11.5712
Epoch [2/5]: Train Loss=7.4251, Val Loss=7.6750
Epoch [3/5]: Train Loss=4.4798, Val Loss=5.4732
Epoch [4/5]: Train Loss=2.8805, Val Loss=4.2865
Epoch [5/5]: Train Loss=1.9385, Val Loss=3.4414
Reservoir Test CPC Loss: 3.0046
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.5717, Val Loss=2.7008
Epoch [2/5]: Train Loss=4.4115, Val Loss=2.7011
Epoch [3/5]: Train Loss=3.5918, Val Loss=2.7021
Epoch [4/5]: Train Loss=3.1412, Val Loss=2.7024
Epoch [5/5]: Train Loss=2.9237, Val Loss=2.7026
BERT Test CPC Loss: 2.7027

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=314.9061, Val Loss=2.9862
Epoch [2/5]: Train Loss=16.8118, Val Loss=2.9414
Epoch [3/5]: Train Loss=11.8474, Val Loss=2.9472
Epoch [4/5]: Train Loss=9.2335, Val Loss=2.9514
Epoch [5/5]: Train Loss=7.6706, Val Loss=2.9572
GPT2 Test CPC Loss: 2.9561
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7157, Val Loss=1.3410
Epoch [2/5]: Train Loss=0.6497, Val Loss=0.6486
Epoch [3/5]: Train Loss=0.1776, Val Loss=0.1857
Epoch [4/5]: Train Loss=0.0311, Val Loss=0.0879
Epoch [5/5]: Train Loss=0.0074, Val Loss=0.0671
LSTM Test CPC Loss: 0.0603
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.1774, Val Loss=13.6391
Epoch [2/5]: Train Loss=9.3298, Val Loss=8.7677
Epoch [3/5]: Train Loss=5.6509, Val Loss=6.2228
Epoch [4/5]: Train Loss=3.6348, Val Loss=4.5277
Epoch [5/5]: Train Loss=2.4693, Val Loss=3.5089
Reservoir Test CPC Loss: 3.4841
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0151, Val Loss=2.9901
Epoch [2/5]: Train Loss=4.5902, Val Loss=2.9916
Epoch [3/5]: Train Loss=3.8339, Val Loss=2.9923
Epoch [4/5]: Train Loss=3.4178, Val Loss=2.9927
Epoch [5/5]: Train Loss=3.2168, Val Loss=2.9930
BERT Test CPC Loss: 2.9929

--- Fish 9: Run 6 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=338.4726, Val Loss=14.4259
Epoch [2/5]: Train Loss=32.2106, Val Loss=2.4856
Epoch [3/5]: Train Loss=21.1336, Val Loss=1.4943
Epoch [4/5]: Train Loss=15.6791, Val Loss=1.4474
Epoch [5/5]: Train Loss=12.4099, Val Loss=1.4275
GPT2 Test CPC Loss: 1.4340
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5345, Val Loss=0.0395
Epoch [2/5]: Train Loss=0.0060, Val Loss=0.0042
Epoch [3/5]: Train Loss=0.0009, Val Loss=0.0021
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0018
Epoch [5/5]: Train Loss=0.0002, Val Loss=0.0014
LSTM Test CPC Loss: 0.0032
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.4881, Val Loss=5.0041
Epoch [2/5]: Train Loss=2.6311, Val Loss=3.1875
Epoch [3/5]: Train Loss=1.5418, Val Loss=2.4949
Epoch [4/5]: Train Loss=1.0036, Val Loss=2.0231
Epoch [5/5]: Train Loss=0.6798, Val Loss=1.8304
Reservoir Test CPC Loss: 1.6008
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5030, Val Loss=1.5201
Epoch [2/5]: Train Loss=4.7558, Val Loss=1.5227
Epoch [3/5]: Train Loss=3.7363, Val Loss=1.5341
Epoch [4/5]: Train Loss=2.9702, Val Loss=1.5367
Epoch [5/5]: Train Loss=2.4132, Val Loss=1.5009
BERT Test CPC Loss: 1.5020

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=332.5377, Val Loss=2.5567
Epoch [2/5]: Train Loss=29.5117, Val Loss=2.3956
Epoch [3/5]: Train Loss=20.0010, Val Loss=2.3738
Epoch [4/5]: Train Loss=14.7319, Val Loss=2.5324
Epoch [5/5]: Train Loss=11.6831, Val Loss=2.5770
GPT2 Test CPC Loss: 2.5682
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3536, Val Loss=0.6236
Epoch [2/5]: Train Loss=0.2666, Val Loss=0.1444
Epoch [3/5]: Train Loss=0.0382, Val Loss=0.0472
Epoch [4/5]: Train Loss=0.0064, Val Loss=0.0296
Epoch [5/5]: Train Loss=0.0026, Val Loss=0.0205
LSTM Test CPC Loss: 0.0329
[Model: Reservoir]
Epoch [1/5]: Train Loss=14.9447, Val Loss=9.4891
Epoch [2/5]: Train Loss=6.7256, Val Loss=6.0400
Epoch [3/5]: Train Loss=4.0862, Val Loss=4.3321
Epoch [4/5]: Train Loss=2.6471, Val Loss=3.3371
Epoch [5/5]: Train Loss=1.8136, Val Loss=2.6647
Reservoir Test CPC Loss: 2.5001
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.2874, Val Loss=2.2907
Epoch [2/5]: Train Loss=4.6081, Val Loss=2.2913
Epoch [3/5]: Train Loss=3.6068, Val Loss=2.2929
Epoch [4/5]: Train Loss=2.8910, Val Loss=2.2946
Epoch [5/5]: Train Loss=2.5287, Val Loss=2.2963
BERT Test CPC Loss: 2.2963

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=406.3528, Val Loss=6.1420
Epoch [2/5]: Train Loss=38.9057, Val Loss=3.3368
Epoch [3/5]: Train Loss=26.0328, Val Loss=2.7619
Epoch [4/5]: Train Loss=19.5640, Val Loss=2.6566
Epoch [5/5]: Train Loss=15.5504, Val Loss=2.6481
GPT2 Test CPC Loss: 2.6477
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6822, Val Loss=1.0541
Epoch [2/5]: Train Loss=0.5063, Val Loss=0.2992
Epoch [3/5]: Train Loss=0.1029, Val Loss=0.0772
Epoch [4/5]: Train Loss=0.0160, Val Loss=0.0411
Epoch [5/5]: Train Loss=0.0053, Val Loss=0.0250
LSTM Test CPC Loss: 0.0434
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.7923, Val Loss=12.9983
Epoch [2/5]: Train Loss=8.3378, Val Loss=8.1969
Epoch [3/5]: Train Loss=4.9803, Val Loss=5.4933
Epoch [4/5]: Train Loss=3.1181, Val Loss=3.9968
Epoch [5/5]: Train Loss=2.0549, Val Loss=3.0875
Reservoir Test CPC Loss: 3.2890
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.8495, Val Loss=2.7026
Epoch [2/5]: Train Loss=4.5253, Val Loss=2.7029
Epoch [3/5]: Train Loss=3.6664, Val Loss=2.7031
Epoch [4/5]: Train Loss=3.1777, Val Loss=2.7033
Epoch [5/5]: Train Loss=2.9484, Val Loss=2.7035
BERT Test CPC Loss: 2.7036

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=319.7308, Val Loss=3.0264
Epoch [2/5]: Train Loss=23.0492, Val Loss=2.9467
Epoch [3/5]: Train Loss=15.4998, Val Loss=2.9565
Epoch [4/5]: Train Loss=11.7889, Val Loss=2.9676
Epoch [5/5]: Train Loss=9.5306, Val Loss=2.9635
GPT2 Test CPC Loss: 2.9615
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9136, Val Loss=1.4829
Epoch [2/5]: Train Loss=0.8382, Val Loss=1.0488
Epoch [3/5]: Train Loss=0.3264, Val Loss=0.4341
Epoch [4/5]: Train Loss=0.0730, Val Loss=0.1450
Epoch [5/5]: Train Loss=0.0163, Val Loss=0.0653
LSTM Test CPC Loss: 0.0881
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.2887, Val Loss=12.6177
Epoch [2/5]: Train Loss=8.1180, Val Loss=8.5612
Epoch [3/5]: Train Loss=4.9112, Val Loss=6.1747
Epoch [4/5]: Train Loss=3.1692, Val Loss=4.6679
Epoch [5/5]: Train Loss=2.1137, Val Loss=3.6508
Reservoir Test CPC Loss: 3.6214
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.9124, Val Loss=2.9921
Epoch [2/5]: Train Loss=4.5978, Val Loss=2.9915
Epoch [3/5]: Train Loss=3.8376, Val Loss=2.9922
Epoch [4/5]: Train Loss=3.4012, Val Loss=2.9927
Epoch [5/5]: Train Loss=3.1991, Val Loss=2.9931
BERT Test CPC Loss: 2.9932

--- Fish 9: Run 7 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=282.0075, Val Loss=1.7024
Epoch [2/5]: Train Loss=22.8407, Val Loss=1.5951
Epoch [3/5]: Train Loss=14.2647, Val Loss=1.5096
Epoch [4/5]: Train Loss=10.7404, Val Loss=1.4797
Epoch [5/5]: Train Loss=8.6480, Val Loss=1.4606
GPT2 Test CPC Loss: 1.4608
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7540, Val Loss=0.1146
Epoch [2/5]: Train Loss=0.0279, Val Loss=0.0081
Epoch [3/5]: Train Loss=0.0023, Val Loss=0.0035
Epoch [4/5]: Train Loss=0.0009, Val Loss=0.0021
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0014
LSTM Test CPC Loss: 0.0119
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.9485, Val Loss=3.5985
Epoch [2/5]: Train Loss=2.6633, Val Loss=2.2363
Epoch [3/5]: Train Loss=1.4901, Val Loss=1.6259
Epoch [4/5]: Train Loss=0.9056, Val Loss=1.2880
Epoch [5/5]: Train Loss=0.5829, Val Loss=1.1066
Reservoir Test CPC Loss: 1.2006
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5345, Val Loss=1.5305
Epoch [2/5]: Train Loss=4.7727, Val Loss=1.5295
Epoch [3/5]: Train Loss=3.6907, Val Loss=1.5270
Epoch [4/5]: Train Loss=2.8115, Val Loss=1.5202
Epoch [5/5]: Train Loss=2.2296, Val Loss=1.5167
BERT Test CPC Loss: 1.5165

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=400.6039, Val Loss=5.0155
Epoch [2/5]: Train Loss=26.3133, Val Loss=3.4367
Epoch [3/5]: Train Loss=17.4448, Val Loss=3.1651
Epoch [4/5]: Train Loss=13.4370, Val Loss=2.9608
Epoch [5/5]: Train Loss=11.0975, Val Loss=2.9084
GPT2 Test CPC Loss: 2.9111
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3959, Val Loss=0.6916
Epoch [2/5]: Train Loss=0.2943, Val Loss=0.1584
Epoch [3/5]: Train Loss=0.0461, Val Loss=0.0464
Epoch [4/5]: Train Loss=0.0076, Val Loss=0.0286
Epoch [5/5]: Train Loss=0.0025, Val Loss=0.0204
LSTM Test CPC Loss: 0.0341
[Model: Reservoir]
Epoch [1/5]: Train Loss=13.2232, Val Loss=8.9097
Epoch [2/5]: Train Loss=6.0112, Val Loss=6.0083
Epoch [3/5]: Train Loss=3.7820, Val Loss=4.3583
Epoch [4/5]: Train Loss=2.5134, Val Loss=3.3680
Epoch [5/5]: Train Loss=1.7478, Val Loss=2.6730
Reservoir Test CPC Loss: 2.6486
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0960, Val Loss=2.2789
Epoch [2/5]: Train Loss=4.4471, Val Loss=2.2782
Epoch [3/5]: Train Loss=3.4678, Val Loss=2.2802
Epoch [4/5]: Train Loss=2.8276, Val Loss=2.2836
Epoch [5/5]: Train Loss=2.5404, Val Loss=2.2845
BERT Test CPC Loss: 2.2845

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=361.3307, Val Loss=4.3799
Epoch [2/5]: Train Loss=28.3260, Val Loss=2.8879
Epoch [3/5]: Train Loss=17.6435, Val Loss=2.7434
Epoch [4/5]: Train Loss=12.9006, Val Loss=2.7048
Epoch [5/5]: Train Loss=10.1524, Val Loss=2.6807
GPT2 Test CPC Loss: 2.6828
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5337, Val Loss=0.9528
Epoch [2/5]: Train Loss=0.4724, Val Loss=0.4549
Epoch [3/5]: Train Loss=0.1016, Val Loss=0.1621
Epoch [4/5]: Train Loss=0.0184, Val Loss=0.0745
Epoch [5/5]: Train Loss=0.0056, Val Loss=0.0538
LSTM Test CPC Loss: 0.0637
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.5159, Val Loss=12.7012
Epoch [2/5]: Train Loss=8.3900, Val Loss=7.9549
Epoch [3/5]: Train Loss=4.7439, Val Loss=5.4032
Epoch [4/5]: Train Loss=2.8842, Val Loss=3.9602
Epoch [5/5]: Train Loss=1.8557, Val Loss=3.0610
Reservoir Test CPC Loss: 3.0959
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.3117, Val Loss=2.7049
Epoch [2/5]: Train Loss=4.3646, Val Loss=2.7057
Epoch [3/5]: Train Loss=3.5255, Val Loss=2.7061
Epoch [4/5]: Train Loss=3.0460, Val Loss=2.7060
Epoch [5/5]: Train Loss=2.8516, Val Loss=2.7058
BERT Test CPC Loss: 2.7057

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=256.2900, Val Loss=2.8821
Epoch [2/5]: Train Loss=18.8044, Val Loss=2.9086
Epoch [3/5]: Train Loss=13.8451, Val Loss=2.9345
Epoch [4/5]: Train Loss=11.0259, Val Loss=2.9506
Epoch [5/5]: Train Loss=9.3288, Val Loss=2.9382
GPT2 Test CPC Loss: 2.9391
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8880, Val Loss=1.4240
Epoch [2/5]: Train Loss=0.8357, Val Loss=0.8301
Epoch [3/5]: Train Loss=0.2476, Val Loss=0.3930
Epoch [4/5]: Train Loss=0.0541, Val Loss=0.1370
Epoch [5/5]: Train Loss=0.0119, Val Loss=0.0777
LSTM Test CPC Loss: 0.0701
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.8422, Val Loss=11.9704
Epoch [2/5]: Train Loss=8.1410, Val Loss=8.3607
Epoch [3/5]: Train Loss=5.0087, Val Loss=6.1691
Epoch [4/5]: Train Loss=3.2346, Val Loss=4.9255
Epoch [5/5]: Train Loss=2.1857, Val Loss=4.0348
Reservoir Test CPC Loss: 4.0133
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.9527, Val Loss=2.9937
Epoch [2/5]: Train Loss=4.4927, Val Loss=2.9941
Epoch [3/5]: Train Loss=3.7136, Val Loss=2.9945
Epoch [4/5]: Train Loss=3.2867, Val Loss=2.9944
Epoch [5/5]: Train Loss=3.1261, Val Loss=2.9947
BERT Test CPC Loss: 2.9946

--- Fish 9: Run 8 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=568.0297, Val Loss=1.9785
Epoch [2/5]: Train Loss=36.2259, Val Loss=1.8539
Epoch [3/5]: Train Loss=23.3789, Val Loss=1.7136
Epoch [4/5]: Train Loss=17.3431, Val Loss=1.5407
Epoch [5/5]: Train Loss=13.8173, Val Loss=1.5479
GPT2 Test CPC Loss: 1.5762
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6875, Val Loss=0.0751
Epoch [2/5]: Train Loss=0.0154, Val Loss=0.0068
Epoch [3/5]: Train Loss=0.0014, Val Loss=0.0035
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0027
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0017
LSTM Test CPC Loss: 0.0035
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.8478, Val Loss=3.9438
Epoch [2/5]: Train Loss=2.8761, Val Loss=2.5783
Epoch [3/5]: Train Loss=1.7486, Val Loss=1.9983
Epoch [4/5]: Train Loss=1.1675, Val Loss=1.6407
Epoch [5/5]: Train Loss=0.8152, Val Loss=1.4125
Reservoir Test CPC Loss: 1.6025
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.3602, Val Loss=1.5150
Epoch [2/5]: Train Loss=4.6736, Val Loss=1.5093
Epoch [3/5]: Train Loss=3.6746, Val Loss=1.5000
Epoch [4/5]: Train Loss=2.8957, Val Loss=1.4997
Epoch [5/5]: Train Loss=2.3093, Val Loss=1.4845
BERT Test CPC Loss: 1.4850

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=411.6496, Val Loss=3.3268
Epoch [2/5]: Train Loss=35.9238, Val Loss=2.4343
Epoch [3/5]: Train Loss=23.0301, Val Loss=2.2858
Epoch [4/5]: Train Loss=16.9043, Val Loss=2.2428
Epoch [5/5]: Train Loss=13.4798, Val Loss=2.2310
GPT2 Test CPC Loss: 2.2330
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3353, Val Loss=0.5745
Epoch [2/5]: Train Loss=0.2482, Val Loss=0.1470
Epoch [3/5]: Train Loss=0.0337, Val Loss=0.0312
Epoch [4/5]: Train Loss=0.0062, Val Loss=0.0202
Epoch [5/5]: Train Loss=0.0024, Val Loss=0.0130
LSTM Test CPC Loss: 0.0269
[Model: Reservoir]
Epoch [1/5]: Train Loss=13.1903, Val Loss=8.3814
Epoch [2/5]: Train Loss=6.1214, Val Loss=6.0379
Epoch [3/5]: Train Loss=3.8341, Val Loss=4.5385
Epoch [4/5]: Train Loss=2.5318, Val Loss=3.4945
Epoch [5/5]: Train Loss=1.7358, Val Loss=2.8993
Reservoir Test CPC Loss: 2.6924
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.1112, Val Loss=2.2854
Epoch [2/5]: Train Loss=4.5682, Val Loss=2.2891
Epoch [3/5]: Train Loss=3.5925, Val Loss=2.2907
Epoch [4/5]: Train Loss=2.9298, Val Loss=2.2911
Epoch [5/5]: Train Loss=2.5991, Val Loss=2.2924
BERT Test CPC Loss: 2.2923

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=367.5940, Val Loss=2.7404
Epoch [2/5]: Train Loss=24.0193, Val Loss=2.6704
Epoch [3/5]: Train Loss=16.5263, Val Loss=2.6556
Epoch [4/5]: Train Loss=12.5751, Val Loss=2.6543
Epoch [5/5]: Train Loss=10.3063, Val Loss=2.6549
GPT2 Test CPC Loss: 2.6538
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4953, Val Loss=1.2265
Epoch [2/5]: Train Loss=0.4164, Val Loss=0.3637
Epoch [3/5]: Train Loss=0.0805, Val Loss=0.1680
Epoch [4/5]: Train Loss=0.0146, Val Loss=0.0689
Epoch [5/5]: Train Loss=0.0037, Val Loss=0.0625
LSTM Test CPC Loss: 0.0455
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.0522, Val Loss=11.4589
Epoch [2/5]: Train Loss=7.7351, Val Loss=7.2394
Epoch [3/5]: Train Loss=4.3815, Val Loss=4.9588
Epoch [4/5]: Train Loss=2.6659, Val Loss=3.6778
Epoch [5/5]: Train Loss=1.7232, Val Loss=2.8778
Reservoir Test CPC Loss: 2.4941
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.6591, Val Loss=2.7051
Epoch [2/5]: Train Loss=4.3713, Val Loss=2.7057
Epoch [3/5]: Train Loss=3.5020, Val Loss=2.7061
Epoch [4/5]: Train Loss=3.0228, Val Loss=2.7059
Epoch [5/5]: Train Loss=2.8475, Val Loss=2.7060
BERT Test CPC Loss: 2.7060

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=346.2459, Val Loss=4.0767
Epoch [2/5]: Train Loss=19.4271, Val Loss=3.6913
Epoch [3/5]: Train Loss=13.5669, Val Loss=2.9356
Epoch [4/5]: Train Loss=10.8096, Val Loss=2.9732
Epoch [5/5]: Train Loss=9.2012, Val Loss=2.9667
GPT2 Test CPC Loss: 2.9669
[Model: LSTM]
Epoch [1/5]: Train Loss=2.2318, Val Loss=1.7651
Epoch [2/5]: Train Loss=1.0661, Val Loss=0.9212
Epoch [3/5]: Train Loss=0.5486, Val Loss=0.4840
Epoch [4/5]: Train Loss=0.1709, Val Loss=0.2378
Epoch [5/5]: Train Loss=0.0380, Val Loss=0.1141
LSTM Test CPC Loss: 0.1438
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.7164, Val Loss=14.1456
Epoch [2/5]: Train Loss=8.6022, Val Loss=9.0241
Epoch [3/5]: Train Loss=5.1502, Val Loss=6.3678
Epoch [4/5]: Train Loss=3.2334, Val Loss=4.7187
Epoch [5/5]: Train Loss=2.1423, Val Loss=3.7663
Reservoir Test CPC Loss: 3.5897
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.6902, Val Loss=2.9924
Epoch [2/5]: Train Loss=4.5030, Val Loss=2.9926
Epoch [3/5]: Train Loss=3.7557, Val Loss=2.9930
Epoch [4/5]: Train Loss=3.3526, Val Loss=2.9929
Epoch [5/5]: Train Loss=3.1751, Val Loss=2.9934
BERT Test CPC Loss: 2.9934

--- Fish 9: Run 9 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=326.6750, Val Loss=3.8353
Epoch [2/5]: Train Loss=30.7688, Val Loss=1.5452
Epoch [3/5]: Train Loss=20.9906, Val Loss=1.4318
Epoch [4/5]: Train Loss=15.6335, Val Loss=1.4465
Epoch [5/5]: Train Loss=12.5316, Val Loss=1.4544
GPT2 Test CPC Loss: 1.4667
[Model: LSTM]
Epoch [1/5]: Train Loss=0.8113, Val Loss=0.1601
Epoch [2/5]: Train Loss=0.0367, Val Loss=0.0075
Epoch [3/5]: Train Loss=0.0019, Val Loss=0.0027
Epoch [4/5]: Train Loss=0.0009, Val Loss=0.0019
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0016
LSTM Test CPC Loss: 0.0023
[Model: Reservoir]
Epoch [1/5]: Train Loss=6.9703, Val Loss=3.7733
Epoch [2/5]: Train Loss=2.1893, Val Loss=2.3508
Epoch [3/5]: Train Loss=1.2087, Val Loss=1.7563
Epoch [4/5]: Train Loss=0.7500, Val Loss=1.4563
Epoch [5/5]: Train Loss=0.4852, Val Loss=1.2701
Reservoir Test CPC Loss: 1.0141
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4294, Val Loss=1.5363
Epoch [2/5]: Train Loss=4.7225, Val Loss=1.5280
Epoch [3/5]: Train Loss=3.6329, Val Loss=1.5168
Epoch [4/5]: Train Loss=2.8205, Val Loss=1.5126
Epoch [5/5]: Train Loss=2.2538, Val Loss=1.4818
BERT Test CPC Loss: 1.4822

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=408.1279, Val Loss=2.2736
Epoch [2/5]: Train Loss=31.2234, Val Loss=2.2832
Epoch [3/5]: Train Loss=20.4320, Val Loss=2.2282
Epoch [4/5]: Train Loss=15.4175, Val Loss=2.2390
Epoch [5/5]: Train Loss=12.4445, Val Loss=2.2459
GPT2 Test CPC Loss: 2.2479
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3438, Val Loss=0.6139
Epoch [2/5]: Train Loss=0.2485, Val Loss=0.1502
Epoch [3/5]: Train Loss=0.0328, Val Loss=0.0420
Epoch [4/5]: Train Loss=0.0050, Val Loss=0.0203
Epoch [5/5]: Train Loss=0.0023, Val Loss=0.0166
LSTM Test CPC Loss: 0.0214
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.1120, Val Loss=10.7879
Epoch [2/5]: Train Loss=6.8831, Val Loss=6.8638
Epoch [3/5]: Train Loss=3.9911, Val Loss=4.7749
Epoch [4/5]: Train Loss=2.4754, Val Loss=3.5404
Epoch [5/5]: Train Loss=1.6200, Val Loss=2.8689
Reservoir Test CPC Loss: 2.7883
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.6296, Val Loss=2.2922
Epoch [2/5]: Train Loss=4.3774, Val Loss=2.2913
Epoch [3/5]: Train Loss=3.3927, Val Loss=2.2915
Epoch [4/5]: Train Loss=2.7730, Val Loss=2.2928
Epoch [5/5]: Train Loss=2.5054, Val Loss=2.2935
BERT Test CPC Loss: 2.2934

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=313.1267, Val Loss=2.6865
Epoch [2/5]: Train Loss=21.8009, Val Loss=2.6477
Epoch [3/5]: Train Loss=14.4764, Val Loss=2.6468
Epoch [4/5]: Train Loss=11.2123, Val Loss=2.6545
Epoch [5/5]: Train Loss=9.0441, Val Loss=2.6565
GPT2 Test CPC Loss: 2.6560
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7097, Val Loss=0.9895
Epoch [2/5]: Train Loss=0.4985, Val Loss=0.4037
Epoch [3/5]: Train Loss=0.1006, Val Loss=0.1096
Epoch [4/5]: Train Loss=0.0161, Val Loss=0.0606
Epoch [5/5]: Train Loss=0.0048, Val Loss=0.0497
LSTM Test CPC Loss: 0.0487
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.2453, Val Loss=13.8895
Epoch [2/5]: Train Loss=9.1724, Val Loss=8.5437
Epoch [3/5]: Train Loss=5.4101, Val Loss=5.9094
Epoch [4/5]: Train Loss=3.3930, Val Loss=4.3189
Epoch [5/5]: Train Loss=2.2311, Val Loss=3.3723
Reservoir Test CPC Loss: 3.5550
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.5724, Val Loss=2.7000
Epoch [2/5]: Train Loss=4.3695, Val Loss=2.7006
Epoch [3/5]: Train Loss=3.5021, Val Loss=2.7011
Epoch [4/5]: Train Loss=3.0451, Val Loss=2.7023
Epoch [5/5]: Train Loss=2.8710, Val Loss=2.7029
BERT Test CPC Loss: 2.7029

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=452.0824, Val Loss=2.9582
Epoch [2/5]: Train Loss=32.9452, Val Loss=2.9515
Epoch [3/5]: Train Loss=21.5561, Val Loss=2.9552
Epoch [4/5]: Train Loss=16.4718, Val Loss=2.9512
Epoch [5/5]: Train Loss=13.4420, Val Loss=2.9515
GPT2 Test CPC Loss: 2.9526
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1003, Val Loss=1.4124
Epoch [2/5]: Train Loss=0.9026, Val Loss=0.8612
Epoch [3/5]: Train Loss=0.4077, Val Loss=0.5531
Epoch [4/5]: Train Loss=0.1160, Val Loss=0.1839
Epoch [5/5]: Train Loss=0.0353, Val Loss=0.0575
LSTM Test CPC Loss: 0.0948
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.0485, Val Loss=13.6358
Epoch [2/5]: Train Loss=9.2779, Val Loss=8.6488
Epoch [3/5]: Train Loss=5.2847, Val Loss=6.0033
Epoch [4/5]: Train Loss=3.2340, Val Loss=4.4078
Epoch [5/5]: Train Loss=2.1335, Val Loss=3.4174
Reservoir Test CPC Loss: 3.2489
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7181, Val Loss=2.9926
Epoch [2/5]: Train Loss=4.5100, Val Loss=2.9929
Epoch [3/5]: Train Loss=3.7487, Val Loss=2.9933
Epoch [4/5]: Train Loss=3.3182, Val Loss=2.9935
Epoch [5/5]: Train Loss=3.1418, Val Loss=2.9938
BERT Test CPC Loss: 2.9938

--- Fish 9: Run 10 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=358.3502, Val Loss=2.3556
Epoch [2/5]: Train Loss=25.2850, Val Loss=1.7627
Epoch [3/5]: Train Loss=14.4801, Val Loss=1.5412
Epoch [4/5]: Train Loss=10.2948, Val Loss=1.4736
Epoch [5/5]: Train Loss=8.3629, Val Loss=1.4190
GPT2 Test CPC Loss: 1.4270
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7490, Val Loss=0.0926
Epoch [2/5]: Train Loss=0.0189, Val Loss=0.0062
Epoch [3/5]: Train Loss=0.0015, Val Loss=0.0033
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0018
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0015
LSTM Test CPC Loss: 0.0015
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.6238, Val Loss=4.9880
Epoch [2/5]: Train Loss=2.7444, Val Loss=3.1079
Epoch [3/5]: Train Loss=1.5439, Val Loss=2.3935
Epoch [4/5]: Train Loss=0.9846, Val Loss=1.9285
Epoch [5/5]: Train Loss=0.6568, Val Loss=1.6149
Reservoir Test CPC Loss: 1.5373
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.3991, Val Loss=1.5318
Epoch [2/5]: Train Loss=4.7904, Val Loss=1.5324
Epoch [3/5]: Train Loss=3.7114, Val Loss=1.5220
Epoch [4/5]: Train Loss=2.8531, Val Loss=1.5179
Epoch [5/5]: Train Loss=2.2578, Val Loss=1.5061
BERT Test CPC Loss: 1.5061

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=279.5228, Val Loss=3.3576
Epoch [2/5]: Train Loss=18.8610, Val Loss=3.2705
Epoch [3/5]: Train Loss=13.4352, Val Loss=2.8828
Epoch [4/5]: Train Loss=10.7333, Val Loss=2.7752
Epoch [5/5]: Train Loss=8.9016, Val Loss=2.4690
GPT2 Test CPC Loss: 2.4807
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2054, Val Loss=0.4586
Epoch [2/5]: Train Loss=0.1469, Val Loss=0.0759
Epoch [3/5]: Train Loss=0.0114, Val Loss=0.0185
Epoch [4/5]: Train Loss=0.0027, Val Loss=0.0384
Epoch [5/5]: Train Loss=0.0014, Val Loss=0.0230
LSTM Test CPC Loss: 0.0201
[Model: Reservoir]
Epoch [1/5]: Train Loss=14.5317, Val Loss=9.0360
Epoch [2/5]: Train Loss=6.2219, Val Loss=5.9363
Epoch [3/5]: Train Loss=3.8949, Val Loss=4.2805
Epoch [4/5]: Train Loss=2.5814, Val Loss=3.2552
Epoch [5/5]: Train Loss=1.7890, Val Loss=2.5696
Reservoir Test CPC Loss: 2.9882
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7552, Val Loss=2.2882
Epoch [2/5]: Train Loss=4.4375, Val Loss=2.2911
Epoch [3/5]: Train Loss=3.4523, Val Loss=2.2930
Epoch [4/5]: Train Loss=2.8075, Val Loss=2.2934
Epoch [5/5]: Train Loss=2.5288, Val Loss=2.2952
BERT Test CPC Loss: 2.2952

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=298.6081, Val Loss=3.3167
Epoch [2/5]: Train Loss=30.0683, Val Loss=2.7525
Epoch [3/5]: Train Loss=20.4659, Val Loss=2.6842
Epoch [4/5]: Train Loss=15.2730, Val Loss=2.6630
Epoch [5/5]: Train Loss=12.1747, Val Loss=2.6588
GPT2 Test CPC Loss: 2.6591
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8201, Val Loss=1.0852
Epoch [2/5]: Train Loss=0.6251, Val Loss=0.5643
Epoch [3/5]: Train Loss=0.1763, Val Loss=0.2817
Epoch [4/5]: Train Loss=0.0355, Val Loss=0.1241
Epoch [5/5]: Train Loss=0.0095, Val Loss=0.1025
LSTM Test CPC Loss: 0.1000
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.2839, Val Loss=11.1921
Epoch [2/5]: Train Loss=7.6534, Val Loss=7.5018
Epoch [3/5]: Train Loss=4.6762, Val Loss=5.3625
Epoch [4/5]: Train Loss=3.0150, Val Loss=4.0623
Epoch [5/5]: Train Loss=2.0256, Val Loss=3.2122
Reservoir Test CPC Loss: 3.2432
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.9728, Val Loss=2.7035
Epoch [2/5]: Train Loss=4.4494, Val Loss=2.7048
Epoch [3/5]: Train Loss=3.5762, Val Loss=2.7055
Epoch [4/5]: Train Loss=3.0745, Val Loss=2.7057
Epoch [5/5]: Train Loss=2.8773, Val Loss=2.7055
BERT Test CPC Loss: 2.7055

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=419.7620, Val Loss=5.7940
Epoch [2/5]: Train Loss=33.4442, Val Loss=3.0439
Epoch [3/5]: Train Loss=18.5748, Val Loss=2.9536
Epoch [4/5]: Train Loss=13.3944, Val Loss=2.9525
Epoch [5/5]: Train Loss=10.7179, Val Loss=2.9366
GPT2 Test CPC Loss: 2.9385
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9712, Val Loss=1.3925
Epoch [2/5]: Train Loss=0.9746, Val Loss=0.8882
Epoch [3/5]: Train Loss=0.4037, Val Loss=0.4964
Epoch [4/5]: Train Loss=0.1260, Val Loss=0.1893
Epoch [5/5]: Train Loss=0.0173, Val Loss=0.0962
LSTM Test CPC Loss: 0.1105
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.0630, Val Loss=15.0869
Epoch [2/5]: Train Loss=9.6794, Val Loss=9.8347
Epoch [3/5]: Train Loss=5.6941, Val Loss=6.9331
Epoch [4/5]: Train Loss=3.5298, Val Loss=5.1891
Epoch [5/5]: Train Loss=2.3231, Val Loss=4.1483
Reservoir Test CPC Loss: 3.5245
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.3247, Val Loss=2.9934
Epoch [2/5]: Train Loss=4.3680, Val Loss=2.9931
Epoch [3/5]: Train Loss=3.6307, Val Loss=2.9934
Epoch [4/5]: Train Loss=3.2582, Val Loss=2.9938
Epoch [5/5]: Train Loss=3.1199, Val Loss=2.9942
BERT Test CPC Loss: 2.9942

========== Processing Fish 10 ==========
Fish 10: Neural data shape: (2793, 7441)

--- Fish 10: Run 1 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=425.3400, Val Loss=9.4470
Epoch [2/5]: Train Loss=30.1067, Val Loss=4.9382
Epoch [3/5]: Train Loss=20.4630, Val Loss=3.9669
Epoch [4/5]: Train Loss=14.6302, Val Loss=2.8718
Epoch [5/5]: Train Loss=11.3898, Val Loss=2.3198
GPT2 Test CPC Loss: 3.2477
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6291, Val Loss=0.0710
Epoch [2/5]: Train Loss=0.0180, Val Loss=0.0089
Epoch [3/5]: Train Loss=0.0019, Val Loss=0.0020
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0014
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0010
LSTM Test CPC Loss: 0.0064
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.9097, Val Loss=5.9623
Epoch [2/5]: Train Loss=3.5091, Val Loss=3.7618
Epoch [3/5]: Train Loss=1.9529, Val Loss=2.6779
Epoch [4/5]: Train Loss=1.2071, Val Loss=2.0918
Epoch [5/5]: Train Loss=0.8043, Val Loss=1.8699
Reservoir Test CPC Loss: 1.4762
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8514, Val Loss=1.5426
Epoch [2/5]: Train Loss=4.7547, Val Loss=1.5918
Epoch [3/5]: Train Loss=3.6862, Val Loss=1.6261
Epoch [4/5]: Train Loss=2.9703, Val Loss=1.5802
Epoch [5/5]: Train Loss=2.4070, Val Loss=1.4989
BERT Test CPC Loss: 1.5107

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=423.4927, Val Loss=8.2600
Epoch [2/5]: Train Loss=26.2795, Val Loss=10.5750
Epoch [3/5]: Train Loss=18.7779, Val Loss=7.4013
Epoch [4/5]: Train Loss=14.1412, Val Loss=7.0093
Epoch [5/5]: Train Loss=12.1478, Val Loss=6.1584
GPT2 Test CPC Loss: 8.1008
[Model: LSTM]
Epoch [1/5]: Train Loss=1.0628, Val Loss=0.4415
Epoch [2/5]: Train Loss=0.1559, Val Loss=0.1154
Epoch [3/5]: Train Loss=0.0189, Val Loss=0.0565
Epoch [4/5]: Train Loss=0.0056, Val Loss=0.0391
Epoch [5/5]: Train Loss=0.0031, Val Loss=0.0217
LSTM Test CPC Loss: 0.0492
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.3131, Val Loss=11.9352
Epoch [2/5]: Train Loss=8.2252, Val Loss=7.2489
Epoch [3/5]: Train Loss=4.5705, Val Loss=5.0145
Epoch [4/5]: Train Loss=2.7912, Val Loss=3.7364
Epoch [5/5]: Train Loss=1.8342, Val Loss=2.9780
Reservoir Test CPC Loss: 2.9398
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2802, Val Loss=2.2837
Epoch [2/5]: Train Loss=4.8057, Val Loss=2.2834
Epoch [3/5]: Train Loss=3.8163, Val Loss=2.2854
Epoch [4/5]: Train Loss=3.0539, Val Loss=2.2865
Epoch [5/5]: Train Loss=2.6048, Val Loss=2.2879
BERT Test CPC Loss: 2.2870

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=441.5865, Val Loss=4.4989
Epoch [2/5]: Train Loss=25.4981, Val Loss=2.9913
Epoch [3/5]: Train Loss=17.8075, Val Loss=3.0539
Epoch [4/5]: Train Loss=14.0422, Val Loss=2.9533
Epoch [5/5]: Train Loss=11.7617, Val Loss=2.7926
GPT2 Test CPC Loss: 2.8132
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8388, Val Loss=1.1323
Epoch [2/5]: Train Loss=0.5782, Val Loss=0.4482
Epoch [3/5]: Train Loss=0.0915, Val Loss=0.0848
Epoch [4/5]: Train Loss=0.0151, Val Loss=0.0592
Epoch [5/5]: Train Loss=0.0047, Val Loss=0.0374
LSTM Test CPC Loss: 0.0674
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.3507, Val Loss=17.2646
Epoch [2/5]: Train Loss=10.9148, Val Loss=10.3001
Epoch [3/5]: Train Loss=5.9345, Val Loss=6.7897
Epoch [4/5]: Train Loss=3.4611, Val Loss=4.8879
Epoch [5/5]: Train Loss=2.1695, Val Loss=3.7575
Reservoir Test CPC Loss: 3.1255
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8959, Val Loss=2.6963
Epoch [2/5]: Train Loss=4.6803, Val Loss=2.6993
Epoch [3/5]: Train Loss=3.8399, Val Loss=2.7001
Epoch [4/5]: Train Loss=3.2884, Val Loss=2.7013
Epoch [5/5]: Train Loss=2.9736, Val Loss=2.7019
BERT Test CPC Loss: 2.7015

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=377.2666, Val Loss=4.5157
Epoch [2/5]: Train Loss=20.6146, Val Loss=3.5685
Epoch [3/5]: Train Loss=15.0035, Val Loss=3.3407
Epoch [4/5]: Train Loss=12.0289, Val Loss=3.2414
Epoch [5/5]: Train Loss=10.1646, Val Loss=3.0916
GPT2 Test CPC Loss: 3.1312
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1478, Val Loss=1.7441
Epoch [2/5]: Train Loss=0.9966, Val Loss=1.0827
Epoch [3/5]: Train Loss=0.3809, Val Loss=0.4640
Epoch [4/5]: Train Loss=0.0791, Val Loss=0.1922
Epoch [5/5]: Train Loss=0.0173, Val Loss=0.0874
LSTM Test CPC Loss: 0.0924
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.4618, Val Loss=15.2565
Epoch [2/5]: Train Loss=10.8083, Val Loss=9.2112
Epoch [3/5]: Train Loss=5.8246, Val Loss=6.0330
Epoch [4/5]: Train Loss=3.3483, Val Loss=4.4190
Epoch [5/5]: Train Loss=2.0699, Val Loss=3.2860
Reservoir Test CPC Loss: 3.0917
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7475, Val Loss=2.9873
Epoch [2/5]: Train Loss=4.6409, Val Loss=2.9888
Epoch [3/5]: Train Loss=3.8400, Val Loss=2.9897
Epoch [4/5]: Train Loss=3.3819, Val Loss=2.9907
Epoch [5/5]: Train Loss=3.1737, Val Loss=2.9911
BERT Test CPC Loss: 2.9908

--- Fish 10: Run 2 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=319.1847, Val Loss=6.3926
Epoch [2/5]: Train Loss=23.6778, Val Loss=4.2970
Epoch [3/5]: Train Loss=16.4560, Val Loss=3.2013
Epoch [4/5]: Train Loss=11.8555, Val Loss=2.3733
Epoch [5/5]: Train Loss=9.5691, Val Loss=2.4619
GPT2 Test CPC Loss: 3.7781
[Model: LSTM]
Epoch [1/5]: Train Loss=0.8255, Val Loss=0.1756
Epoch [2/5]: Train Loss=0.0369, Val Loss=0.0145
Epoch [3/5]: Train Loss=0.0044, Val Loss=0.0149
Epoch [4/5]: Train Loss=0.0031, Val Loss=0.0174
Epoch [5/5]: Train Loss=0.0018, Val Loss=0.0031
LSTM Test CPC Loss: 0.0027
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.0266, Val Loss=5.6446
Epoch [2/5]: Train Loss=4.1486, Val Loss=3.3713
Epoch [3/5]: Train Loss=2.3312, Val Loss=2.4313
Epoch [4/5]: Train Loss=1.4373, Val Loss=1.9133
Epoch [5/5]: Train Loss=0.9123, Val Loss=1.5337
Reservoir Test CPC Loss: 1.7053
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2402, Val Loss=1.5090
Epoch [2/5]: Train Loss=4.7774, Val Loss=1.5488
Epoch [3/5]: Train Loss=3.7349, Val Loss=1.5896
Epoch [4/5]: Train Loss=3.0278, Val Loss=1.5535
Epoch [5/5]: Train Loss=2.5097, Val Loss=1.5072
BERT Test CPC Loss: 1.5232

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=345.1710, Val Loss=2.2922
Epoch [2/5]: Train Loss=26.6361, Val Loss=2.2348
Epoch [3/5]: Train Loss=17.4779, Val Loss=2.2275
Epoch [4/5]: Train Loss=13.0853, Val Loss=2.2181
Epoch [5/5]: Train Loss=10.5484, Val Loss=2.2166
GPT2 Test CPC Loss: 2.2291
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3772, Val Loss=0.6008
Epoch [2/5]: Train Loss=0.2070, Val Loss=0.1508
Epoch [3/5]: Train Loss=0.0237, Val Loss=0.0420
Epoch [4/5]: Train Loss=0.0057, Val Loss=0.0222
Epoch [5/5]: Train Loss=0.0020, Val Loss=0.0187
LSTM Test CPC Loss: 0.0705
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.6574, Val Loss=14.2518
Epoch [2/5]: Train Loss=9.5090, Val Loss=9.1003
Epoch [3/5]: Train Loss=5.6329, Val Loss=6.2352
Epoch [4/5]: Train Loss=3.5492, Val Loss=4.7180
Epoch [5/5]: Train Loss=2.3444, Val Loss=3.6953
Reservoir Test CPC Loss: 3.3378
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1903, Val Loss=2.2850
Epoch [2/5]: Train Loss=4.7217, Val Loss=2.2824
Epoch [3/5]: Train Loss=3.7919, Val Loss=2.2817
Epoch [4/5]: Train Loss=3.1386, Val Loss=2.2800
Epoch [5/5]: Train Loss=2.7246, Val Loss=2.2794
BERT Test CPC Loss: 2.2776

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=360.7923, Val Loss=3.7733
Epoch [2/5]: Train Loss=22.0016, Val Loss=3.4723
Epoch [3/5]: Train Loss=15.9839, Val Loss=3.2000
Epoch [4/5]: Train Loss=13.0675, Val Loss=3.1866
Epoch [5/5]: Train Loss=11.0230, Val Loss=3.0260
GPT2 Test CPC Loss: 3.0422
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8311, Val Loss=1.1291
Epoch [2/5]: Train Loss=0.5814, Val Loss=0.3865
Epoch [3/5]: Train Loss=0.1141, Val Loss=0.0864
Epoch [4/5]: Train Loss=0.0209, Val Loss=0.0363
Epoch [5/5]: Train Loss=0.0071, Val Loss=0.0203
LSTM Test CPC Loss: 0.0814
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.6875, Val Loss=15.7032
Epoch [2/5]: Train Loss=9.9886, Val Loss=9.5538
Epoch [3/5]: Train Loss=5.4215, Val Loss=6.2518
Epoch [4/5]: Train Loss=3.1996, Val Loss=4.5304
Epoch [5/5]: Train Loss=2.0149, Val Loss=3.4512
Reservoir Test CPC Loss: 2.5243
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0567, Val Loss=2.6982
Epoch [2/5]: Train Loss=4.7009, Val Loss=2.6992
Epoch [3/5]: Train Loss=3.8504, Val Loss=2.7003
Epoch [4/5]: Train Loss=3.2722, Val Loss=2.7012
Epoch [5/5]: Train Loss=2.9562, Val Loss=2.7013
BERT Test CPC Loss: 2.7008

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=492.7666, Val Loss=6.6343
Epoch [2/5]: Train Loss=36.5072, Val Loss=3.6917
Epoch [3/5]: Train Loss=21.9501, Val Loss=3.1106
Epoch [4/5]: Train Loss=16.0100, Val Loss=2.9988
Epoch [5/5]: Train Loss=12.7561, Val Loss=2.9680
GPT2 Test CPC Loss: 3.0204
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0266, Val Loss=1.4294
Epoch [2/5]: Train Loss=0.8177, Val Loss=0.6856
Epoch [3/5]: Train Loss=0.1889, Val Loss=0.1691
Epoch [4/5]: Train Loss=0.0275, Val Loss=0.0572
Epoch [5/5]: Train Loss=0.0089, Val Loss=0.0342
LSTM Test CPC Loss: 0.0948
[Model: Reservoir]
Epoch [1/5]: Train Loss=29.9647, Val Loss=17.8333
Epoch [2/5]: Train Loss=13.1824, Val Loss=10.5099
Epoch [3/5]: Train Loss=7.2815, Val Loss=6.8934
Epoch [4/5]: Train Loss=4.2754, Val Loss=4.8454
Epoch [5/5]: Train Loss=2.6791, Val Loss=3.6783
Reservoir Test CPC Loss: 3.6879
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9380, Val Loss=2.9914
Epoch [2/5]: Train Loss=4.7408, Val Loss=2.9916
Epoch [3/5]: Train Loss=3.9801, Val Loss=2.9918
Epoch [4/5]: Train Loss=3.5088, Val Loss=2.9918
Epoch [5/5]: Train Loss=3.2377, Val Loss=2.9922
BERT Test CPC Loss: 2.9920

--- Fish 10: Run 3 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=449.2489, Val Loss=25.4512
Epoch [2/5]: Train Loss=41.3350, Val Loss=5.7915
Epoch [3/5]: Train Loss=25.0981, Val Loss=1.9565
Epoch [4/5]: Train Loss=17.6403, Val Loss=1.5861
Epoch [5/5]: Train Loss=13.8329, Val Loss=1.4542
GPT2 Test CPC Loss: 1.5564
[Model: LSTM]
Epoch [1/5]: Train Loss=0.8585, Val Loss=0.1992
Epoch [2/5]: Train Loss=0.0473, Val Loss=0.0148
Epoch [3/5]: Train Loss=0.0037, Val Loss=0.0078
Epoch [4/5]: Train Loss=0.0011, Val Loss=0.0059
Epoch [5/5]: Train Loss=0.0006, Val Loss=0.0049
LSTM Test CPC Loss: 0.0054
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.4534, Val Loss=4.5465
Epoch [2/5]: Train Loss=3.1042, Val Loss=2.8175
Epoch [3/5]: Train Loss=1.7981, Val Loss=2.0581
Epoch [4/5]: Train Loss=1.1634, Val Loss=1.6585
Epoch [5/5]: Train Loss=0.7930, Val Loss=1.3548
Reservoir Test CPC Loss: 1.0111
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9935, Val Loss=1.5519
Epoch [2/5]: Train Loss=4.8056, Val Loss=1.5639
Epoch [3/5]: Train Loss=3.7934, Val Loss=1.5904
Epoch [4/5]: Train Loss=3.0568, Val Loss=1.5757
Epoch [5/5]: Train Loss=2.5071, Val Loss=1.5211
BERT Test CPC Loss: 1.5407

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=565.8307, Val Loss=2.7616
Epoch [2/5]: Train Loss=32.9989, Val Loss=2.3889
Epoch [3/5]: Train Loss=20.3529, Val Loss=2.3822
Epoch [4/5]: Train Loss=14.9101, Val Loss=2.3730
Epoch [5/5]: Train Loss=12.1095, Val Loss=2.3409
GPT2 Test CPC Loss: 2.3443
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4132, Val Loss=0.6271
Epoch [2/5]: Train Loss=0.2320, Val Loss=0.1455
Epoch [3/5]: Train Loss=0.0212, Val Loss=0.0489
Epoch [4/5]: Train Loss=0.0045, Val Loss=0.0340
Epoch [5/5]: Train Loss=0.0022, Val Loss=0.0203
LSTM Test CPC Loss: 0.0494
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.1260, Val Loss=13.3855
Epoch [2/5]: Train Loss=9.9010, Val Loss=8.2842
Epoch [3/5]: Train Loss=5.8986, Val Loss=5.7888
Epoch [4/5]: Train Loss=3.7106, Val Loss=4.2487
Epoch [5/5]: Train Loss=2.4311, Val Loss=3.4060
Reservoir Test CPC Loss: 3.2174
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1599, Val Loss=2.2828
Epoch [2/5]: Train Loss=4.8056, Val Loss=2.2845
Epoch [3/5]: Train Loss=3.8684, Val Loss=2.2860
Epoch [4/5]: Train Loss=3.1961, Val Loss=2.2863
Epoch [5/5]: Train Loss=2.7523, Val Loss=2.2872
BERT Test CPC Loss: 2.2861

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=419.1811, Val Loss=3.2369
Epoch [2/5]: Train Loss=29.4828, Val Loss=2.8025
Epoch [3/5]: Train Loss=20.1317, Val Loss=2.6875
Epoch [4/5]: Train Loss=15.2185, Val Loss=2.6586
Epoch [5/5]: Train Loss=12.3363, Val Loss=2.6508
GPT2 Test CPC Loss: 2.6718
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6137, Val Loss=0.9293
Epoch [2/5]: Train Loss=0.3873, Val Loss=0.2704
Epoch [3/5]: Train Loss=0.0565, Val Loss=0.0688
Epoch [4/5]: Train Loss=0.0102, Val Loss=0.0471
Epoch [5/5]: Train Loss=0.0037, Val Loss=0.0292
LSTM Test CPC Loss: 0.0672
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.9589, Val Loss=13.4919
Epoch [2/5]: Train Loss=8.8782, Val Loss=8.2848
Epoch [3/5]: Train Loss=5.1123, Val Loss=5.5256
Epoch [4/5]: Train Loss=3.1246, Val Loss=4.1134
Epoch [5/5]: Train Loss=2.0184, Val Loss=3.1329
Reservoir Test CPC Loss: 2.6720
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3174, Val Loss=2.6981
Epoch [2/5]: Train Loss=4.8004, Val Loss=2.6999
Epoch [3/5]: Train Loss=3.9463, Val Loss=2.7004
Epoch [4/5]: Train Loss=3.3967, Val Loss=2.7011
Epoch [5/5]: Train Loss=3.0665, Val Loss=2.7012
BERT Test CPC Loss: 2.7007

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=545.2394, Val Loss=3.5061
Epoch [2/5]: Train Loss=36.0379, Val Loss=3.0985
Epoch [3/5]: Train Loss=21.8025, Val Loss=3.0231
Epoch [4/5]: Train Loss=15.1775, Val Loss=2.9795
Epoch [5/5]: Train Loss=12.0205, Val Loss=2.9672
GPT2 Test CPC Loss: 2.9867
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9404, Val Loss=1.3645
Epoch [2/5]: Train Loss=0.7487, Val Loss=0.7387
Epoch [3/5]: Train Loss=0.1741, Val Loss=0.1794
Epoch [4/5]: Train Loss=0.0275, Val Loss=0.0665
Epoch [5/5]: Train Loss=0.0082, Val Loss=0.0436
LSTM Test CPC Loss: 0.0854
[Model: Reservoir]
Epoch [1/5]: Train Loss=26.7940, Val Loss=16.6723
Epoch [2/5]: Train Loss=10.9231, Val Loss=9.4066
Epoch [3/5]: Train Loss=5.7877, Val Loss=5.9462
Epoch [4/5]: Train Loss=3.3365, Val Loss=4.0855
Epoch [5/5]: Train Loss=2.0676, Val Loss=3.0995
Reservoir Test CPC Loss: 3.4178
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0439, Val Loss=2.9881
Epoch [2/5]: Train Loss=4.7635, Val Loss=2.9889
Epoch [3/5]: Train Loss=3.9888, Val Loss=2.9898
Epoch [4/5]: Train Loss=3.5123, Val Loss=2.9904
Epoch [5/5]: Train Loss=3.2440, Val Loss=2.9908
BERT Test CPC Loss: 2.9904

--- Fish 10: Run 4 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=309.2927, Val Loss=1.9738
Epoch [2/5]: Train Loss=27.5787, Val Loss=1.6229
Epoch [3/5]: Train Loss=16.8685, Val Loss=1.5303
Epoch [4/5]: Train Loss=11.8668, Val Loss=1.4514
Epoch [5/5]: Train Loss=9.2901, Val Loss=1.4175
GPT2 Test CPC Loss: 1.4297
[Model: LSTM]
Epoch [1/5]: Train Loss=0.8738, Val Loss=0.2639
Epoch [2/5]: Train Loss=0.0388, Val Loss=0.0205
Epoch [3/5]: Train Loss=0.0062, Val Loss=0.0238
Epoch [4/5]: Train Loss=0.0011, Val Loss=0.0159
Epoch [5/5]: Train Loss=0.0006, Val Loss=0.0128
LSTM Test CPC Loss: 0.0058
[Model: Reservoir]
Epoch [1/5]: Train Loss=12.2455, Val Loss=6.8821
Epoch [2/5]: Train Loss=3.4380, Val Loss=3.7805
Epoch [3/5]: Train Loss=1.7436, Val Loss=2.6431
Epoch [4/5]: Train Loss=0.9908, Val Loss=2.0958
Epoch [5/5]: Train Loss=0.6050, Val Loss=1.7024
Reservoir Test CPC Loss: 1.2984
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1683, Val Loss=1.4970
Epoch [2/5]: Train Loss=4.8060, Val Loss=1.5477
Epoch [3/5]: Train Loss=3.7460, Val Loss=1.6129
Epoch [4/5]: Train Loss=3.0722, Val Loss=1.5762
Epoch [5/5]: Train Loss=2.5601, Val Loss=1.5239
BERT Test CPC Loss: 1.5445

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=315.3436, Val Loss=2.3063
Epoch [2/5]: Train Loss=19.4618, Val Loss=2.2118
Epoch [3/5]: Train Loss=12.9865, Val Loss=2.2048
Epoch [4/5]: Train Loss=10.0407, Val Loss=2.2037
Epoch [5/5]: Train Loss=8.2470, Val Loss=2.2078
GPT2 Test CPC Loss: 2.2210
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3124, Val Loss=0.5290
Epoch [2/5]: Train Loss=0.1766, Val Loss=0.1273
Epoch [3/5]: Train Loss=0.0229, Val Loss=0.0707
Epoch [4/5]: Train Loss=0.0134, Val Loss=0.0345
Epoch [5/5]: Train Loss=0.0032, Val Loss=0.0218
LSTM Test CPC Loss: 0.0506
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.9082, Val Loss=13.1274
Epoch [2/5]: Train Loss=10.2768, Val Loss=8.3797
Epoch [3/5]: Train Loss=6.1847, Val Loss=5.8594
Epoch [4/5]: Train Loss=3.9443, Val Loss=4.3678
Epoch [5/5]: Train Loss=2.5990, Val Loss=3.4582
Reservoir Test CPC Loss: 3.2470
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4817, Val Loss=2.2887
Epoch [2/5]: Train Loss=4.8198, Val Loss=2.2867
Epoch [3/5]: Train Loss=3.7878, Val Loss=2.2884
Epoch [4/5]: Train Loss=3.0005, Val Loss=2.2904
Epoch [5/5]: Train Loss=2.5691, Val Loss=2.2917
BERT Test CPC Loss: 2.2910

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=582.4723, Val Loss=16.5823
Epoch [2/5]: Train Loss=32.7762, Val Loss=12.1228
Epoch [3/5]: Train Loss=23.7616, Val Loss=11.4796
Epoch [4/5]: Train Loss=18.7466, Val Loss=10.5882
Epoch [5/5]: Train Loss=15.5970, Val Loss=8.4518
GPT2 Test CPC Loss: 10.2010
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5141, Val Loss=0.9611
Epoch [2/5]: Train Loss=0.4000, Val Loss=0.3607
Epoch [3/5]: Train Loss=0.0598, Val Loss=0.0695
Epoch [4/5]: Train Loss=0.0131, Val Loss=0.0331
Epoch [5/5]: Train Loss=0.0040, Val Loss=0.0321
LSTM Test CPC Loss: 0.0678
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.7450, Val Loss=16.2918
Epoch [2/5]: Train Loss=10.5701, Val Loss=10.2849
Epoch [3/5]: Train Loss=5.8535, Val Loss=6.9192
Epoch [4/5]: Train Loss=3.4663, Val Loss=5.0477
Epoch [5/5]: Train Loss=2.1908, Val Loss=3.9386
Reservoir Test CPC Loss: 3.4044
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9526, Val Loss=2.6976
Epoch [2/5]: Train Loss=4.6850, Val Loss=2.6977
Epoch [3/5]: Train Loss=3.8301, Val Loss=2.6976
Epoch [4/5]: Train Loss=3.3076, Val Loss=2.6973
Epoch [5/5]: Train Loss=3.0144, Val Loss=2.6979
BERT Test CPC Loss: 2.6975

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=341.3908, Val Loss=2.9390
Epoch [2/5]: Train Loss=19.1180, Val Loss=2.9906
Epoch [3/5]: Train Loss=13.7028, Val Loss=2.9833
Epoch [4/5]: Train Loss=11.0918, Val Loss=2.9457
Epoch [5/5]: Train Loss=9.5053, Val Loss=2.9571
GPT2 Test CPC Loss: 2.9608
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0052, Val Loss=1.4033
Epoch [2/5]: Train Loss=0.7447, Val Loss=0.5465
Epoch [3/5]: Train Loss=0.1269, Val Loss=0.0767
Epoch [4/5]: Train Loss=0.0153, Val Loss=0.0475
Epoch [5/5]: Train Loss=0.0060, Val Loss=0.0301
LSTM Test CPC Loss: 0.0563
[Model: Reservoir]
Epoch [1/5]: Train Loss=27.0645, Val Loss=16.5080
Epoch [2/5]: Train Loss=11.3258, Val Loss=9.1826
Epoch [3/5]: Train Loss=5.8396, Val Loss=5.6480
Epoch [4/5]: Train Loss=3.2592, Val Loss=3.8394
Epoch [5/5]: Train Loss=1.9779, Val Loss=2.8575
Reservoir Test CPC Loss: 3.0838
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9987, Val Loss=2.9897
Epoch [2/5]: Train Loss=4.7404, Val Loss=2.9895
Epoch [3/5]: Train Loss=3.9135, Val Loss=2.9903
Epoch [4/5]: Train Loss=3.4017, Val Loss=2.9911
Epoch [5/5]: Train Loss=3.1758, Val Loss=2.9916
BERT Test CPC Loss: 2.9915

--- Fish 10: Run 5 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=328.2144, Val Loss=1.6701
Epoch [2/5]: Train Loss=23.8082, Val Loss=1.5816
Epoch [3/5]: Train Loss=15.3209, Val Loss=1.6405
Epoch [4/5]: Train Loss=11.6807, Val Loss=1.6675
Epoch [5/5]: Train Loss=9.7273, Val Loss=1.7211
GPT2 Test CPC Loss: 1.7678
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7776, Val Loss=0.0996
Epoch [2/5]: Train Loss=0.0208, Val Loss=0.0120
Epoch [3/5]: Train Loss=0.0025, Val Loss=0.0047
Epoch [4/5]: Train Loss=0.0021, Val Loss=0.0036
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0021
LSTM Test CPC Loss: 0.0026
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.8997, Val Loss=6.2923
Epoch [2/5]: Train Loss=4.2420, Val Loss=3.8187
Epoch [3/5]: Train Loss=2.3589, Val Loss=2.8358
Epoch [4/5]: Train Loss=1.4498, Val Loss=2.3135
Epoch [5/5]: Train Loss=0.9320, Val Loss=1.9424
Reservoir Test CPC Loss: 1.5481
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0863, Val Loss=1.5350
Epoch [2/5]: Train Loss=4.7543, Val Loss=1.5870
Epoch [3/5]: Train Loss=3.6975, Val Loss=1.6111
Epoch [4/5]: Train Loss=2.9938, Val Loss=1.5794
Epoch [5/5]: Train Loss=2.5068, Val Loss=1.5088
BERT Test CPC Loss: 1.5260

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=337.8920, Val Loss=6.6056
Epoch [2/5]: Train Loss=21.8938, Val Loss=3.9633
Epoch [3/5]: Train Loss=16.1670, Val Loss=3.5124
Epoch [4/5]: Train Loss=12.3829, Val Loss=2.7980
Epoch [5/5]: Train Loss=10.0216, Val Loss=2.7478
GPT2 Test CPC Loss: 3.9269
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4158, Val Loss=0.5980
Epoch [2/5]: Train Loss=0.2061, Val Loss=0.1568
Epoch [3/5]: Train Loss=0.0249, Val Loss=0.0495
Epoch [4/5]: Train Loss=0.0048, Val Loss=0.0213
Epoch [5/5]: Train Loss=0.0020, Val Loss=0.0273
LSTM Test CPC Loss: 0.0314
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.2460, Val Loss=12.4698
Epoch [2/5]: Train Loss=8.3645, Val Loss=8.0405
Epoch [3/5]: Train Loss=4.9179, Val Loss=5.6434
Epoch [4/5]: Train Loss=3.0828, Val Loss=4.2055
Epoch [5/5]: Train Loss=2.0444, Val Loss=3.3309
Reservoir Test CPC Loss: 3.0374
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7303, Val Loss=2.2783
Epoch [2/5]: Train Loss=4.6558, Val Loss=2.2776
Epoch [3/5]: Train Loss=3.6645, Val Loss=2.2769
Epoch [4/5]: Train Loss=2.9554, Val Loss=2.2779
Epoch [5/5]: Train Loss=2.5990, Val Loss=2.2787
BERT Test CPC Loss: 2.2770

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=287.6504, Val Loss=4.6567
Epoch [2/5]: Train Loss=21.1051, Val Loss=2.6858
Epoch [3/5]: Train Loss=14.7376, Val Loss=2.6854
Epoch [4/5]: Train Loss=11.5460, Val Loss=2.7286
Epoch [5/5]: Train Loss=9.5541, Val Loss=2.8811
GPT2 Test CPC Loss: 2.8616
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6921, Val Loss=0.9986
Epoch [2/5]: Train Loss=0.5005, Val Loss=0.2892
Epoch [3/5]: Train Loss=0.0804, Val Loss=0.0881
Epoch [4/5]: Train Loss=0.0140, Val Loss=0.0424
Epoch [5/5]: Train Loss=0.0046, Val Loss=0.0379
LSTM Test CPC Loss: 0.0505
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.4298, Val Loss=16.6273
Epoch [2/5]: Train Loss=10.3703, Val Loss=9.6487
Epoch [3/5]: Train Loss=5.4681, Val Loss=6.3543
Epoch [4/5]: Train Loss=3.1613, Val Loss=4.5615
Epoch [5/5]: Train Loss=1.9725, Val Loss=3.5874
Reservoir Test CPC Loss: 3.2421
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9804, Val Loss=2.7019
Epoch [2/5]: Train Loss=4.7041, Val Loss=2.7012
Epoch [3/5]: Train Loss=3.7983, Val Loss=2.7016
Epoch [4/5]: Train Loss=3.2075, Val Loss=2.7020
Epoch [5/5]: Train Loss=2.9284, Val Loss=2.7028
BERT Test CPC Loss: 2.7024

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=446.2224, Val Loss=9.6351
Epoch [2/5]: Train Loss=21.7692, Val Loss=3.8818
Epoch [3/5]: Train Loss=16.2206, Val Loss=3.8658
Epoch [4/5]: Train Loss=12.8242, Val Loss=3.6652
Epoch [5/5]: Train Loss=10.9327, Val Loss=3.6071
GPT2 Test CPC Loss: 4.8050
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0800, Val Loss=1.5833
Epoch [2/5]: Train Loss=0.9449, Val Loss=0.9686
Epoch [3/5]: Train Loss=0.3170, Val Loss=0.2764
Epoch [4/5]: Train Loss=0.0513, Val Loss=0.0773
Epoch [5/5]: Train Loss=0.0117, Val Loss=0.0363
LSTM Test CPC Loss: 0.0949
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.1857, Val Loss=17.7096
Epoch [2/5]: Train Loss=10.9211, Val Loss=10.1596
Epoch [3/5]: Train Loss=5.6362, Val Loss=6.5000
Epoch [4/5]: Train Loss=3.1903, Val Loss=4.6309
Epoch [5/5]: Train Loss=1.9601, Val Loss=3.5852
Reservoir Test CPC Loss: 3.0009
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0402, Val Loss=2.9896
Epoch [2/5]: Train Loss=4.6651, Val Loss=2.9904
Epoch [3/5]: Train Loss=3.9172, Val Loss=2.9915
Epoch [4/5]: Train Loss=3.4597, Val Loss=2.9917
Epoch [5/5]: Train Loss=3.2143, Val Loss=2.9919
BERT Test CPC Loss: 2.9918

--- Fish 10: Run 6 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=291.5760, Val Loss=3.0807
Epoch [2/5]: Train Loss=21.0530, Val Loss=2.3813
Epoch [3/5]: Train Loss=13.7300, Val Loss=2.2454
Epoch [4/5]: Train Loss=10.6692, Val Loss=2.0518
Epoch [5/5]: Train Loss=8.3096, Val Loss=1.7028
GPT2 Test CPC Loss: 1.6725
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6610, Val Loss=0.0703
Epoch [2/5]: Train Loss=0.0156, Val Loss=0.0240
Epoch [3/5]: Train Loss=0.0028, Val Loss=0.0024
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0012
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0009
LSTM Test CPC Loss: 0.0029
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.3915, Val Loss=5.8013
Epoch [2/5]: Train Loss=3.7899, Val Loss=3.5417
Epoch [3/5]: Train Loss=2.2556, Val Loss=2.6003
Epoch [4/5]: Train Loss=1.4736, Val Loss=2.0447
Epoch [5/5]: Train Loss=0.9741, Val Loss=1.6746
Reservoir Test CPC Loss: 1.3620
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3520, Val Loss=1.5229
Epoch [2/5]: Train Loss=4.8374, Val Loss=1.5332
Epoch [3/5]: Train Loss=3.8478, Val Loss=1.5953
Epoch [4/5]: Train Loss=3.0887, Val Loss=1.5823
Epoch [5/5]: Train Loss=2.5005, Val Loss=1.5206
BERT Test CPC Loss: 1.5374

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=389.4224, Val Loss=2.4412
Epoch [2/5]: Train Loss=20.1153, Val Loss=2.2634
Epoch [3/5]: Train Loss=14.5184, Val Loss=2.2309
Epoch [4/5]: Train Loss=11.7317, Val Loss=2.2372
Epoch [5/5]: Train Loss=9.8993, Val Loss=2.2414
GPT2 Test CPC Loss: 2.2529
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2409, Val Loss=0.5452
Epoch [2/5]: Train Loss=0.1620, Val Loss=0.1040
Epoch [3/5]: Train Loss=0.0205, Val Loss=0.0643
Epoch [4/5]: Train Loss=0.0047, Val Loss=0.0341
Epoch [5/5]: Train Loss=0.0021, Val Loss=0.0251
LSTM Test CPC Loss: 0.0825
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.2467, Val Loss=14.8229
Epoch [2/5]: Train Loss=10.1541, Val Loss=9.0526
Epoch [3/5]: Train Loss=5.9091, Val Loss=6.2377
Epoch [4/5]: Train Loss=3.6528, Val Loss=4.6350
Epoch [5/5]: Train Loss=2.3661, Val Loss=3.6232
Reservoir Test CPC Loss: 3.1107
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1129, Val Loss=2.2920
Epoch [2/5]: Train Loss=4.7662, Val Loss=2.2885
Epoch [3/5]: Train Loss=3.8188, Val Loss=2.2845
Epoch [4/5]: Train Loss=3.1482, Val Loss=2.2824
Epoch [5/5]: Train Loss=2.7333, Val Loss=2.2805
BERT Test CPC Loss: 2.2796

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=385.6976, Val Loss=2.4519
Epoch [2/5]: Train Loss=22.5462, Val Loss=2.6162
Epoch [3/5]: Train Loss=16.0300, Val Loss=2.6952
Epoch [4/5]: Train Loss=12.7693, Val Loss=2.8092
Epoch [5/5]: Train Loss=10.7240, Val Loss=2.8092
GPT2 Test CPC Loss: 2.8316
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6475, Val Loss=0.9485
Epoch [2/5]: Train Loss=0.4287, Val Loss=0.3343
Epoch [3/5]: Train Loss=0.0651, Val Loss=0.1000
Epoch [4/5]: Train Loss=0.0133, Val Loss=0.0644
Epoch [5/5]: Train Loss=0.0052, Val Loss=0.0544
LSTM Test CPC Loss: 0.0826
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.8143, Val Loss=15.7434
Epoch [2/5]: Train Loss=10.8130, Val Loss=9.6127
Epoch [3/5]: Train Loss=6.2222, Val Loss=6.4138
Epoch [4/5]: Train Loss=3.7777, Val Loss=4.5709
Epoch [5/5]: Train Loss=2.4168, Val Loss=3.4640
Reservoir Test CPC Loss: 3.1601
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0640, Val Loss=2.6965
Epoch [2/5]: Train Loss=4.6970, Val Loss=2.6963
Epoch [3/5]: Train Loss=3.7103, Val Loss=2.6986
Epoch [4/5]: Train Loss=3.1202, Val Loss=2.7002
Epoch [5/5]: Train Loss=2.9034, Val Loss=2.7012
BERT Test CPC Loss: 2.7005

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=336.2411, Val Loss=3.1544
Epoch [2/5]: Train Loss=22.3882, Val Loss=3.0310
Epoch [3/5]: Train Loss=14.5244, Val Loss=2.9931
Epoch [4/5]: Train Loss=11.0343, Val Loss=2.9786
Epoch [5/5]: Train Loss=8.9738, Val Loss=2.9653
GPT2 Test CPC Loss: 2.9769
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8923, Val Loss=1.4634
Epoch [2/5]: Train Loss=0.6675, Val Loss=0.4525
Epoch [3/5]: Train Loss=0.1134, Val Loss=0.1154
Epoch [4/5]: Train Loss=0.0171, Val Loss=0.0531
Epoch [5/5]: Train Loss=0.0057, Val Loss=0.0322
LSTM Test CPC Loss: 0.0795
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.6602, Val Loss=17.5722
Epoch [2/5]: Train Loss=10.9504, Val Loss=10.0094
Epoch [3/5]: Train Loss=5.7666, Val Loss=6.5337
Epoch [4/5]: Train Loss=3.2910, Val Loss=4.6988
Epoch [5/5]: Train Loss=2.0322, Val Loss=3.5396
Reservoir Test CPC Loss: 3.3067
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5333, Val Loss=2.9866
Epoch [2/5]: Train Loss=4.6649, Val Loss=2.9885
Epoch [3/5]: Train Loss=3.8590, Val Loss=2.9897
Epoch [4/5]: Train Loss=3.3741, Val Loss=2.9909
Epoch [5/5]: Train Loss=3.1575, Val Loss=2.9916
BERT Test CPC Loss: 2.9914

--- Fish 10: Run 7 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=403.1355, Val Loss=2.8493
Epoch [2/5]: Train Loss=28.2556, Val Loss=2.3738
Epoch [3/5]: Train Loss=17.4429, Val Loss=2.9980
Epoch [4/5]: Train Loss=13.2693, Val Loss=2.6854
Epoch [5/5]: Train Loss=10.9541, Val Loss=2.4158
GPT2 Test CPC Loss: 2.5220
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7959, Val Loss=0.0883
Epoch [2/5]: Train Loss=0.0162, Val Loss=0.0082
Epoch [3/5]: Train Loss=0.0030, Val Loss=0.0148
Epoch [4/5]: Train Loss=0.0081, Val Loss=0.0032
Epoch [5/5]: Train Loss=0.0008, Val Loss=0.0021
LSTM Test CPC Loss: 0.0031
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.0013, Val Loss=6.6765
Epoch [2/5]: Train Loss=3.9976, Val Loss=4.0745
Epoch [3/5]: Train Loss=2.2574, Val Loss=2.9472
Epoch [4/5]: Train Loss=1.3816, Val Loss=2.3608
Epoch [5/5]: Train Loss=0.8823, Val Loss=2.0668
Reservoir Test CPC Loss: 1.6376
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.5459, Val Loss=1.5334
Epoch [2/5]: Train Loss=4.9357, Val Loss=1.5396
Epoch [3/5]: Train Loss=3.8346, Val Loss=1.5859
Epoch [4/5]: Train Loss=3.0452, Val Loss=1.5727
Epoch [5/5]: Train Loss=2.4857, Val Loss=1.5095
BERT Test CPC Loss: 1.5250

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=563.3843, Val Loss=3.1778
Epoch [2/5]: Train Loss=49.8781, Val Loss=2.9238
Epoch [3/5]: Train Loss=34.2339, Val Loss=2.8941
Epoch [4/5]: Train Loss=25.6688, Val Loss=2.7428
Epoch [5/5]: Train Loss=20.4500, Val Loss=2.4997
GPT2 Test CPC Loss: 2.6240
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5614, Val Loss=0.8104
Epoch [2/5]: Train Loss=0.3252, Val Loss=0.1737
Epoch [3/5]: Train Loss=0.0388, Val Loss=0.0481
Epoch [4/5]: Train Loss=0.0070, Val Loss=0.0224
Epoch [5/5]: Train Loss=0.0035, Val Loss=0.0243
LSTM Test CPC Loss: 0.0895
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.8050, Val Loss=11.8897
Epoch [2/5]: Train Loss=8.5827, Val Loss=7.7186
Epoch [3/5]: Train Loss=4.9559, Val Loss=5.4770
Epoch [4/5]: Train Loss=3.0571, Val Loss=4.2298
Epoch [5/5]: Train Loss=1.9809, Val Loss=3.3605
Reservoir Test CPC Loss: 2.6381
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6966, Val Loss=2.2751
Epoch [2/5]: Train Loss=4.6411, Val Loss=2.2758
Epoch [3/5]: Train Loss=3.7156, Val Loss=2.2766
Epoch [4/5]: Train Loss=3.0744, Val Loss=2.2746
Epoch [5/5]: Train Loss=2.6903, Val Loss=2.2732
BERT Test CPC Loss: 2.2711

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=350.2892, Val Loss=2.8566
Epoch [2/5]: Train Loss=21.4309, Val Loss=2.6770
Epoch [3/5]: Train Loss=15.0286, Val Loss=2.6520
Epoch [4/5]: Train Loss=12.0467, Val Loss=2.6532
Epoch [5/5]: Train Loss=10.1953, Val Loss=2.6612
GPT2 Test CPC Loss: 2.6776
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8061, Val Loss=1.1332
Epoch [2/5]: Train Loss=0.5514, Val Loss=0.3744
Epoch [3/5]: Train Loss=0.0841, Val Loss=0.1043
Epoch [4/5]: Train Loss=0.0138, Val Loss=0.0489
Epoch [5/5]: Train Loss=0.0051, Val Loss=0.0349
LSTM Test CPC Loss: 0.1234
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.6732, Val Loss=15.1893
Epoch [2/5]: Train Loss=10.1296, Val Loss=9.2616
Epoch [3/5]: Train Loss=5.6397, Val Loss=6.2198
Epoch [4/5]: Train Loss=3.3761, Val Loss=4.4736
Epoch [5/5]: Train Loss=2.1550, Val Loss=3.4550
Reservoir Test CPC Loss: 3.0021
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1667, Val Loss=2.6969
Epoch [2/5]: Train Loss=4.7429, Val Loss=2.6964
Epoch [3/5]: Train Loss=3.8450, Val Loss=2.6976
Epoch [4/5]: Train Loss=3.2556, Val Loss=2.6986
Epoch [5/5]: Train Loss=2.9433, Val Loss=2.6997
BERT Test CPC Loss: 2.6995

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=352.3830, Val Loss=2.8726
Epoch [2/5]: Train Loss=19.8604, Val Loss=2.8889
Epoch [3/5]: Train Loss=14.6202, Val Loss=2.9209
Epoch [4/5]: Train Loss=11.7835, Val Loss=2.9510
Epoch [5/5]: Train Loss=9.9233, Val Loss=2.9451
GPT2 Test CPC Loss: 2.9662
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0273, Val Loss=1.5121
Epoch [2/5]: Train Loss=0.7709, Val Loss=0.5792
Epoch [3/5]: Train Loss=0.1467, Val Loss=0.1005
Epoch [4/5]: Train Loss=0.0186, Val Loss=0.0456
Epoch [5/5]: Train Loss=0.0053, Val Loss=0.0249
LSTM Test CPC Loss: 0.0706
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.5049, Val Loss=16.9351
Epoch [2/5]: Train Loss=11.1077, Val Loss=9.5710
Epoch [3/5]: Train Loss=5.7506, Val Loss=6.0960
Epoch [4/5]: Train Loss=3.2527, Val Loss=4.2329
Epoch [5/5]: Train Loss=2.0042, Val Loss=3.2365
Reservoir Test CPC Loss: 2.6673
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6305, Val Loss=2.9897
Epoch [2/5]: Train Loss=4.6681, Val Loss=2.9905
Epoch [3/5]: Train Loss=3.8698, Val Loss=2.9911
Epoch [4/5]: Train Loss=3.3834, Val Loss=2.9913
Epoch [5/5]: Train Loss=3.1643, Val Loss=2.9917
BERT Test CPC Loss: 2.9913

--- Fish 10: Run 8 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=424.6851, Val Loss=10.7112
Epoch [2/5]: Train Loss=35.4894, Val Loss=2.0893
Epoch [3/5]: Train Loss=21.9608, Val Loss=1.6343
Epoch [4/5]: Train Loss=15.7115, Val Loss=1.4724
Epoch [5/5]: Train Loss=12.2123, Val Loss=1.4396
GPT2 Test CPC Loss: 1.4702
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7748, Val Loss=0.1088
Epoch [2/5]: Train Loss=0.0214, Val Loss=0.0064
Epoch [3/5]: Train Loss=0.0027, Val Loss=0.0022
Epoch [4/5]: Train Loss=0.0008, Val Loss=0.0023
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0010
LSTM Test CPC Loss: 0.0057
[Model: Reservoir]
Epoch [1/5]: Train Loss=12.5666, Val Loss=6.9514
Epoch [2/5]: Train Loss=4.1297, Val Loss=4.3168
Epoch [3/5]: Train Loss=2.1441, Val Loss=3.1046
Epoch [4/5]: Train Loss=1.2539, Val Loss=2.5431
Epoch [5/5]: Train Loss=0.7650, Val Loss=2.0556
Reservoir Test CPC Loss: 1.9679
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9290, Val Loss=1.5235
Epoch [2/5]: Train Loss=4.8016, Val Loss=1.5750
Epoch [3/5]: Train Loss=3.7388, Val Loss=1.6323
Epoch [4/5]: Train Loss=2.9036, Val Loss=1.5553
Epoch [5/5]: Train Loss=2.2947, Val Loss=1.4993
BERT Test CPC Loss: 1.5060

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=547.4128, Val Loss=18.5769
Epoch [2/5]: Train Loss=51.9255, Val Loss=3.5606
Epoch [3/5]: Train Loss=26.7609, Val Loss=2.4500
Epoch [4/5]: Train Loss=17.4749, Val Loss=2.2639
Epoch [5/5]: Train Loss=12.9310, Val Loss=2.1945
GPT2 Test CPC Loss: 2.2437
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4016, Val Loss=0.6285
Epoch [2/5]: Train Loss=0.2395, Val Loss=0.1303
Epoch [3/5]: Train Loss=0.0267, Val Loss=0.0437
Epoch [4/5]: Train Loss=0.0060, Val Loss=0.0238
Epoch [5/5]: Train Loss=0.0020, Val Loss=0.0168
LSTM Test CPC Loss: 0.0271
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.2345, Val Loss=13.5501
Epoch [2/5]: Train Loss=9.2333, Val Loss=8.6352
Epoch [3/5]: Train Loss=5.3102, Val Loss=6.0984
Epoch [4/5]: Train Loss=3.2498, Val Loss=4.5992
Epoch [5/5]: Train Loss=2.0756, Val Loss=3.5553
Reservoir Test CPC Loss: 3.0083
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9116, Val Loss=2.2788
Epoch [2/5]: Train Loss=4.6430, Val Loss=2.2807
Epoch [3/5]: Train Loss=3.6838, Val Loss=2.2822
Epoch [4/5]: Train Loss=2.9968, Val Loss=2.2829
Epoch [5/5]: Train Loss=2.6122, Val Loss=2.2828
BERT Test CPC Loss: 2.2815

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=371.7492, Val Loss=2.7536
Epoch [2/5]: Train Loss=22.4277, Val Loss=2.7856
Epoch [3/5]: Train Loss=16.3340, Val Loss=2.6874
Epoch [4/5]: Train Loss=13.2025, Val Loss=2.6527
Epoch [5/5]: Train Loss=11.1521, Val Loss=2.6788
GPT2 Test CPC Loss: 2.6955
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9297, Val Loss=1.1415
Epoch [2/5]: Train Loss=0.5842, Val Loss=0.3854
Epoch [3/5]: Train Loss=0.1110, Val Loss=0.0975
Epoch [4/5]: Train Loss=0.0196, Val Loss=0.0478
Epoch [5/5]: Train Loss=0.0057, Val Loss=0.0270
LSTM Test CPC Loss: 0.1010
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.9143, Val Loss=16.2000
Epoch [2/5]: Train Loss=11.0566, Val Loss=9.8567
Epoch [3/5]: Train Loss=6.1316, Val Loss=6.5109
Epoch [4/5]: Train Loss=3.6470, Val Loss=4.6032
Epoch [5/5]: Train Loss=2.3133, Val Loss=3.4945
Reservoir Test CPC Loss: 3.2475
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7723, Val Loss=2.7009
Epoch [2/5]: Train Loss=4.6383, Val Loss=2.7013
Epoch [3/5]: Train Loss=3.8122, Val Loss=2.7013
Epoch [4/5]: Train Loss=3.2736, Val Loss=2.7020
Epoch [5/5]: Train Loss=2.9760, Val Loss=2.7021
BERT Test CPC Loss: 2.7016

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=315.5920, Val Loss=5.8422
Epoch [2/5]: Train Loss=20.5864, Val Loss=4.6206
Epoch [3/5]: Train Loss=15.0121, Val Loss=4.2300
Epoch [4/5]: Train Loss=12.0827, Val Loss=3.9055
Epoch [5/5]: Train Loss=10.2086, Val Loss=3.6131
GPT2 Test CPC Loss: 5.2721
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0605, Val Loss=1.6458
Epoch [2/5]: Train Loss=0.8550, Val Loss=0.7960
Epoch [3/5]: Train Loss=0.2166, Val Loss=0.2199
Epoch [4/5]: Train Loss=0.0274, Val Loss=0.0685
Epoch [5/5]: Train Loss=0.0069, Val Loss=0.0519
LSTM Test CPC Loss: 0.0746
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.2277, Val Loss=15.6063
Epoch [2/5]: Train Loss=10.8197, Val Loss=8.7977
Epoch [3/5]: Train Loss=5.7006, Val Loss=5.4890
Epoch [4/5]: Train Loss=3.2622, Val Loss=3.7255
Epoch [5/5]: Train Loss=2.0130, Val Loss=2.8150
Reservoir Test CPC Loss: 2.7646
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8951, Val Loss=2.9891
Epoch [2/5]: Train Loss=4.6975, Val Loss=2.9895
Epoch [3/5]: Train Loss=3.8591, Val Loss=2.9910
Epoch [4/5]: Train Loss=3.3234, Val Loss=2.9923
Epoch [5/5]: Train Loss=3.1212, Val Loss=2.9931
BERT Test CPC Loss: 2.9931

--- Fish 10: Run 9 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=399.0528, Val Loss=4.1050
Epoch [2/5]: Train Loss=37.8657, Val Loss=2.0853
Epoch [3/5]: Train Loss=25.3660, Val Loss=1.6292
Epoch [4/5]: Train Loss=18.3253, Val Loss=1.5377
Epoch [5/5]: Train Loss=14.7463, Val Loss=1.4947
GPT2 Test CPC Loss: 1.5165
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7171, Val Loss=0.0916
Epoch [2/5]: Train Loss=0.0219, Val Loss=0.0065
Epoch [3/5]: Train Loss=0.0018, Val Loss=0.0040
Epoch [4/5]: Train Loss=0.0016, Val Loss=0.0045
Epoch [5/5]: Train Loss=0.0028, Val Loss=0.0014
LSTM Test CPC Loss: 0.0024
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.1083, Val Loss=6.1805
Epoch [2/5]: Train Loss=3.9865, Val Loss=3.6650
Epoch [3/5]: Train Loss=2.1993, Val Loss=2.5435
Epoch [4/5]: Train Loss=1.3351, Val Loss=1.9794
Epoch [5/5]: Train Loss=0.8487, Val Loss=1.6276
Reservoir Test CPC Loss: 1.7012
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4103, Val Loss=1.5574
Epoch [2/5]: Train Loss=4.7695, Val Loss=1.6315
Epoch [3/5]: Train Loss=3.7620, Val Loss=1.6475
Epoch [4/5]: Train Loss=3.0503, Val Loss=1.6016
Epoch [5/5]: Train Loss=2.5260, Val Loss=1.5190
BERT Test CPC Loss: 1.5385

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=409.5527, Val Loss=9.9299
Epoch [2/5]: Train Loss=26.0895, Val Loss=3.7358
Epoch [3/5]: Train Loss=18.4277, Val Loss=3.1911
Epoch [4/5]: Train Loss=14.6885, Val Loss=3.0293
Epoch [5/5]: Train Loss=12.1524, Val Loss=2.6656
GPT2 Test CPC Loss: 2.5732
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3060, Val Loss=0.5901
Epoch [2/5]: Train Loss=0.2428, Val Loss=0.1714
Epoch [3/5]: Train Loss=0.0348, Val Loss=0.0758
Epoch [4/5]: Train Loss=0.0079, Val Loss=0.0515
Epoch [5/5]: Train Loss=0.0034, Val Loss=0.0331
LSTM Test CPC Loss: 0.0561
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.4037, Val Loss=13.4190
Epoch [2/5]: Train Loss=9.2439, Val Loss=8.1199
Epoch [3/5]: Train Loss=5.0938, Val Loss=5.5583
Epoch [4/5]: Train Loss=3.0363, Val Loss=4.0436
Epoch [5/5]: Train Loss=1.9246, Val Loss=3.1537
Reservoir Test CPC Loss: 2.6884
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2598, Val Loss=2.2776
Epoch [2/5]: Train Loss=4.7848, Val Loss=2.2782
Epoch [3/5]: Train Loss=3.7578, Val Loss=2.2784
Epoch [4/5]: Train Loss=3.0162, Val Loss=2.2800
Epoch [5/5]: Train Loss=2.6266, Val Loss=2.2820
BERT Test CPC Loss: 2.2808

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=406.5847, Val Loss=3.1917
Epoch [2/5]: Train Loss=33.0773, Val Loss=2.7644
Epoch [3/5]: Train Loss=20.5592, Val Loss=2.6798
Epoch [4/5]: Train Loss=14.9785, Val Loss=2.6443
Epoch [5/5]: Train Loss=11.8132, Val Loss=2.6349
GPT2 Test CPC Loss: 2.6712
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5041, Val Loss=1.1085
Epoch [2/5]: Train Loss=0.3930, Val Loss=0.3567
Epoch [3/5]: Train Loss=0.0654, Val Loss=0.1335
Epoch [4/5]: Train Loss=0.0121, Val Loss=0.0893
Epoch [5/5]: Train Loss=0.0047, Val Loss=0.0598
LSTM Test CPC Loss: 0.0851
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.6988, Val Loss=15.2806
Epoch [2/5]: Train Loss=10.9359, Val Loss=9.2180
Epoch [3/5]: Train Loss=6.0064, Val Loss=6.1751
Epoch [4/5]: Train Loss=3.5762, Val Loss=4.4561
Epoch [5/5]: Train Loss=2.2531, Val Loss=3.3916
Reservoir Test CPC Loss: 2.9926
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8232, Val Loss=2.6982
Epoch [2/5]: Train Loss=4.6963, Val Loss=2.6994
Epoch [3/5]: Train Loss=3.8384, Val Loss=2.7003
Epoch [4/5]: Train Loss=3.3030, Val Loss=2.7009
Epoch [5/5]: Train Loss=2.9997, Val Loss=2.7014
BERT Test CPC Loss: 2.7009

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=475.3528, Val Loss=4.4807
Epoch [2/5]: Train Loss=28.4056, Val Loss=3.2115
Epoch [3/5]: Train Loss=18.2884, Val Loss=2.9982
Epoch [4/5]: Train Loss=12.8549, Val Loss=2.9473
Epoch [5/5]: Train Loss=10.4011, Val Loss=2.9266
GPT2 Test CPC Loss: 2.9697
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9494, Val Loss=1.5462
Epoch [2/5]: Train Loss=0.7781, Val Loss=0.6457
Epoch [3/5]: Train Loss=0.1812, Val Loss=0.1632
Epoch [4/5]: Train Loss=0.0257, Val Loss=0.0604
Epoch [5/5]: Train Loss=0.0073, Val Loss=0.0462
LSTM Test CPC Loss: 0.0777
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.1054, Val Loss=15.4933
Epoch [2/5]: Train Loss=10.1100, Val Loss=8.7302
Epoch [3/5]: Train Loss=5.3048, Val Loss=5.5255
Epoch [4/5]: Train Loss=3.0181, Val Loss=3.8320
Epoch [5/5]: Train Loss=1.8765, Val Loss=2.8646
Reservoir Test CPC Loss: 2.7270
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3119, Val Loss=2.9908
Epoch [2/5]: Train Loss=4.8470, Val Loss=2.9896
Epoch [3/5]: Train Loss=4.0582, Val Loss=2.9900
Epoch [4/5]: Train Loss=3.5859, Val Loss=2.9902
Epoch [5/5]: Train Loss=3.3149, Val Loss=2.9907
BERT Test CPC Loss: 2.9906

--- Fish 10: Run 10 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=405.4459, Val Loss=12.3814
Epoch [2/5]: Train Loss=33.9068, Val Loss=2.3856
Epoch [3/5]: Train Loss=21.3877, Val Loss=1.6029
Epoch [4/5]: Train Loss=15.5435, Val Loss=1.5011
Epoch [5/5]: Train Loss=12.2101, Val Loss=1.4596
GPT2 Test CPC Loss: 1.4928
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7578, Val Loss=0.1261
Epoch [2/5]: Train Loss=0.0201, Val Loss=0.0063
Epoch [3/5]: Train Loss=0.0017, Val Loss=0.0034
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0023
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0016
LSTM Test CPC Loss: 0.0033
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.7810, Val Loss=5.9092
Epoch [2/5]: Train Loss=3.7353, Val Loss=3.5870
Epoch [3/5]: Train Loss=2.0116, Val Loss=2.6325
Epoch [4/5]: Train Loss=1.2075, Val Loss=2.1266
Epoch [5/5]: Train Loss=0.7658, Val Loss=1.8139
Reservoir Test CPC Loss: 1.7915
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4166, Val Loss=1.5079
Epoch [2/5]: Train Loss=4.8954, Val Loss=1.5296
Epoch [3/5]: Train Loss=3.8847, Val Loss=1.5802
Epoch [4/5]: Train Loss=3.1192, Val Loss=1.5809
Epoch [5/5]: Train Loss=2.5772, Val Loss=1.5229
BERT Test CPC Loss: 1.5443

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=320.5384, Val Loss=2.8369
Epoch [2/5]: Train Loss=22.9841, Val Loss=2.2931
Epoch [3/5]: Train Loss=16.5803, Val Loss=2.3431
Epoch [4/5]: Train Loss=13.4166, Val Loss=2.2957
Epoch [5/5]: Train Loss=11.2493, Val Loss=2.2827
GPT2 Test CPC Loss: 2.3025
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1828, Val Loss=0.4302
Epoch [2/5]: Train Loss=0.1479, Val Loss=0.0592
Epoch [3/5]: Train Loss=0.0154, Val Loss=0.0410
Epoch [4/5]: Train Loss=0.0063, Val Loss=0.0200
Epoch [5/5]: Train Loss=0.0023, Val Loss=0.0105
LSTM Test CPC Loss: 0.0431
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.6965, Val Loss=12.6134
Epoch [2/5]: Train Loss=9.0005, Val Loss=7.7514
Epoch [3/5]: Train Loss=5.2535, Val Loss=5.2328
Epoch [4/5]: Train Loss=3.2454, Val Loss=3.7040
Epoch [5/5]: Train Loss=2.1105, Val Loss=2.7913
Reservoir Test CPC Loss: 2.9964
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1299, Val Loss=2.2871
Epoch [2/5]: Train Loss=4.7491, Val Loss=2.2885
Epoch [3/5]: Train Loss=3.7822, Val Loss=2.2879
Epoch [4/5]: Train Loss=3.0700, Val Loss=2.2870
Epoch [5/5]: Train Loss=2.6386, Val Loss=2.2878
BERT Test CPC Loss: 2.2867

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=375.1638, Val Loss=3.1371
Epoch [2/5]: Train Loss=28.2911, Val Loss=2.7577
Epoch [3/5]: Train Loss=18.0824, Val Loss=2.6720
Epoch [4/5]: Train Loss=13.8618, Val Loss=2.6512
Epoch [5/5]: Train Loss=11.0945, Val Loss=2.6461
GPT2 Test CPC Loss: 2.6689
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8676, Val Loss=1.2277
Epoch [2/5]: Train Loss=0.5612, Val Loss=0.3559
Epoch [3/5]: Train Loss=0.0821, Val Loss=0.1030
Epoch [4/5]: Train Loss=0.0126, Val Loss=0.0444
Epoch [5/5]: Train Loss=0.0046, Val Loss=0.0382
LSTM Test CPC Loss: 0.0600
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.4591, Val Loss=15.6848
Epoch [2/5]: Train Loss=10.1946, Val Loss=9.5586
Epoch [3/5]: Train Loss=5.7650, Val Loss=6.3852
Epoch [4/5]: Train Loss=3.4773, Val Loss=4.5605
Epoch [5/5]: Train Loss=2.2169, Val Loss=3.4400
Reservoir Test CPC Loss: 3.6233
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8412, Val Loss=2.6971
Epoch [2/5]: Train Loss=4.6799, Val Loss=2.6982
Epoch [3/5]: Train Loss=3.8093, Val Loss=2.6994
Epoch [4/5]: Train Loss=3.2491, Val Loss=2.7002
Epoch [5/5]: Train Loss=2.9658, Val Loss=2.7009
BERT Test CPC Loss: 2.7006

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=482.6710, Val Loss=3.7786
Epoch [2/5]: Train Loss=35.3821, Val Loss=3.0001
Epoch [3/5]: Train Loss=22.6547, Val Loss=2.9349
Epoch [4/5]: Train Loss=16.3598, Val Loss=2.9235
Epoch [5/5]: Train Loss=12.7702, Val Loss=2.9213
GPT2 Test CPC Loss: 2.9590
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1291, Val Loss=1.6328
Epoch [2/5]: Train Loss=0.8052, Val Loss=0.5435
Epoch [3/5]: Train Loss=0.1514, Val Loss=0.1200
Epoch [4/5]: Train Loss=0.0162, Val Loss=0.0586
Epoch [5/5]: Train Loss=0.0051, Val Loss=0.0515
LSTM Test CPC Loss: 0.0703
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.7274, Val Loss=16.6340
Epoch [2/5]: Train Loss=11.0495, Val Loss=9.7535
Epoch [3/5]: Train Loss=5.8644, Val Loss=6.3505
Epoch [4/5]: Train Loss=3.3805, Val Loss=4.4478
Epoch [5/5]: Train Loss=2.1078, Val Loss=3.3968
Reservoir Test CPC Loss: 3.1849
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0784, Val Loss=2.9868
Epoch [2/5]: Train Loss=4.7486, Val Loss=2.9859
Epoch [3/5]: Train Loss=3.9448, Val Loss=2.9870
Epoch [4/5]: Train Loss=3.5015, Val Loss=2.9874
Epoch [5/5]: Train Loss=3.2806, Val Loss=2.9882
BERT Test CPC Loss: 2.9881

========== Processing Fish 11 ==========
Fish 11: Neural data shape: (2798, 14015)

--- Fish 11: Run 1 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=457.1884, Val Loss=3.2966
Epoch [2/5]: Train Loss=34.0028, Val Loss=1.7661
Epoch [3/5]: Train Loss=22.0975, Val Loss=1.5292
Epoch [4/5]: Train Loss=17.1081, Val Loss=1.4631
Epoch [5/5]: Train Loss=13.3023, Val Loss=1.4781
GPT2 Test CPC Loss: 1.4865
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5748, Val Loss=0.0373
Epoch [2/5]: Train Loss=0.0077, Val Loss=0.0042
Epoch [3/5]: Train Loss=0.0019, Val Loss=0.0240
Epoch [4/5]: Train Loss=0.0069, Val Loss=0.0117
Epoch [5/5]: Train Loss=0.0089, Val Loss=0.0018
LSTM Test CPC Loss: 0.0038
[Model: Reservoir]
Epoch [1/5]: Train Loss=5.7272, Val Loss=2.7956
Epoch [2/5]: Train Loss=1.0588, Val Loss=1.6148
Epoch [3/5]: Train Loss=0.4837, Val Loss=1.1871
Epoch [4/5]: Train Loss=0.2619, Val Loss=0.9896
Epoch [5/5]: Train Loss=0.1403, Val Loss=0.8338
Reservoir Test CPC Loss: 1.0625
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1879, Val Loss=1.5001
Epoch [2/5]: Train Loss=4.9420, Val Loss=1.5119
Epoch [3/5]: Train Loss=3.9355, Val Loss=1.5281
Epoch [4/5]: Train Loss=3.1502, Val Loss=1.5210
Epoch [5/5]: Train Loss=2.5191, Val Loss=1.4957
BERT Test CPC Loss: 1.4996

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=485.0320, Val Loss=4.2656
Epoch [2/5]: Train Loss=26.4346, Val Loss=2.8941
Epoch [3/5]: Train Loss=19.0655, Val Loss=2.5230
Epoch [4/5]: Train Loss=14.9136, Val Loss=2.3374
Epoch [5/5]: Train Loss=11.7531, Val Loss=2.1236
GPT2 Test CPC Loss: 2.6024
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2660, Val Loss=0.4155
Epoch [2/5]: Train Loss=0.1570, Val Loss=0.0710
Epoch [3/5]: Train Loss=0.0158, Val Loss=0.0148
Epoch [4/5]: Train Loss=0.0049, Val Loss=0.0113
Epoch [5/5]: Train Loss=0.0058, Val Loss=0.0104
LSTM Test CPC Loss: 0.0343
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.8011, Val Loss=9.3336
Epoch [2/5]: Train Loss=6.6156, Val Loss=5.1195
Epoch [3/5]: Train Loss=3.6886, Val Loss=3.2937
Epoch [4/5]: Train Loss=2.2708, Val Loss=2.3087
Epoch [5/5]: Train Loss=1.5055, Val Loss=1.7812
Reservoir Test CPC Loss: 2.6949
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7055, Val Loss=2.2844
Epoch [2/5]: Train Loss=4.6882, Val Loss=2.2836
Epoch [3/5]: Train Loss=3.7620, Val Loss=2.2857
Epoch [4/5]: Train Loss=3.0400, Val Loss=2.2871
Epoch [5/5]: Train Loss=2.6174, Val Loss=2.2888
BERT Test CPC Loss: 2.2882

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=467.8124, Val Loss=6.6632
Epoch [2/5]: Train Loss=34.8047, Val Loss=2.9904
Epoch [3/5]: Train Loss=19.6958, Val Loss=2.7131
Epoch [4/5]: Train Loss=14.1380, Val Loss=2.6580
Epoch [5/5]: Train Loss=11.3831, Val Loss=2.6437
GPT2 Test CPC Loss: 2.6414
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5537, Val Loss=0.7381
Epoch [2/5]: Train Loss=0.3362, Val Loss=0.1617
Epoch [3/5]: Train Loss=0.0481, Val Loss=0.0834
Epoch [4/5]: Train Loss=0.0113, Val Loss=0.0408
Epoch [5/5]: Train Loss=0.0044, Val Loss=0.0187
LSTM Test CPC Loss: 0.0440
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.7450, Val Loss=13.0276
Epoch [2/5]: Train Loss=8.3174, Val Loss=7.2234
Epoch [3/5]: Train Loss=4.4745, Val Loss=4.6293
Epoch [4/5]: Train Loss=2.6814, Val Loss=3.2409
Epoch [5/5]: Train Loss=1.7401, Val Loss=2.5184
Reservoir Test CPC Loss: 2.9688
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6846, Val Loss=2.6989
Epoch [2/5]: Train Loss=4.7076, Val Loss=2.7000
Epoch [3/5]: Train Loss=3.8353, Val Loss=2.7011
Epoch [4/5]: Train Loss=3.2820, Val Loss=2.7023
Epoch [5/5]: Train Loss=2.9874, Val Loss=2.7026
BERT Test CPC Loss: 2.7023

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=388.6573, Val Loss=3.0544
Epoch [2/5]: Train Loss=25.0914, Val Loss=2.9173
Epoch [3/5]: Train Loss=17.9009, Val Loss=2.9198
Epoch [4/5]: Train Loss=14.0611, Val Loss=2.9221
Epoch [5/5]: Train Loss=11.9135, Val Loss=2.9287
GPT2 Test CPC Loss: 2.9147
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9669, Val Loss=1.3375
Epoch [2/5]: Train Loss=0.6761, Val Loss=0.3990
Epoch [3/5]: Train Loss=0.1455, Val Loss=0.1028
Epoch [4/5]: Train Loss=0.0218, Val Loss=0.0424
Epoch [5/5]: Train Loss=0.0068, Val Loss=0.0307
LSTM Test CPC Loss: 0.0943
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.0326, Val Loss=12.5243
Epoch [2/5]: Train Loss=8.5914, Val Loss=6.5131
Epoch [3/5]: Train Loss=4.4911, Val Loss=3.9208
Epoch [4/5]: Train Loss=2.6267, Val Loss=2.6776
Epoch [5/5]: Train Loss=1.6705, Val Loss=1.9278
Reservoir Test CPC Loss: 2.5025
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5650, Val Loss=2.9902
Epoch [2/5]: Train Loss=4.7214, Val Loss=2.9902
Epoch [3/5]: Train Loss=3.9111, Val Loss=2.9903
Epoch [4/5]: Train Loss=3.4287, Val Loss=2.9907
Epoch [5/5]: Train Loss=3.2017, Val Loss=2.9913
BERT Test CPC Loss: 2.9912

--- Fish 11: Run 2 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=477.9932, Val Loss=11.3021
Epoch [2/5]: Train Loss=31.3213, Val Loss=12.4153
Epoch [3/5]: Train Loss=18.1330, Val Loss=13.0256
Epoch [4/5]: Train Loss=13.4920, Val Loss=9.7820
Epoch [5/5]: Train Loss=10.2986, Val Loss=9.6466
GPT2 Test CPC Loss: 10.1128
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6400, Val Loss=0.0287
Epoch [2/5]: Train Loss=0.0126, Val Loss=0.0018
Epoch [3/5]: Train Loss=0.0069, Val Loss=0.0011
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0010
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0004
LSTM Test CPC Loss: 0.0027
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.7087, Val Loss=3.6713
Epoch [2/5]: Train Loss=2.5003, Val Loss=2.1020
Epoch [3/5]: Train Loss=1.2501, Val Loss=1.4768
Epoch [4/5]: Train Loss=0.7313, Val Loss=1.1614
Epoch [5/5]: Train Loss=0.4609, Val Loss=0.9770
Reservoir Test CPC Loss: 1.1932
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7056, Val Loss=1.5223
Epoch [2/5]: Train Loss=4.8446, Val Loss=1.5361
Epoch [3/5]: Train Loss=3.8530, Val Loss=1.5771
Epoch [4/5]: Train Loss=3.0992, Val Loss=1.5667
Epoch [5/5]: Train Loss=2.5319, Val Loss=1.5158
BERT Test CPC Loss: 1.5215

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=334.7350, Val Loss=3.1511
Epoch [2/5]: Train Loss=19.2363, Val Loss=2.3447
Epoch [3/5]: Train Loss=13.7600, Val Loss=2.6448
Epoch [4/5]: Train Loss=10.9964, Val Loss=2.6032
Epoch [5/5]: Train Loss=9.1653, Val Loss=2.4691
GPT2 Test CPC Loss: 2.4484
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3700, Val Loss=0.6040
Epoch [2/5]: Train Loss=0.1924, Val Loss=0.0957
Epoch [3/5]: Train Loss=0.0278, Val Loss=0.0560
Epoch [4/5]: Train Loss=0.0083, Val Loss=0.0358
Epoch [5/5]: Train Loss=0.0045, Val Loss=0.0247
LSTM Test CPC Loss: 0.0303
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.2767, Val Loss=8.9911
Epoch [2/5]: Train Loss=6.8343, Val Loss=5.1903
Epoch [3/5]: Train Loss=3.8844, Val Loss=3.4744
Epoch [4/5]: Train Loss=2.4369, Val Loss=2.5640
Epoch [5/5]: Train Loss=1.6141, Val Loss=2.0091
Reservoir Test CPC Loss: 2.4620
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3094, Val Loss=2.2817
Epoch [2/5]: Train Loss=4.8496, Val Loss=2.2845
Epoch [3/5]: Train Loss=3.9252, Val Loss=2.2853
Epoch [4/5]: Train Loss=3.2395, Val Loss=2.2865
Epoch [5/5]: Train Loss=2.7500, Val Loss=2.2893
BERT Test CPC Loss: 2.2888

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=440.2799, Val Loss=2.6329
Epoch [2/5]: Train Loss=26.3752, Val Loss=2.6530
Epoch [3/5]: Train Loss=17.1071, Val Loss=2.6498
Epoch [4/5]: Train Loss=12.9525, Val Loss=2.6479
Epoch [5/5]: Train Loss=10.4150, Val Loss=2.6516
GPT2 Test CPC Loss: 2.6434
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6260, Val Loss=0.8307
Epoch [2/5]: Train Loss=0.3894, Val Loss=0.1605
Epoch [3/5]: Train Loss=0.0554, Val Loss=0.0260
Epoch [4/5]: Train Loss=0.0141, Val Loss=0.0206
Epoch [5/5]: Train Loss=0.0050, Val Loss=0.0154
LSTM Test CPC Loss: 0.0562
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.5795, Val Loss=10.3742
Epoch [2/5]: Train Loss=7.4211, Val Loss=6.1106
Epoch [3/5]: Train Loss=4.2421, Val Loss=3.9255
Epoch [4/5]: Train Loss=2.6314, Val Loss=2.7470
Epoch [5/5]: Train Loss=1.7238, Val Loss=2.0652
Reservoir Test CPC Loss: 2.4173
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4244, Val Loss=2.6955
Epoch [2/5]: Train Loss=4.6768, Val Loss=2.6985
Epoch [3/5]: Train Loss=3.7929, Val Loss=2.6998
Epoch [4/5]: Train Loss=3.2322, Val Loss=2.7012
Epoch [5/5]: Train Loss=2.9582, Val Loss=2.7018
BERT Test CPC Loss: 2.7016

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=415.7812, Val Loss=3.7754
Epoch [2/5]: Train Loss=22.6308, Val Loss=3.0378
Epoch [3/5]: Train Loss=15.8317, Val Loss=2.9851
Epoch [4/5]: Train Loss=12.4880, Val Loss=2.9855
Epoch [5/5]: Train Loss=10.1855, Val Loss=2.9488
GPT2 Test CPC Loss: 2.9374
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7950, Val Loss=1.0849
Epoch [2/5]: Train Loss=0.5692, Val Loss=0.4054
Epoch [3/5]: Train Loss=0.1091, Val Loss=0.1349
Epoch [4/5]: Train Loss=0.0198, Val Loss=0.0564
Epoch [5/5]: Train Loss=0.0058, Val Loss=0.0312
LSTM Test CPC Loss: 0.0704
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.6828, Val Loss=11.5714
Epoch [2/5]: Train Loss=9.1340, Val Loss=6.4797
Epoch [3/5]: Train Loss=5.0226, Val Loss=4.1887
Epoch [4/5]: Train Loss=3.0250, Val Loss=2.9295
Epoch [5/5]: Train Loss=1.9672, Val Loss=2.1456
Reservoir Test CPC Loss: 2.8586
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8357, Val Loss=2.9907
Epoch [2/5]: Train Loss=4.7669, Val Loss=2.9914
Epoch [3/5]: Train Loss=3.9547, Val Loss=2.9927
Epoch [4/5]: Train Loss=3.4185, Val Loss=2.9932
Epoch [5/5]: Train Loss=3.1689, Val Loss=2.9936
BERT Test CPC Loss: 2.9935

--- Fish 11: Run 3 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=388.8511, Val Loss=1.7886
Epoch [2/5]: Train Loss=29.6076, Val Loss=1.5514
Epoch [3/5]: Train Loss=20.1856, Val Loss=1.4786
Epoch [4/5]: Train Loss=14.1475, Val Loss=1.4552
Epoch [5/5]: Train Loss=11.5305, Val Loss=1.4426
GPT2 Test CPC Loss: 1.4445
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6335, Val Loss=0.0306
Epoch [2/5]: Train Loss=0.0070, Val Loss=0.0011
Epoch [3/5]: Train Loss=0.0009, Val Loss=0.0007
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0004
Epoch [5/5]: Train Loss=0.0012, Val Loss=0.0021
LSTM Test CPC Loss: 0.0093
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.5520, Val Loss=1.6844
Epoch [2/5]: Train Loss=1.2648, Val Loss=0.8439
Epoch [3/5]: Train Loss=0.6337, Val Loss=0.6021
Epoch [4/5]: Train Loss=0.3825, Val Loss=0.4768
Epoch [5/5]: Train Loss=0.2516, Val Loss=0.4302
Reservoir Test CPC Loss: 0.8484
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3240, Val Loss=1.5149
Epoch [2/5]: Train Loss=4.9442, Val Loss=1.5475
Epoch [3/5]: Train Loss=3.9285, Val Loss=1.5721
Epoch [4/5]: Train Loss=3.2123, Val Loss=1.5712
Epoch [5/5]: Train Loss=2.6407, Val Loss=1.5167
BERT Test CPC Loss: 1.5232

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=427.1432, Val Loss=3.1251
Epoch [2/5]: Train Loss=24.6268, Val Loss=2.3946
Epoch [3/5]: Train Loss=18.7832, Val Loss=2.3104
Epoch [4/5]: Train Loss=15.4549, Val Loss=2.3083
Epoch [5/5]: Train Loss=13.1207, Val Loss=2.2744
GPT2 Test CPC Loss: 2.2864
[Model: LSTM]
Epoch [1/5]: Train Loss=1.0700, Val Loss=0.2408
Epoch [2/5]: Train Loss=0.0874, Val Loss=0.0334
Epoch [3/5]: Train Loss=0.0087, Val Loss=0.0130
Epoch [4/5]: Train Loss=0.0039, Val Loss=0.0065
Epoch [5/5]: Train Loss=0.0064, Val Loss=0.0106
LSTM Test CPC Loss: 0.0547
[Model: Reservoir]
Epoch [1/5]: Train Loss=13.5801, Val Loss=8.2925
Epoch [2/5]: Train Loss=5.6096, Val Loss=4.9128
Epoch [3/5]: Train Loss=3.1732, Val Loss=3.4148
Epoch [4/5]: Train Loss=1.9609, Val Loss=2.5637
Epoch [5/5]: Train Loss=1.3034, Val Loss=2.0513
Reservoir Test CPC Loss: 2.1913
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9649, Val Loss=2.2821
Epoch [2/5]: Train Loss=4.7964, Val Loss=2.2849
Epoch [3/5]: Train Loss=3.8438, Val Loss=2.2879
Epoch [4/5]: Train Loss=3.1300, Val Loss=2.2889
Epoch [5/5]: Train Loss=2.6750, Val Loss=2.2907
BERT Test CPC Loss: 2.2903

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=469.4584, Val Loss=3.0116
Epoch [2/5]: Train Loss=35.5063, Val Loss=2.6959
Epoch [3/5]: Train Loss=20.9284, Val Loss=2.6689
Epoch [4/5]: Train Loss=14.8989, Val Loss=2.6486
Epoch [5/5]: Train Loss=11.6661, Val Loss=2.6317
GPT2 Test CPC Loss: 2.6291
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7943, Val Loss=0.9139
Epoch [2/5]: Train Loss=0.4843, Val Loss=0.1898
Epoch [3/5]: Train Loss=0.0568, Val Loss=0.0299
Epoch [4/5]: Train Loss=0.0093, Val Loss=0.0150
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0115
LSTM Test CPC Loss: 0.0714
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.2872, Val Loss=8.4181
Epoch [2/5]: Train Loss=7.1246, Val Loss=4.6276
Epoch [3/5]: Train Loss=4.0247, Val Loss=3.0726
Epoch [4/5]: Train Loss=2.4738, Val Loss=2.1106
Epoch [5/5]: Train Loss=1.6126, Val Loss=1.5896
Reservoir Test CPC Loss: 2.3609
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8585, Val Loss=2.6978
Epoch [2/5]: Train Loss=4.7213, Val Loss=2.6997
Epoch [3/5]: Train Loss=3.8239, Val Loss=2.7013
Epoch [4/5]: Train Loss=3.2391, Val Loss=2.7021
Epoch [5/5]: Train Loss=2.9374, Val Loss=2.7025
BERT Test CPC Loss: 2.7023

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=364.3960, Val Loss=3.1604
Epoch [2/5]: Train Loss=26.3658, Val Loss=2.9553
Epoch [3/5]: Train Loss=18.5750, Val Loss=2.9979
Epoch [4/5]: Train Loss=14.5562, Val Loss=3.0441
Epoch [5/5]: Train Loss=11.9720, Val Loss=3.0355
GPT2 Test CPC Loss: 3.0142
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0989, Val Loss=1.3662
Epoch [2/5]: Train Loss=0.7851, Val Loss=0.4559
Epoch [3/5]: Train Loss=0.1790, Val Loss=0.0805
Epoch [4/5]: Train Loss=0.0216, Val Loss=0.0220
Epoch [5/5]: Train Loss=0.0062, Val Loss=0.0200
LSTM Test CPC Loss: 0.1019
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.8151, Val Loss=14.1526
Epoch [2/5]: Train Loss=9.5123, Val Loss=7.3947
Epoch [3/5]: Train Loss=4.9291, Val Loss=4.2793
Epoch [4/5]: Train Loss=2.8457, Val Loss=2.7808
Epoch [5/5]: Train Loss=1.7947, Val Loss=1.9849
Reservoir Test CPC Loss: 2.6253
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9143, Val Loss=2.9894
Epoch [2/5]: Train Loss=4.7892, Val Loss=2.9905
Epoch [3/5]: Train Loss=3.9821, Val Loss=2.9915
Epoch [4/5]: Train Loss=3.4813, Val Loss=2.9921
Epoch [5/5]: Train Loss=3.2129, Val Loss=2.9926
BERT Test CPC Loss: 2.9925

--- Fish 11: Run 4 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=484.0335, Val Loss=9.6149
Epoch [2/5]: Train Loss=32.7490, Val Loss=5.3892
Epoch [3/5]: Train Loss=21.3008, Val Loss=3.0207
Epoch [4/5]: Train Loss=15.2416, Val Loss=2.1596
Epoch [5/5]: Train Loss=11.3206, Val Loss=2.1084
GPT2 Test CPC Loss: 2.5264
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6124, Val Loss=0.0212
Epoch [2/5]: Train Loss=0.0071, Val Loss=0.0029
Epoch [3/5]: Train Loss=0.0044, Val Loss=0.0110
Epoch [4/5]: Train Loss=0.0021, Val Loss=0.0010
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0010
LSTM Test CPC Loss: 0.0025
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.7345, Val Loss=2.9848
Epoch [2/5]: Train Loss=1.8484, Val Loss=1.7576
Epoch [3/5]: Train Loss=0.9689, Val Loss=1.3159
Epoch [4/5]: Train Loss=0.5853, Val Loss=1.0636
Epoch [5/5]: Train Loss=0.3961, Val Loss=0.9249
Reservoir Test CPC Loss: 0.9594
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3049, Val Loss=1.5213
Epoch [2/5]: Train Loss=4.9213, Val Loss=1.5627
Epoch [3/5]: Train Loss=3.8644, Val Loss=1.6058
Epoch [4/5]: Train Loss=3.0927, Val Loss=1.5643
Epoch [5/5]: Train Loss=2.5055, Val Loss=1.4941
BERT Test CPC Loss: 1.5010

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=418.1471, Val Loss=6.3929
Epoch [2/5]: Train Loss=23.7757, Val Loss=2.9216
Epoch [3/5]: Train Loss=17.1273, Val Loss=2.9350
Epoch [4/5]: Train Loss=13.7963, Val Loss=2.6807
Epoch [5/5]: Train Loss=11.6241, Val Loss=2.6775
GPT2 Test CPC Loss: 2.6880
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1585, Val Loss=0.4349
Epoch [2/5]: Train Loss=0.1184, Val Loss=0.0824
Epoch [3/5]: Train Loss=0.0153, Val Loss=0.0121
Epoch [4/5]: Train Loss=0.0043, Val Loss=0.0121
Epoch [5/5]: Train Loss=0.0057, Val Loss=0.0228
LSTM Test CPC Loss: 0.0441
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.2769, Val Loss=9.0918
Epoch [2/5]: Train Loss=7.0451, Val Loss=5.3913
Epoch [3/5]: Train Loss=3.9711, Val Loss=3.6517
Epoch [4/5]: Train Loss=2.4682, Val Loss=2.7186
Epoch [5/5]: Train Loss=1.6377, Val Loss=2.1293
Reservoir Test CPC Loss: 2.7097
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7732, Val Loss=2.2843
Epoch [2/5]: Train Loss=4.7009, Val Loss=2.2853
Epoch [3/5]: Train Loss=3.7535, Val Loss=2.2861
Epoch [4/5]: Train Loss=3.0584, Val Loss=2.2869
Epoch [5/5]: Train Loss=2.6556, Val Loss=2.2888
BERT Test CPC Loss: 2.2882

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=432.0063, Val Loss=2.7262
Epoch [2/5]: Train Loss=27.6489, Val Loss=2.6307
Epoch [3/5]: Train Loss=19.7084, Val Loss=2.6207
Epoch [4/5]: Train Loss=15.6178, Val Loss=2.6449
Epoch [5/5]: Train Loss=13.2193, Val Loss=2.6433
GPT2 Test CPC Loss: 2.6323
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8125, Val Loss=0.9008
Epoch [2/5]: Train Loss=0.4853, Val Loss=0.2750
Epoch [3/5]: Train Loss=0.0811, Val Loss=0.0506
Epoch [4/5]: Train Loss=0.0138, Val Loss=0.0296
Epoch [5/5]: Train Loss=0.0065, Val Loss=0.0193
LSTM Test CPC Loss: 0.0659
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.6537, Val Loss=11.3862
Epoch [2/5]: Train Loss=8.3388, Val Loss=6.6325
Epoch [3/5]: Train Loss=4.7724, Val Loss=4.1993
Epoch [4/5]: Train Loss=2.9563, Val Loss=2.8791
Epoch [5/5]: Train Loss=1.9444, Val Loss=2.1600
Reservoir Test CPC Loss: 2.9874
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7487, Val Loss=2.6958
Epoch [2/5]: Train Loss=4.7013, Val Loss=2.6973
Epoch [3/5]: Train Loss=3.8162, Val Loss=2.6988
Epoch [4/5]: Train Loss=3.2613, Val Loss=2.6995
Epoch [5/5]: Train Loss=2.9706, Val Loss=2.7005
BERT Test CPC Loss: 2.7004

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=406.7234, Val Loss=2.8825
Epoch [2/5]: Train Loss=20.4889, Val Loss=2.8871
Epoch [3/5]: Train Loss=15.1099, Val Loss=2.8945
Epoch [4/5]: Train Loss=12.3581, Val Loss=2.9013
Epoch [5/5]: Train Loss=10.6673, Val Loss=2.9210
GPT2 Test CPC Loss: 2.9041
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1090, Val Loss=1.4197
Epoch [2/5]: Train Loss=0.8809, Val Loss=0.7284
Epoch [3/5]: Train Loss=0.2731, Val Loss=0.2282
Epoch [4/5]: Train Loss=0.0516, Val Loss=0.0611
Epoch [5/5]: Train Loss=0.0128, Val Loss=0.0396
LSTM Test CPC Loss: 0.0915
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.6098, Val Loss=12.9826
Epoch [2/5]: Train Loss=9.0544, Val Loss=7.2897
Epoch [3/5]: Train Loss=5.0874, Val Loss=4.6474
Epoch [4/5]: Train Loss=3.1207, Val Loss=3.1794
Epoch [5/5]: Train Loss=2.0381, Val Loss=2.2981
Reservoir Test CPC Loss: 2.9483
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9657, Val Loss=2.9902
Epoch [2/5]: Train Loss=4.8064, Val Loss=2.9918
Epoch [3/5]: Train Loss=4.0274, Val Loss=2.9923
Epoch [4/5]: Train Loss=3.5365, Val Loss=2.9923
Epoch [5/5]: Train Loss=3.2571, Val Loss=2.9927
BERT Test CPC Loss: 2.9926

--- Fish 11: Run 5 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=577.6781, Val Loss=4.9111
Epoch [2/5]: Train Loss=40.4968, Val Loss=1.6172
Epoch [3/5]: Train Loss=24.9633, Val Loss=1.6497
Epoch [4/5]: Train Loss=18.0053, Val Loss=1.7617
Epoch [5/5]: Train Loss=14.2159, Val Loss=1.7060
GPT2 Test CPC Loss: 1.7681
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5706, Val Loss=0.0309
Epoch [2/5]: Train Loss=0.0089, Val Loss=0.0030
Epoch [3/5]: Train Loss=0.0008, Val Loss=0.0010
Epoch [4/5]: Train Loss=0.0039, Val Loss=0.0041
Epoch [5/5]: Train Loss=0.0054, Val Loss=0.0014
LSTM Test CPC Loss: 0.0053
[Model: Reservoir]
Epoch [1/5]: Train Loss=6.3509, Val Loss=1.9136
Epoch [2/5]: Train Loss=1.2706, Val Loss=1.0341
Epoch [3/5]: Train Loss=0.6425, Val Loss=0.7477
Epoch [4/5]: Train Loss=0.3727, Val Loss=0.6194
Epoch [5/5]: Train Loss=0.2165, Val Loss=0.5349
Reservoir Test CPC Loss: 0.6872
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1443, Val Loss=1.5225
Epoch [2/5]: Train Loss=4.9393, Val Loss=1.5487
Epoch [3/5]: Train Loss=3.9251, Val Loss=1.5769
Epoch [4/5]: Train Loss=3.2264, Val Loss=1.5808
Epoch [5/5]: Train Loss=2.6799, Val Loss=1.5163
BERT Test CPC Loss: 1.5249

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=433.2058, Val Loss=5.4744
Epoch [2/5]: Train Loss=29.1499, Val Loss=3.8326
Epoch [3/5]: Train Loss=20.7138, Val Loss=3.3146
Epoch [4/5]: Train Loss=16.5340, Val Loss=3.0353
Epoch [5/5]: Train Loss=13.3864, Val Loss=2.8441
GPT2 Test CPC Loss: 2.8191
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3532, Val Loss=0.4595
Epoch [2/5]: Train Loss=0.1851, Val Loss=0.0428
Epoch [3/5]: Train Loss=0.0154, Val Loss=0.0097
Epoch [4/5]: Train Loss=0.0068, Val Loss=0.0050
Epoch [5/5]: Train Loss=0.0040, Val Loss=0.0061
LSTM Test CPC Loss: 0.0261
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.2158, Val Loss=10.4705
Epoch [2/5]: Train Loss=7.0106, Val Loss=6.1485
Epoch [3/5]: Train Loss=4.0095, Val Loss=4.1281
Epoch [4/5]: Train Loss=2.5369, Val Loss=3.0504
Epoch [5/5]: Train Loss=1.6894, Val Loss=2.3895
Reservoir Test CPC Loss: 2.8371
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0863, Val Loss=2.2717
Epoch [2/5]: Train Loss=4.8287, Val Loss=2.2713
Epoch [3/5]: Train Loss=3.8697, Val Loss=2.2720
Epoch [4/5]: Train Loss=3.2154, Val Loss=2.2726
Epoch [5/5]: Train Loss=2.7797, Val Loss=2.2732
BERT Test CPC Loss: 2.2724

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=349.0006, Val Loss=2.6964
Epoch [2/5]: Train Loss=18.6129, Val Loss=2.6679
Epoch [3/5]: Train Loss=13.2581, Val Loss=2.6591
Epoch [4/5]: Train Loss=10.6890, Val Loss=2.6668
Epoch [5/5]: Train Loss=9.0863, Val Loss=2.6653
GPT2 Test CPC Loss: 2.6664
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6884, Val Loss=0.8482
Epoch [2/5]: Train Loss=0.4316, Val Loss=0.2557
Epoch [3/5]: Train Loss=0.0622, Val Loss=0.0919
Epoch [4/5]: Train Loss=0.0101, Val Loss=0.0601
Epoch [5/5]: Train Loss=0.0037, Val Loss=0.0336
LSTM Test CPC Loss: 0.0427
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.9560, Val Loss=12.8970
Epoch [2/5]: Train Loss=8.6565, Val Loss=7.4893
Epoch [3/5]: Train Loss=4.9056, Val Loss=4.9210
Epoch [4/5]: Train Loss=3.0432, Val Loss=3.5555
Epoch [5/5]: Train Loss=2.0167, Val Loss=2.6759
Reservoir Test CPC Loss: 2.7992
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3979, Val Loss=2.7018
Epoch [2/5]: Train Loss=4.8426, Val Loss=2.7008
Epoch [3/5]: Train Loss=3.9807, Val Loss=2.7013
Epoch [4/5]: Train Loss=3.4116, Val Loss=2.7014
Epoch [5/5]: Train Loss=3.0542, Val Loss=2.7024
BERT Test CPC Loss: 2.7023

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=464.3635, Val Loss=4.8982
Epoch [2/5]: Train Loss=37.1180, Val Loss=4.0516
Epoch [3/5]: Train Loss=25.4939, Val Loss=3.2650
Epoch [4/5]: Train Loss=20.1023, Val Loss=3.0999
Epoch [5/5]: Train Loss=16.4293, Val Loss=3.0250
GPT2 Test CPC Loss: 3.0085
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7416, Val Loss=1.0073
Epoch [2/5]: Train Loss=0.5142, Val Loss=0.2250
Epoch [3/5]: Train Loss=0.0731, Val Loss=0.0343
Epoch [4/5]: Train Loss=0.0108, Val Loss=0.0144
Epoch [5/5]: Train Loss=0.0039, Val Loss=0.0076
LSTM Test CPC Loss: 0.0475
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.2115, Val Loss=10.7195
Epoch [2/5]: Train Loss=7.8642, Val Loss=6.0961
Epoch [3/5]: Train Loss=4.4050, Val Loss=3.8979
Epoch [4/5]: Train Loss=2.7050, Val Loss=2.6819
Epoch [5/5]: Train Loss=1.7822, Val Loss=1.9858
Reservoir Test CPC Loss: 2.4399
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5945, Val Loss=2.9893
Epoch [2/5]: Train Loss=4.7313, Val Loss=2.9908
Epoch [3/5]: Train Loss=3.9705, Val Loss=2.9913
Epoch [4/5]: Train Loss=3.5313, Val Loss=2.9918
Epoch [5/5]: Train Loss=3.2802, Val Loss=2.9922
BERT Test CPC Loss: 2.9920

--- Fish 11: Run 6 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=408.8483, Val Loss=1.4147
Epoch [2/5]: Train Loss=29.4093, Val Loss=1.4247
Epoch [3/5]: Train Loss=18.1440, Val Loss=1.4171
Epoch [4/5]: Train Loss=13.6147, Val Loss=1.4177
Epoch [5/5]: Train Loss=10.7969, Val Loss=1.4134
GPT2 Test CPC Loss: 1.4153
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5609, Val Loss=0.0180
Epoch [2/5]: Train Loss=0.0085, Val Loss=0.0052
Epoch [3/5]: Train Loss=0.0059, Val Loss=0.0062
Epoch [4/5]: Train Loss=0.0035, Val Loss=0.0005
Epoch [5/5]: Train Loss=0.0002, Val Loss=0.0001
LSTM Test CPC Loss: 0.0005
[Model: Reservoir]
Epoch [1/5]: Train Loss=6.5671, Val Loss=2.2545
Epoch [2/5]: Train Loss=1.2971, Val Loss=1.1609
Epoch [3/5]: Train Loss=0.6145, Val Loss=0.8059
Epoch [4/5]: Train Loss=0.3457, Val Loss=0.6179
Epoch [5/5]: Train Loss=0.2100, Val Loss=0.5348
Reservoir Test CPC Loss: 0.8470
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4314, Val Loss=1.5135
Epoch [2/5]: Train Loss=4.7999, Val Loss=1.5409
Epoch [3/5]: Train Loss=3.8207, Val Loss=1.5524
Epoch [4/5]: Train Loss=3.0856, Val Loss=1.5524
Epoch [5/5]: Train Loss=2.5393, Val Loss=1.4987
BERT Test CPC Loss: 1.5063

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=639.4255, Val Loss=14.8988
Epoch [2/5]: Train Loss=48.0489, Val Loss=5.2634
Epoch [3/5]: Train Loss=29.2728, Val Loss=3.1101
Epoch [4/5]: Train Loss=21.3544, Val Loss=2.4692
Epoch [5/5]: Train Loss=16.5602, Val Loss=2.1694
GPT2 Test CPC Loss: 2.1797
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3520, Val Loss=0.4759
Epoch [2/5]: Train Loss=0.1643, Val Loss=0.1364
Epoch [3/5]: Train Loss=0.0187, Val Loss=0.0430
Epoch [4/5]: Train Loss=0.0059, Val Loss=0.0177
Epoch [5/5]: Train Loss=0.0041, Val Loss=0.0184
LSTM Test CPC Loss: 0.0319
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.3742, Val Loss=8.6233
Epoch [2/5]: Train Loss=5.8852, Val Loss=5.0793
Epoch [3/5]: Train Loss=3.3461, Val Loss=3.4855
Epoch [4/5]: Train Loss=2.0777, Val Loss=2.5497
Epoch [5/5]: Train Loss=1.3691, Val Loss=1.9939
Reservoir Test CPC Loss: 2.3692
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0001, Val Loss=2.2762
Epoch [2/5]: Train Loss=4.7588, Val Loss=2.2802
Epoch [3/5]: Train Loss=3.8442, Val Loss=2.2822
Epoch [4/5]: Train Loss=3.1535, Val Loss=2.2843
Epoch [5/5]: Train Loss=2.7194, Val Loss=2.2860
BERT Test CPC Loss: 2.2856

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=373.4360, Val Loss=2.7428
Epoch [2/5]: Train Loss=19.4325, Val Loss=2.6720
Epoch [3/5]: Train Loss=13.9818, Val Loss=2.6756
Epoch [4/5]: Train Loss=11.1735, Val Loss=2.6707
Epoch [5/5]: Train Loss=9.5421, Val Loss=2.6748
GPT2 Test CPC Loss: 2.6697
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5356, Val Loss=0.7842
Epoch [2/5]: Train Loss=0.3144, Val Loss=0.1321
Epoch [3/5]: Train Loss=0.0390, Val Loss=0.0397
Epoch [4/5]: Train Loss=0.0090, Val Loss=0.0155
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0082
LSTM Test CPC Loss: 0.0318
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.8855, Val Loss=10.4756
Epoch [2/5]: Train Loss=7.2285, Val Loss=6.4175
Epoch [3/5]: Train Loss=4.1627, Val Loss=4.3604
Epoch [4/5]: Train Loss=2.6280, Val Loss=3.2995
Epoch [5/5]: Train Loss=1.7738, Val Loss=2.5821
Reservoir Test CPC Loss: 2.6318
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8668, Val Loss=2.6969
Epoch [2/5]: Train Loss=4.7615, Val Loss=2.6982
Epoch [3/5]: Train Loss=3.8711, Val Loss=2.6988
Epoch [4/5]: Train Loss=3.3098, Val Loss=2.6996
Epoch [5/5]: Train Loss=3.0005, Val Loss=2.7005
BERT Test CPC Loss: 2.7003

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=523.5437, Val Loss=3.0295
Epoch [2/5]: Train Loss=33.7482, Val Loss=2.9784
Epoch [3/5]: Train Loss=19.9528, Val Loss=2.9396
Epoch [4/5]: Train Loss=14.1355, Val Loss=2.9310
Epoch [5/5]: Train Loss=11.0580, Val Loss=2.9314
GPT2 Test CPC Loss: 2.9183
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7577, Val Loss=0.9057
Epoch [2/5]: Train Loss=0.5388, Val Loss=0.2438
Epoch [3/5]: Train Loss=0.0984, Val Loss=0.0674
Epoch [4/5]: Train Loss=0.0142, Val Loss=0.0193
Epoch [5/5]: Train Loss=0.0050, Val Loss=0.0110
LSTM Test CPC Loss: 0.0770
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.2010, Val Loss=12.8453
Epoch [2/5]: Train Loss=9.3715, Val Loss=7.4268
Epoch [3/5]: Train Loss=5.3557, Val Loss=4.8296
Epoch [4/5]: Train Loss=3.3336, Val Loss=3.4085
Epoch [5/5]: Train Loss=2.2044, Val Loss=2.6060
Reservoir Test CPC Loss: 3.3959
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2728, Val Loss=2.9901
Epoch [2/5]: Train Loss=4.8330, Val Loss=2.9905
Epoch [3/5]: Train Loss=4.0154, Val Loss=2.9911
Epoch [4/5]: Train Loss=3.4691, Val Loss=2.9917
Epoch [5/5]: Train Loss=3.1848, Val Loss=2.9925
BERT Test CPC Loss: 2.9923

--- Fish 11: Run 7 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=507.3053, Val Loss=1.6697
Epoch [2/5]: Train Loss=33.0044, Val Loss=1.6322
Epoch [3/5]: Train Loss=23.1044, Val Loss=1.6426
Epoch [4/5]: Train Loss=17.4886, Val Loss=1.6555
Epoch [5/5]: Train Loss=13.8919, Val Loss=1.7124
GPT2 Test CPC Loss: 1.7235
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5824, Val Loss=0.0297
Epoch [2/5]: Train Loss=0.0078, Val Loss=0.0180
Epoch [3/5]: Train Loss=0.0055, Val Loss=0.0007
Epoch [4/5]: Train Loss=0.0056, Val Loss=0.0020
Epoch [5/5]: Train Loss=0.0013, Val Loss=0.0002
LSTM Test CPC Loss: 0.0009
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.3546, Val Loss=4.0878
Epoch [2/5]: Train Loss=2.3492, Val Loss=2.0702
Epoch [3/5]: Train Loss=1.2571, Val Loss=1.3237
Epoch [4/5]: Train Loss=0.7788, Val Loss=0.9830
Epoch [5/5]: Train Loss=0.5414, Val Loss=0.7730
Reservoir Test CPC Loss: 1.3062
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7753, Val Loss=1.5374
Epoch [2/5]: Train Loss=4.8760, Val Loss=1.5477
Epoch [3/5]: Train Loss=3.9060, Val Loss=1.5665
Epoch [4/5]: Train Loss=3.1739, Val Loss=1.5479
Epoch [5/5]: Train Loss=2.5685, Val Loss=1.5163
BERT Test CPC Loss: 1.5212

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=669.8223, Val Loss=2.4325
Epoch [2/5]: Train Loss=37.3837, Val Loss=2.1746
Epoch [3/5]: Train Loss=22.7298, Val Loss=2.1841
Epoch [4/5]: Train Loss=16.7268, Val Loss=2.1993
Epoch [5/5]: Train Loss=13.1294, Val Loss=2.2019
GPT2 Test CPC Loss: 2.1970
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1397, Val Loss=0.3437
Epoch [2/5]: Train Loss=0.1049, Val Loss=0.0264
Epoch [3/5]: Train Loss=0.0128, Val Loss=0.0158
Epoch [4/5]: Train Loss=0.0046, Val Loss=0.0056
Epoch [5/5]: Train Loss=0.0011, Val Loss=0.0030
LSTM Test CPC Loss: 0.0332
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.4854, Val Loss=8.7564
Epoch [2/5]: Train Loss=5.9142, Val Loss=4.9536
Epoch [3/5]: Train Loss=3.2811, Val Loss=3.2267
Epoch [4/5]: Train Loss=2.0039, Val Loss=2.3183
Epoch [5/5]: Train Loss=1.3049, Val Loss=1.7943
Reservoir Test CPC Loss: 1.9761
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0516, Val Loss=2.2757
Epoch [2/5]: Train Loss=4.7946, Val Loss=2.2780
Epoch [3/5]: Train Loss=3.8621, Val Loss=2.2785
Epoch [4/5]: Train Loss=3.1676, Val Loss=2.2789
Epoch [5/5]: Train Loss=2.7016, Val Loss=2.2810
BERT Test CPC Loss: 2.2805

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=381.4440, Val Loss=2.8354
Epoch [2/5]: Train Loss=32.4972, Val Loss=2.6650
Epoch [3/5]: Train Loss=21.4404, Val Loss=2.6306
Epoch [4/5]: Train Loss=16.0086, Val Loss=2.6313
Epoch [5/5]: Train Loss=12.6999, Val Loss=2.6321
GPT2 Test CPC Loss: 2.6240
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5234, Val Loss=0.6338
Epoch [2/5]: Train Loss=0.2653, Val Loss=0.0977
Epoch [3/5]: Train Loss=0.0276, Val Loss=0.0277
Epoch [4/5]: Train Loss=0.0063, Val Loss=0.0164
Epoch [5/5]: Train Loss=0.0027, Val Loss=0.0123
LSTM Test CPC Loss: 0.0437
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.0262, Val Loss=11.5421
Epoch [2/5]: Train Loss=8.6585, Val Loss=6.6682
Epoch [3/5]: Train Loss=4.7899, Val Loss=4.3704
Epoch [4/5]: Train Loss=2.9301, Val Loss=3.1790
Epoch [5/5]: Train Loss=1.9211, Val Loss=2.4649
Reservoir Test CPC Loss: 2.7961
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7270, Val Loss=2.7015
Epoch [2/5]: Train Loss=4.7329, Val Loss=2.7033
Epoch [3/5]: Train Loss=3.8545, Val Loss=2.7048
Epoch [4/5]: Train Loss=3.2669, Val Loss=2.7051
Epoch [5/5]: Train Loss=2.9558, Val Loss=2.7052
BERT Test CPC Loss: 2.7050

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=308.1708, Val Loss=2.9269
Epoch [2/5]: Train Loss=24.4113, Val Loss=2.9081
Epoch [3/5]: Train Loss=16.2176, Val Loss=2.9169
Epoch [4/5]: Train Loss=12.4965, Val Loss=2.9259
Epoch [5/5]: Train Loss=10.2502, Val Loss=2.9289
GPT2 Test CPC Loss: 2.9123
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8744, Val Loss=1.1930
Epoch [2/5]: Train Loss=0.6939, Val Loss=0.5022
Epoch [3/5]: Train Loss=0.1513, Val Loss=0.1005
Epoch [4/5]: Train Loss=0.0205, Val Loss=0.0447
Epoch [5/5]: Train Loss=0.0061, Val Loss=0.0289
LSTM Test CPC Loss: 0.0685
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.4188, Val Loss=11.3485
Epoch [2/5]: Train Loss=8.3409, Val Loss=6.3084
Epoch [3/5]: Train Loss=4.6565, Val Loss=4.0561
Epoch [4/5]: Train Loss=2.8595, Val Loss=2.8635
Epoch [5/5]: Train Loss=1.8856, Val Loss=2.1398
Reservoir Test CPC Loss: 2.6650
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0251, Val Loss=2.9872
Epoch [2/5]: Train Loss=4.8058, Val Loss=2.9882
Epoch [3/5]: Train Loss=3.9730, Val Loss=2.9894
Epoch [4/5]: Train Loss=3.4181, Val Loss=2.9906
Epoch [5/5]: Train Loss=3.1742, Val Loss=2.9915
BERT Test CPC Loss: 2.9914

--- Fish 11: Run 8 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=373.8283, Val Loss=5.0808
Epoch [2/5]: Train Loss=30.5352, Val Loss=1.7060
Epoch [3/5]: Train Loss=18.0893, Val Loss=1.5083
Epoch [4/5]: Train Loss=13.3853, Val Loss=1.4212
Epoch [5/5]: Train Loss=10.6122, Val Loss=1.4049
GPT2 Test CPC Loss: 1.4079
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7040, Val Loss=0.0589
Epoch [2/5]: Train Loss=0.0140, Val Loss=0.0043
Epoch [3/5]: Train Loss=0.0034, Val Loss=0.0024
Epoch [4/5]: Train Loss=0.0023, Val Loss=0.0151
Epoch [5/5]: Train Loss=0.0062, Val Loss=0.0010
LSTM Test CPC Loss: 0.0026
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.5415, Val Loss=3.2180
Epoch [2/5]: Train Loss=1.6693, Val Loss=1.7286
Epoch [3/5]: Train Loss=0.8418, Val Loss=1.1956
Epoch [4/5]: Train Loss=0.4861, Val Loss=0.9815
Epoch [5/5]: Train Loss=0.2993, Val Loss=0.8552
Reservoir Test CPC Loss: 1.3493
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0716, Val Loss=1.5161
Epoch [2/5]: Train Loss=4.8533, Val Loss=1.5286
Epoch [3/5]: Train Loss=3.8827, Val Loss=1.5653
Epoch [4/5]: Train Loss=3.2110, Val Loss=1.5660
Epoch [5/5]: Train Loss=2.6424, Val Loss=1.5008
BERT Test CPC Loss: 1.5090

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=454.9797, Val Loss=2.4325
Epoch [2/5]: Train Loss=26.8773, Val Loss=2.2380
Epoch [3/5]: Train Loss=16.9018, Val Loss=2.2253
Epoch [4/5]: Train Loss=12.9509, Val Loss=2.2164
Epoch [5/5]: Train Loss=10.4189, Val Loss=2.2146
GPT2 Test CPC Loss: 2.2105
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2444, Val Loss=0.4552
Epoch [2/5]: Train Loss=0.1411, Val Loss=0.0484
Epoch [3/5]: Train Loss=0.0141, Val Loss=0.0280
Epoch [4/5]: Train Loss=0.0060, Val Loss=0.0091
Epoch [5/5]: Train Loss=0.0042, Val Loss=0.0052
LSTM Test CPC Loss: 0.0142
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.6911, Val Loss=9.0498
Epoch [2/5]: Train Loss=6.1355, Val Loss=5.5375
Epoch [3/5]: Train Loss=3.5843, Val Loss=3.8447
Epoch [4/5]: Train Loss=2.3026, Val Loss=2.8537
Epoch [5/5]: Train Loss=1.5649, Val Loss=2.1989
Reservoir Test CPC Loss: 2.1857
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7033, Val Loss=2.2756
Epoch [2/5]: Train Loss=4.7660, Val Loss=2.2764
Epoch [3/5]: Train Loss=3.8394, Val Loss=2.2767
Epoch [4/5]: Train Loss=3.2029, Val Loss=2.2775
Epoch [5/5]: Train Loss=2.7797, Val Loss=2.2789
BERT Test CPC Loss: 2.2782

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=507.0801, Val Loss=7.1190
Epoch [2/5]: Train Loss=38.4329, Val Loss=3.2897
Epoch [3/5]: Train Loss=23.4296, Val Loss=2.8993
Epoch [4/5]: Train Loss=16.5186, Val Loss=2.7290
Epoch [5/5]: Train Loss=13.0221, Val Loss=2.6561
GPT2 Test CPC Loss: 2.6598
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6553, Val Loss=0.8834
Epoch [2/5]: Train Loss=0.4088, Val Loss=0.1798
Epoch [3/5]: Train Loss=0.0509, Val Loss=0.0556
Epoch [4/5]: Train Loss=0.0087, Val Loss=0.0206
Epoch [5/5]: Train Loss=0.0034, Val Loss=0.0262
LSTM Test CPC Loss: 0.0365
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.1168, Val Loss=10.1375
Epoch [2/5]: Train Loss=8.0906, Val Loss=5.7711
Epoch [3/5]: Train Loss=4.4087, Val Loss=3.6512
Epoch [4/5]: Train Loss=2.6282, Val Loss=2.6022
Epoch [5/5]: Train Loss=1.6885, Val Loss=1.9061
Reservoir Test CPC Loss: 2.2517
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8262, Val Loss=2.7006
Epoch [2/5]: Train Loss=4.7203, Val Loss=2.7002
Epoch [3/5]: Train Loss=3.8639, Val Loss=2.7016
Epoch [4/5]: Train Loss=3.2843, Val Loss=2.7021
Epoch [5/5]: Train Loss=2.9731, Val Loss=2.7025
BERT Test CPC Loss: 2.7024

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=263.0061, Val Loss=3.9986
Epoch [2/5]: Train Loss=18.9534, Val Loss=3.2093
Epoch [3/5]: Train Loss=13.9711, Val Loss=3.0496
Epoch [4/5]: Train Loss=11.0396, Val Loss=3.1991
Epoch [5/5]: Train Loss=9.2859, Val Loss=3.0802
GPT2 Test CPC Loss: 3.0820
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8878, Val Loss=1.0686
Epoch [2/5]: Train Loss=0.6100, Val Loss=0.4898
Epoch [3/5]: Train Loss=0.1251, Val Loss=0.1177
Epoch [4/5]: Train Loss=0.0185, Val Loss=0.0246
Epoch [5/5]: Train Loss=0.0059, Val Loss=0.0190
LSTM Test CPC Loss: 0.1168
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.6032, Val Loss=13.4277
Epoch [2/5]: Train Loss=9.7038, Val Loss=7.8340
Epoch [3/5]: Train Loss=5.5872, Val Loss=5.0252
Epoch [4/5]: Train Loss=3.4525, Val Loss=3.5238
Epoch [5/5]: Train Loss=2.2685, Val Loss=2.6045
Reservoir Test CPC Loss: 3.1236
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7423, Val Loss=2.9889
Epoch [2/5]: Train Loss=4.7496, Val Loss=2.9897
Epoch [3/5]: Train Loss=3.9457, Val Loss=2.9904
Epoch [4/5]: Train Loss=3.4447, Val Loss=2.9911
Epoch [5/5]: Train Loss=3.1901, Val Loss=2.9918
BERT Test CPC Loss: 2.9916

--- Fish 11: Run 9 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=341.0077, Val Loss=1.7260
Epoch [2/5]: Train Loss=26.7064, Val Loss=1.4918
Epoch [3/5]: Train Loss=17.4400, Val Loss=1.4242
Epoch [4/5]: Train Loss=12.9139, Val Loss=1.4068
Epoch [5/5]: Train Loss=10.1502, Val Loss=1.4068
GPT2 Test CPC Loss: 1.4075
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6316, Val Loss=0.0625
Epoch [2/5]: Train Loss=0.0092, Val Loss=0.0050
Epoch [3/5]: Train Loss=0.0090, Val Loss=0.0011
Epoch [4/5]: Train Loss=0.0025, Val Loss=0.0045
Epoch [5/5]: Train Loss=0.0031, Val Loss=0.0005
LSTM Test CPC Loss: 0.0013
[Model: Reservoir]
Epoch [1/5]: Train Loss=6.8916, Val Loss=2.2607
Epoch [2/5]: Train Loss=1.3880, Val Loss=1.3410
Epoch [3/5]: Train Loss=0.6849, Val Loss=1.0002
Epoch [4/5]: Train Loss=0.3912, Val Loss=0.7786
Epoch [5/5]: Train Loss=0.2396, Val Loss=0.7357
Reservoir Test CPC Loss: 0.9112
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3712, Val Loss=1.5013
Epoch [2/5]: Train Loss=5.0596, Val Loss=1.5244
Epoch [3/5]: Train Loss=4.0557, Val Loss=1.5502
Epoch [4/5]: Train Loss=3.3038, Val Loss=1.5489
Epoch [5/5]: Train Loss=2.6527, Val Loss=1.5006
BERT Test CPC Loss: 1.5063

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=376.0110, Val Loss=2.8436
Epoch [2/5]: Train Loss=28.3380, Val Loss=2.7172
Epoch [3/5]: Train Loss=19.0459, Val Loss=2.7551
Epoch [4/5]: Train Loss=14.0986, Val Loss=2.8057
Epoch [5/5]: Train Loss=11.4287, Val Loss=2.7837
GPT2 Test CPC Loss: 2.7659
[Model: LSTM]
Epoch [1/5]: Train Loss=1.0798, Val Loss=0.3189
Epoch [2/5]: Train Loss=0.1022, Val Loss=0.0523
Epoch [3/5]: Train Loss=0.0138, Val Loss=0.0118
Epoch [4/5]: Train Loss=0.0064, Val Loss=0.0049
Epoch [5/5]: Train Loss=0.0024, Val Loss=0.0034
LSTM Test CPC Loss: 0.0345
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.7138, Val Loss=12.0114
Epoch [2/5]: Train Loss=7.8929, Val Loss=7.0624
Epoch [3/5]: Train Loss=4.4198, Val Loss=4.6967
Epoch [4/5]: Train Loss=2.6784, Val Loss=3.2996
Epoch [5/5]: Train Loss=1.7273, Val Loss=2.5012
Reservoir Test CPC Loss: 3.4083
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7145, Val Loss=2.2797
Epoch [2/5]: Train Loss=4.8059, Val Loss=2.2811
Epoch [3/5]: Train Loss=3.8859, Val Loss=2.2823
Epoch [4/5]: Train Loss=3.2103, Val Loss=2.2837
Epoch [5/5]: Train Loss=2.7422, Val Loss=2.2851
BERT Test CPC Loss: 2.2846

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=390.2454, Val Loss=2.6534
Epoch [2/5]: Train Loss=31.4128, Val Loss=2.6388
Epoch [3/5]: Train Loss=21.6272, Val Loss=2.6396
Epoch [4/5]: Train Loss=16.5084, Val Loss=2.6413
Epoch [5/5]: Train Loss=13.3983, Val Loss=2.6308
GPT2 Test CPC Loss: 2.6177
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5536, Val Loss=0.7172
Epoch [2/5]: Train Loss=0.3243, Val Loss=0.1369
Epoch [3/5]: Train Loss=0.0412, Val Loss=0.0297
Epoch [4/5]: Train Loss=0.0078, Val Loss=0.0176
Epoch [5/5]: Train Loss=0.0035, Val Loss=0.0084
LSTM Test CPC Loss: 0.0400
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.3255, Val Loss=12.2372
Epoch [2/5]: Train Loss=8.9096, Val Loss=6.7491
Epoch [3/5]: Train Loss=4.9151, Val Loss=4.3179
Epoch [4/5]: Train Loss=3.0020, Val Loss=2.9801
Epoch [5/5]: Train Loss=1.9736, Val Loss=2.2172
Reservoir Test CPC Loss: 2.7934
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8932, Val Loss=2.6983
Epoch [2/5]: Train Loss=4.7929, Val Loss=2.6995
Epoch [3/5]: Train Loss=3.9180, Val Loss=2.7003
Epoch [4/5]: Train Loss=3.3382, Val Loss=2.7012
Epoch [5/5]: Train Loss=3.0027, Val Loss=2.7019
BERT Test CPC Loss: 2.7018

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=317.4750, Val Loss=3.3386
Epoch [2/5]: Train Loss=20.1064, Val Loss=3.2300
Epoch [3/5]: Train Loss=14.9683, Val Loss=3.2242
Epoch [4/5]: Train Loss=12.4904, Val Loss=3.1137
Epoch [5/5]: Train Loss=10.5725, Val Loss=3.0726
GPT2 Test CPC Loss: 3.0757
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9910, Val Loss=1.3162
Epoch [2/5]: Train Loss=0.8158, Val Loss=0.5670
Epoch [3/5]: Train Loss=0.2320, Val Loss=0.1049
Epoch [4/5]: Train Loss=0.0307, Val Loss=0.0331
Epoch [5/5]: Train Loss=0.0074, Val Loss=0.0158
LSTM Test CPC Loss: 0.0716
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.3671, Val Loss=12.7519
Epoch [2/5]: Train Loss=9.0241, Val Loss=7.2505
Epoch [3/5]: Train Loss=5.1740, Val Loss=4.5480
Epoch [4/5]: Train Loss=3.2028, Val Loss=3.1298
Epoch [5/5]: Train Loss=2.1056, Val Loss=2.2694
Reservoir Test CPC Loss: 3.0063
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7248, Val Loss=2.9892
Epoch [2/5]: Train Loss=4.7652, Val Loss=2.9902
Epoch [3/5]: Train Loss=4.0076, Val Loss=2.9907
Epoch [4/5]: Train Loss=3.5411, Val Loss=2.9908
Epoch [5/5]: Train Loss=3.2876, Val Loss=2.9912
BERT Test CPC Loss: 2.9910

--- Fish 11: Run 10 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=430.8371, Val Loss=11.1904
Epoch [2/5]: Train Loss=28.6985, Val Loss=4.8819
Epoch [3/5]: Train Loss=19.4422, Val Loss=5.4099
Epoch [4/5]: Train Loss=14.1065, Val Loss=4.4864
Epoch [5/5]: Train Loss=11.4570, Val Loss=4.4956
GPT2 Test CPC Loss: 6.4591
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6746, Val Loss=0.0747
Epoch [2/5]: Train Loss=0.0129, Val Loss=0.0040
Epoch [3/5]: Train Loss=0.0011, Val Loss=0.0027
Epoch [4/5]: Train Loss=0.0028, Val Loss=0.0532
Epoch [5/5]: Train Loss=0.0069, Val Loss=0.0209
LSTM Test CPC Loss: 0.0130
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.3728, Val Loss=3.7249
Epoch [2/5]: Train Loss=2.5481, Val Loss=2.1193
Epoch [3/5]: Train Loss=1.2151, Val Loss=1.4827
Epoch [4/5]: Train Loss=0.7169, Val Loss=1.1232
Epoch [5/5]: Train Loss=0.4341, Val Loss=0.9918
Reservoir Test CPC Loss: 1.1445
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8967, Val Loss=1.5042
Epoch [2/5]: Train Loss=4.9831, Val Loss=1.4966
Epoch [3/5]: Train Loss=3.9355, Val Loss=1.4997
Epoch [4/5]: Train Loss=3.2172, Val Loss=1.4994
Epoch [5/5]: Train Loss=2.6381, Val Loss=1.4824
BERT Test CPC Loss: 1.4874

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=426.9310, Val Loss=2.2842
Epoch [2/5]: Train Loss=31.2676, Val Loss=2.2201
Epoch [3/5]: Train Loss=18.9368, Val Loss=2.2159
Epoch [4/5]: Train Loss=13.0790, Val Loss=2.2056
Epoch [5/5]: Train Loss=10.2364, Val Loss=2.2024
GPT2 Test CPC Loss: 2.2022
[Model: LSTM]
Epoch [1/5]: Train Loss=1.0467, Val Loss=0.2924
Epoch [2/5]: Train Loss=0.0844, Val Loss=0.0536
Epoch [3/5]: Train Loss=0.0114, Val Loss=0.0161
Epoch [4/5]: Train Loss=0.0064, Val Loss=0.0116
Epoch [5/5]: Train Loss=0.0407, Val Loss=0.2667
LSTM Test CPC Loss: 0.3356
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.8960, Val Loss=8.0819
Epoch [2/5]: Train Loss=6.3432, Val Loss=4.7905
Epoch [3/5]: Train Loss=3.6595, Val Loss=3.2851
Epoch [4/5]: Train Loss=2.3066, Val Loss=2.4194
Epoch [5/5]: Train Loss=1.5521, Val Loss=1.8936
Reservoir Test CPC Loss: 2.4412
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8863, Val Loss=2.2810
Epoch [2/5]: Train Loss=4.7413, Val Loss=2.2853
Epoch [3/5]: Train Loss=3.7937, Val Loss=2.2868
Epoch [4/5]: Train Loss=3.0450, Val Loss=2.2879
Epoch [5/5]: Train Loss=2.6228, Val Loss=2.2900
BERT Test CPC Loss: 2.2895

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=412.1673, Val Loss=3.1039
Epoch [2/5]: Train Loss=32.0087, Val Loss=2.7240
Epoch [3/5]: Train Loss=21.0409, Val Loss=2.6348
Epoch [4/5]: Train Loss=16.0216, Val Loss=2.6309
Epoch [5/5]: Train Loss=12.7882, Val Loss=2.6330
GPT2 Test CPC Loss: 2.6276
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7979, Val Loss=0.9115
Epoch [2/5]: Train Loss=0.4473, Val Loss=0.1576
Epoch [3/5]: Train Loss=0.0577, Val Loss=0.0387
Epoch [4/5]: Train Loss=0.0081, Val Loss=0.0196
Epoch [5/5]: Train Loss=0.0025, Val Loss=0.0173
LSTM Test CPC Loss: 0.0764
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.6516, Val Loss=11.0007
Epoch [2/5]: Train Loss=8.0206, Val Loss=6.5638
Epoch [3/5]: Train Loss=4.5969, Val Loss=4.3601
Epoch [4/5]: Train Loss=2.8498, Val Loss=3.1023
Epoch [5/5]: Train Loss=1.8777, Val Loss=2.3291
Reservoir Test CPC Loss: 2.8295
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0025, Val Loss=2.7000
Epoch [2/5]: Train Loss=4.8294, Val Loss=2.7009
Epoch [3/5]: Train Loss=3.9104, Val Loss=2.7011
Epoch [4/5]: Train Loss=3.2894, Val Loss=2.7016
Epoch [5/5]: Train Loss=2.9537, Val Loss=2.7024
BERT Test CPC Loss: 2.7023

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=323.6732, Val Loss=4.0077
Epoch [2/5]: Train Loss=20.7125, Val Loss=3.5423
Epoch [3/5]: Train Loss=15.1015, Val Loss=3.3875
Epoch [4/5]: Train Loss=12.0921, Val Loss=3.2106
Epoch [5/5]: Train Loss=10.2627, Val Loss=3.0970
GPT2 Test CPC Loss: 3.0775
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7189, Val Loss=1.0306
Epoch [2/5]: Train Loss=0.5227, Val Loss=0.3886
Epoch [3/5]: Train Loss=0.0863, Val Loss=0.0878
Epoch [4/5]: Train Loss=0.0128, Val Loss=0.0399
Epoch [5/5]: Train Loss=0.0048, Val Loss=0.0226
LSTM Test CPC Loss: 0.0415
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.7283, Val Loss=12.1831
Epoch [2/5]: Train Loss=9.2496, Val Loss=7.4059
Epoch [3/5]: Train Loss=5.3491, Val Loss=4.9698
Epoch [4/5]: Train Loss=3.3242, Val Loss=3.4926
Epoch [5/5]: Train Loss=2.1997, Val Loss=2.6703
Reservoir Test CPC Loss: 3.0701
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7718, Val Loss=2.9911
Epoch [2/5]: Train Loss=4.7877, Val Loss=2.9921
Epoch [3/5]: Train Loss=4.0034, Val Loss=2.9926
Epoch [4/5]: Train Loss=3.5044, Val Loss=2.9929
Epoch [5/5]: Train Loss=3.2300, Val Loss=2.9934
BERT Test CPC Loss: 2.9933

========== Processing Fish 12 ==========
Fish 12: Neural data shape: (2793, 10581)

--- Fish 12: Run 1 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=348.1415, Val Loss=2.6372
Epoch [2/5]: Train Loss=21.4161, Val Loss=2.1671
Epoch [3/5]: Train Loss=15.2622, Val Loss=2.2096
Epoch [4/5]: Train Loss=11.6236, Val Loss=2.0305
Epoch [5/5]: Train Loss=9.3941, Val Loss=1.6439
GPT2 Test CPC Loss: 1.6262
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6378, Val Loss=0.0341
Epoch [2/5]: Train Loss=0.0067, Val Loss=0.0049
Epoch [3/5]: Train Loss=0.0009, Val Loss=0.0022
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0016
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0012
LSTM Test CPC Loss: 0.0008
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.1300, Val Loss=3.2961
Epoch [2/5]: Train Loss=2.6000, Val Loss=1.8180
Epoch [3/5]: Train Loss=1.4277, Val Loss=1.3035
Epoch [4/5]: Train Loss=0.8716, Val Loss=0.9939
Epoch [5/5]: Train Loss=0.5544, Val Loss=0.8488
Reservoir Test CPC Loss: 0.9512
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7476, Val Loss=1.5108
Epoch [2/5]: Train Loss=4.8052, Val Loss=1.5564
Epoch [3/5]: Train Loss=3.7500, Val Loss=1.6153
Epoch [4/5]: Train Loss=2.9695, Val Loss=1.5648
Epoch [5/5]: Train Loss=2.3686, Val Loss=1.4867
BERT Test CPC Loss: 1.4876

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=526.0618, Val Loss=2.2727
Epoch [2/5]: Train Loss=27.3913, Val Loss=2.3146
Epoch [3/5]: Train Loss=19.4297, Val Loss=2.3329
Epoch [4/5]: Train Loss=15.3377, Val Loss=2.3137
Epoch [5/5]: Train Loss=12.6738, Val Loss=2.3087
GPT2 Test CPC Loss: 2.3056
[Model: LSTM]
Epoch [1/5]: Train Loss=1.0046, Val Loss=0.3446
Epoch [2/5]: Train Loss=0.0949, Val Loss=0.0557
Epoch [3/5]: Train Loss=0.0090, Val Loss=0.0393
Epoch [4/5]: Train Loss=0.0025, Val Loss=0.0191
Epoch [5/5]: Train Loss=0.0013, Val Loss=0.0148
LSTM Test CPC Loss: 0.0074
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.4556, Val Loss=11.1590
Epoch [2/5]: Train Loss=7.9542, Val Loss=6.2830
Epoch [3/5]: Train Loss=4.4630, Val Loss=3.9495
Epoch [4/5]: Train Loss=2.7359, Val Loss=2.7324
Epoch [5/5]: Train Loss=1.7736, Val Loss=2.0496
Reservoir Test CPC Loss: 2.1941
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5993, Val Loss=2.2787
Epoch [2/5]: Train Loss=4.7109, Val Loss=2.2795
Epoch [3/5]: Train Loss=3.7217, Val Loss=2.2816
Epoch [4/5]: Train Loss=3.0288, Val Loss=2.2823
Epoch [5/5]: Train Loss=2.6388, Val Loss=2.2828
BERT Test CPC Loss: 2.2822

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=435.2530, Val Loss=2.7197
Epoch [2/5]: Train Loss=31.4796, Val Loss=2.6596
Epoch [3/5]: Train Loss=20.6264, Val Loss=2.6486
Epoch [4/5]: Train Loss=15.5169, Val Loss=2.6412
Epoch [5/5]: Train Loss=12.4899, Val Loss=2.6387
GPT2 Test CPC Loss: 2.6368
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6221, Val Loss=0.9310
Epoch [2/5]: Train Loss=0.4131, Val Loss=0.2651
Epoch [3/5]: Train Loss=0.0471, Val Loss=0.0869
Epoch [4/5]: Train Loss=0.0078, Val Loss=0.0550
Epoch [5/5]: Train Loss=0.0032, Val Loss=0.0437
LSTM Test CPC Loss: 0.0224
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.3208, Val Loss=13.0389
Epoch [2/5]: Train Loss=8.7368, Val Loss=7.7630
Epoch [3/5]: Train Loss=4.8681, Val Loss=5.2549
Epoch [4/5]: Train Loss=2.9714, Val Loss=3.8104
Epoch [5/5]: Train Loss=1.9376, Val Loss=2.9320
Reservoir Test CPC Loss: 2.4752
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6705, Val Loss=2.7010
Epoch [2/5]: Train Loss=4.7206, Val Loss=2.7021
Epoch [3/5]: Train Loss=3.8626, Val Loss=2.7032
Epoch [4/5]: Train Loss=3.2939, Val Loss=2.7037
Epoch [5/5]: Train Loss=2.9820, Val Loss=2.7042
BERT Test CPC Loss: 2.7039

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=417.8960, Val Loss=3.0016
Epoch [2/5]: Train Loss=25.5797, Val Loss=2.9242
Epoch [3/5]: Train Loss=16.3493, Val Loss=2.9248
Epoch [4/5]: Train Loss=12.1570, Val Loss=2.9259
Epoch [5/5]: Train Loss=9.8518, Val Loss=2.9279
GPT2 Test CPC Loss: 2.9306
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8843, Val Loss=1.2641
Epoch [2/5]: Train Loss=0.7224, Val Loss=0.6064
Epoch [3/5]: Train Loss=0.1729, Val Loss=0.1244
Epoch [4/5]: Train Loss=0.0229, Val Loss=0.0436
Epoch [5/5]: Train Loss=0.0061, Val Loss=0.0287
LSTM Test CPC Loss: 0.0248
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.2531, Val Loss=13.1783
Epoch [2/5]: Train Loss=8.2153, Val Loss=7.6310
Epoch [3/5]: Train Loss=4.6819, Val Loss=5.0743
Epoch [4/5]: Train Loss=2.8946, Val Loss=3.6044
Epoch [5/5]: Train Loss=1.9148, Val Loss=2.7222
Reservoir Test CPC Loss: 2.5313
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.3917, Val Loss=2.9868
Epoch [2/5]: Train Loss=4.6628, Val Loss=2.9893
Epoch [3/5]: Train Loss=3.8757, Val Loss=2.9905
Epoch [4/5]: Train Loss=3.4163, Val Loss=2.9915
Epoch [5/5]: Train Loss=3.1897, Val Loss=2.9923
BERT Test CPC Loss: 2.9920

--- Fish 12: Run 2 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=404.4849, Val Loss=17.0613
Epoch [2/5]: Train Loss=30.2958, Val Loss=7.4865
Epoch [3/5]: Train Loss=20.9065, Val Loss=5.1461
Epoch [4/5]: Train Loss=15.8174, Val Loss=4.2409
Epoch [5/5]: Train Loss=12.2778, Val Loss=3.2451
GPT2 Test CPC Loss: 2.9395
[Model: LSTM]
Epoch [1/5]: Train Loss=0.8312, Val Loss=0.1174
Epoch [2/5]: Train Loss=0.0255, Val Loss=0.0076
Epoch [3/5]: Train Loss=0.0017, Val Loss=0.0045
Epoch [4/5]: Train Loss=0.0008, Val Loss=0.0019
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0014
LSTM Test CPC Loss: 0.0011
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.8029, Val Loss=4.0775
Epoch [2/5]: Train Loss=2.5185, Val Loss=2.3360
Epoch [3/5]: Train Loss=1.3113, Val Loss=1.7270
Epoch [4/5]: Train Loss=0.7901, Val Loss=1.3898
Epoch [5/5]: Train Loss=0.5046, Val Loss=1.2108
Reservoir Test CPC Loss: 1.0921
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9760, Val Loss=1.5231
Epoch [2/5]: Train Loss=4.9072, Val Loss=1.5497
Epoch [3/5]: Train Loss=3.8771, Val Loss=1.6072
Epoch [4/5]: Train Loss=3.1591, Val Loss=1.5943
Epoch [5/5]: Train Loss=2.5530, Val Loss=1.5098
BERT Test CPC Loss: 1.5155

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=410.3965, Val Loss=2.6105
Epoch [2/5]: Train Loss=24.7403, Val Loss=2.2919
Epoch [3/5]: Train Loss=18.2996, Val Loss=2.2518
Epoch [4/5]: Train Loss=14.9268, Val Loss=2.2468
Epoch [5/5]: Train Loss=12.6689, Val Loss=2.2367
GPT2 Test CPC Loss: 2.2343
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3625, Val Loss=0.5857
Epoch [2/5]: Train Loss=0.2153, Val Loss=0.1049
Epoch [3/5]: Train Loss=0.0180, Val Loss=0.0320
Epoch [4/5]: Train Loss=0.0038, Val Loss=0.0203
Epoch [5/5]: Train Loss=0.0017, Val Loss=0.0139
LSTM Test CPC Loss: 0.0372
[Model: Reservoir]
Epoch [1/5]: Train Loss=13.0960, Val Loss=8.9413
Epoch [2/5]: Train Loss=5.7692, Val Loss=5.7481
Epoch [3/5]: Train Loss=3.4941, Val Loss=4.1031
Epoch [4/5]: Train Loss=2.2589, Val Loss=3.1116
Epoch [5/5]: Train Loss=1.5307, Val Loss=2.4917
Reservoir Test CPC Loss: 2.2423
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8225, Val Loss=2.2843
Epoch [2/5]: Train Loss=4.7355, Val Loss=2.2875
Epoch [3/5]: Train Loss=3.7327, Val Loss=2.2904
Epoch [4/5]: Train Loss=2.8867, Val Loss=2.2939
Epoch [5/5]: Train Loss=2.5101, Val Loss=2.2948
BERT Test CPC Loss: 2.2947

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=409.2894, Val Loss=2.6152
Epoch [2/5]: Train Loss=24.6768, Val Loss=2.6368
Epoch [3/5]: Train Loss=15.7632, Val Loss=2.6271
Epoch [4/5]: Train Loss=11.8812, Val Loss=2.6334
Epoch [5/5]: Train Loss=9.3488, Val Loss=2.6406
GPT2 Test CPC Loss: 2.6449
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4295, Val Loss=0.7280
Epoch [2/5]: Train Loss=0.3049, Val Loss=0.2097
Epoch [3/5]: Train Loss=0.0373, Val Loss=0.0669
Epoch [4/5]: Train Loss=0.0067, Val Loss=0.0326
Epoch [5/5]: Train Loss=0.0027, Val Loss=0.0226
LSTM Test CPC Loss: 0.0203
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.8026, Val Loss=12.1855
Epoch [2/5]: Train Loss=9.2602, Val Loss=7.5672
Epoch [3/5]: Train Loss=5.5752, Val Loss=5.1518
Epoch [4/5]: Train Loss=3.6314, Val Loss=3.6764
Epoch [5/5]: Train Loss=2.4783, Val Loss=2.7719
Reservoir Test CPC Loss: 3.0107
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5324, Val Loss=2.6995
Epoch [2/5]: Train Loss=4.6378, Val Loss=2.7002
Epoch [3/5]: Train Loss=3.7858, Val Loss=2.7002
Epoch [4/5]: Train Loss=3.2599, Val Loss=2.7008
Epoch [5/5]: Train Loss=2.9668, Val Loss=2.7013
BERT Test CPC Loss: 2.7010

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=374.4846, Val Loss=4.7540
Epoch [2/5]: Train Loss=21.8797, Val Loss=3.2303
Epoch [3/5]: Train Loss=15.5796, Val Loss=3.0999
Epoch [4/5]: Train Loss=12.5092, Val Loss=3.0566
Epoch [5/5]: Train Loss=10.6072, Val Loss=3.0624
GPT2 Test CPC Loss: 3.0538
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1346, Val Loss=1.5733
Epoch [2/5]: Train Loss=0.8528, Val Loss=0.7157
Epoch [3/5]: Train Loss=0.2164, Val Loss=0.1905
Epoch [4/5]: Train Loss=0.0281, Val Loss=0.0327
Epoch [5/5]: Train Loss=0.0039, Val Loss=0.0220
LSTM Test CPC Loss: 0.0111
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.4827, Val Loss=12.4435
Epoch [2/5]: Train Loss=8.9215, Val Loss=7.4947
Epoch [3/5]: Train Loss=5.1751, Val Loss=5.0664
Epoch [4/5]: Train Loss=3.2407, Val Loss=3.6752
Epoch [5/5]: Train Loss=2.1445, Val Loss=2.7534
Reservoir Test CPC Loss: 2.6476
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8161, Val Loss=2.9890
Epoch [2/5]: Train Loss=4.7543, Val Loss=2.9904
Epoch [3/5]: Train Loss=3.9622, Val Loss=2.9910
Epoch [4/5]: Train Loss=3.4790, Val Loss=2.9915
Epoch [5/5]: Train Loss=3.2236, Val Loss=2.9918
BERT Test CPC Loss: 2.9915

--- Fish 12: Run 3 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=350.2017, Val Loss=7.0505
Epoch [2/5]: Train Loss=23.5016, Val Loss=5.7254
Epoch [3/5]: Train Loss=16.6946, Val Loss=3.9376
Epoch [4/5]: Train Loss=12.4132, Val Loss=2.6610
Epoch [5/5]: Train Loss=9.6964, Val Loss=2.2337
GPT2 Test CPC Loss: 2.3253
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6243, Val Loss=0.0673
Epoch [2/5]: Train Loss=0.0109, Val Loss=0.0048
Epoch [3/5]: Train Loss=0.0012, Val Loss=0.0022
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0015
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0013
LSTM Test CPC Loss: 0.0008
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.3349, Val Loss=4.2486
Epoch [2/5]: Train Loss=2.4528, Val Loss=2.6330
Epoch [3/5]: Train Loss=1.2628, Val Loss=2.0857
Epoch [4/5]: Train Loss=0.7379, Val Loss=1.7008
Epoch [5/5]: Train Loss=0.4554, Val Loss=1.5050
Reservoir Test CPC Loss: 1.3327
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1105, Val Loss=1.5159
Epoch [2/5]: Train Loss=4.9019, Val Loss=1.5130
Epoch [3/5]: Train Loss=3.8321, Val Loss=1.5396
Epoch [4/5]: Train Loss=3.0174, Val Loss=1.5390
Epoch [5/5]: Train Loss=2.4165, Val Loss=1.4905
BERT Test CPC Loss: 1.4916

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=547.6920, Val Loss=2.9763
Epoch [2/5]: Train Loss=30.1658, Val Loss=2.2613
Epoch [3/5]: Train Loss=20.3085, Val Loss=2.2783
Epoch [4/5]: Train Loss=15.7636, Val Loss=2.2838
Epoch [5/5]: Train Loss=13.2238, Val Loss=2.2827
GPT2 Test CPC Loss: 2.2750
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2959, Val Loss=0.4732
Epoch [2/5]: Train Loss=0.1531, Val Loss=0.1033
Epoch [3/5]: Train Loss=0.0152, Val Loss=0.0333
Epoch [4/5]: Train Loss=0.0037, Val Loss=0.0263
Epoch [5/5]: Train Loss=0.0018, Val Loss=0.0248
LSTM Test CPC Loss: 0.0151
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.0349, Val Loss=9.0310
Epoch [2/5]: Train Loss=7.0363, Val Loss=5.5848
Epoch [3/5]: Train Loss=4.1053, Val Loss=3.8886
Epoch [4/5]: Train Loss=2.5887, Val Loss=2.9814
Epoch [5/5]: Train Loss=1.7412, Val Loss=2.3577
Reservoir Test CPC Loss: 2.5837
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9756, Val Loss=2.2787
Epoch [2/5]: Train Loss=4.7109, Val Loss=2.2778
Epoch [3/5]: Train Loss=3.7702, Val Loss=2.2789
Epoch [4/5]: Train Loss=3.1170, Val Loss=2.2779
Epoch [5/5]: Train Loss=2.7165, Val Loss=2.2786
BERT Test CPC Loss: 2.2780

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=359.1628, Val Loss=2.6102
Epoch [2/5]: Train Loss=21.9257, Val Loss=2.5975
Epoch [3/5]: Train Loss=14.0791, Val Loss=2.6040
Epoch [4/5]: Train Loss=10.3785, Val Loss=2.6135
Epoch [5/5]: Train Loss=8.3753, Val Loss=2.6197
GPT2 Test CPC Loss: 2.6194
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4801, Val Loss=0.8334
Epoch [2/5]: Train Loss=0.3092, Val Loss=0.2104
Epoch [3/5]: Train Loss=0.0398, Val Loss=0.0889
Epoch [4/5]: Train Loss=0.0079, Val Loss=0.0463
Epoch [5/5]: Train Loss=0.0031, Val Loss=0.0345
LSTM Test CPC Loss: 0.0254
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.9617, Val Loss=13.1852
Epoch [2/5]: Train Loss=9.4532, Val Loss=7.8626
Epoch [3/5]: Train Loss=5.4188, Val Loss=5.3559
Epoch [4/5]: Train Loss=3.3333, Val Loss=3.9328
Epoch [5/5]: Train Loss=2.1769, Val Loss=2.9980
Reservoir Test CPC Loss: 2.9974
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6577, Val Loss=2.6961
Epoch [2/5]: Train Loss=4.7066, Val Loss=2.6959
Epoch [3/5]: Train Loss=3.8148, Val Loss=2.6974
Epoch [4/5]: Train Loss=3.2403, Val Loss=2.6974
Epoch [5/5]: Train Loss=2.9534, Val Loss=2.6984
BERT Test CPC Loss: 2.6979

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=420.9242, Val Loss=5.9722
Epoch [2/5]: Train Loss=20.1187, Val Loss=2.8831
Epoch [3/5]: Train Loss=14.6045, Val Loss=2.9018
Epoch [4/5]: Train Loss=11.9274, Val Loss=2.8841
Epoch [5/5]: Train Loss=10.1472, Val Loss=2.7596
GPT2 Test CPC Loss: 2.7282
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7687, Val Loss=1.2214
Epoch [2/5]: Train Loss=0.6579, Val Loss=0.4591
Epoch [3/5]: Train Loss=0.1427, Val Loss=0.0983
Epoch [4/5]: Train Loss=0.0185, Val Loss=0.0342
Epoch [5/5]: Train Loss=0.0050, Val Loss=0.0232
LSTM Test CPC Loss: 0.0201
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.6183, Val Loss=12.6322
Epoch [2/5]: Train Loss=9.0377, Val Loss=7.0654
Epoch [3/5]: Train Loss=5.0366, Val Loss=4.4407
Epoch [4/5]: Train Loss=3.0285, Val Loss=3.0308
Epoch [5/5]: Train Loss=1.9687, Val Loss=2.2309
Reservoir Test CPC Loss: 2.2473
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4749, Val Loss=2.9877
Epoch [2/5]: Train Loss=4.6527, Val Loss=2.9887
Epoch [3/5]: Train Loss=3.8649, Val Loss=2.9899
Epoch [4/5]: Train Loss=3.3959, Val Loss=2.9904
Epoch [5/5]: Train Loss=3.1720, Val Loss=2.9911
BERT Test CPC Loss: 2.9908

--- Fish 12: Run 4 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=348.9512, Val Loss=2.2050
Epoch [2/5]: Train Loss=24.9768, Val Loss=1.4932
Epoch [3/5]: Train Loss=13.7959, Val Loss=1.4312
Epoch [4/5]: Train Loss=9.9017, Val Loss=1.4037
Epoch [5/5]: Train Loss=7.9919, Val Loss=1.3950
GPT2 Test CPC Loss: 1.3951
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6725, Val Loss=0.0339
Epoch [2/5]: Train Loss=0.0068, Val Loss=0.0072
Epoch [3/5]: Train Loss=0.0011, Val Loss=0.0027
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0015
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0015
LSTM Test CPC Loss: 0.0011
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.3574, Val Loss=4.0884
Epoch [2/5]: Train Loss=2.2045, Val Loss=2.4997
Epoch [3/5]: Train Loss=1.1736, Val Loss=1.8531
Epoch [4/5]: Train Loss=0.6908, Val Loss=1.5280
Epoch [5/5]: Train Loss=0.4217, Val Loss=1.3368
Reservoir Test CPC Loss: 1.5111
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6319, Val Loss=1.5113
Epoch [2/5]: Train Loss=4.7061, Val Loss=1.5563
Epoch [3/5]: Train Loss=3.6618, Val Loss=1.5919
Epoch [4/5]: Train Loss=2.9096, Val Loss=1.5573
Epoch [5/5]: Train Loss=2.3123, Val Loss=1.4871
BERT Test CPC Loss: 1.4874

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=578.4185, Val Loss=3.7895
Epoch [2/5]: Train Loss=33.6165, Val Loss=3.1030
Epoch [3/5]: Train Loss=22.7294, Val Loss=2.9056
Epoch [4/5]: Train Loss=17.7525, Val Loss=2.6882
Epoch [5/5]: Train Loss=14.4471, Val Loss=2.3699
GPT2 Test CPC Loss: 2.4130
[Model: LSTM]
Epoch [1/5]: Train Loss=1.0881, Val Loss=0.2991
Epoch [2/5]: Train Loss=0.0878, Val Loss=0.0344
Epoch [3/5]: Train Loss=0.0055, Val Loss=0.0098
Epoch [4/5]: Train Loss=0.0018, Val Loss=0.0067
Epoch [5/5]: Train Loss=0.0010, Val Loss=0.0054
LSTM Test CPC Loss: 0.0085
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.1297, Val Loss=8.4663
Epoch [2/5]: Train Loss=6.1270, Val Loss=5.2001
Epoch [3/5]: Train Loss=3.5788, Val Loss=3.4385
Epoch [4/5]: Train Loss=2.2710, Val Loss=2.5839
Epoch [5/5]: Train Loss=1.5404, Val Loss=2.0087
Reservoir Test CPC Loss: 2.1891
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8407, Val Loss=2.2830
Epoch [2/5]: Train Loss=4.7008, Val Loss=2.2835
Epoch [3/5]: Train Loss=3.7202, Val Loss=2.2859
Epoch [4/5]: Train Loss=3.0010, Val Loss=2.2892
Epoch [5/5]: Train Loss=2.5972, Val Loss=2.2895
BERT Test CPC Loss: 2.2891

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=321.4148, Val Loss=2.6880
Epoch [2/5]: Train Loss=21.6192, Val Loss=2.6685
Epoch [3/5]: Train Loss=14.3517, Val Loss=2.6537
Epoch [4/5]: Train Loss=10.9262, Val Loss=2.6584
Epoch [5/5]: Train Loss=8.9091, Val Loss=2.6468
GPT2 Test CPC Loss: 2.6466
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4755, Val Loss=0.7771
Epoch [2/5]: Train Loss=0.3655, Val Loss=0.3349
Epoch [3/5]: Train Loss=0.0591, Val Loss=0.0625
Epoch [4/5]: Train Loss=0.0090, Val Loss=0.0304
Epoch [5/5]: Train Loss=0.0038, Val Loss=0.0205
LSTM Test CPC Loss: 0.0280
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.0590, Val Loss=12.1747
Epoch [2/5]: Train Loss=8.5966, Val Loss=7.2158
Epoch [3/5]: Train Loss=4.9826, Val Loss=4.9470
Epoch [4/5]: Train Loss=3.1299, Val Loss=3.5312
Epoch [5/5]: Train Loss=2.0904, Val Loss=2.7405
Reservoir Test CPC Loss: 2.8116
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.2396, Val Loss=2.6972
Epoch [2/5]: Train Loss=4.5404, Val Loss=2.6990
Epoch [3/5]: Train Loss=3.6678, Val Loss=2.6984
Epoch [4/5]: Train Loss=3.1696, Val Loss=2.6987
Epoch [5/5]: Train Loss=2.9399, Val Loss=2.6989
BERT Test CPC Loss: 2.6985

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=250.8853, Val Loss=4.3750
Epoch [2/5]: Train Loss=19.4854, Val Loss=3.6211
Epoch [3/5]: Train Loss=13.6841, Val Loss=2.9027
Epoch [4/5]: Train Loss=10.8940, Val Loss=2.8622
Epoch [5/5]: Train Loss=9.0646, Val Loss=2.7879
GPT2 Test CPC Loss: 2.7819
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8673, Val Loss=1.3928
Epoch [2/5]: Train Loss=0.6837, Val Loss=0.5838
Epoch [3/5]: Train Loss=0.1476, Val Loss=0.1202
Epoch [4/5]: Train Loss=0.0168, Val Loss=0.0352
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0213
LSTM Test CPC Loss: 0.0198
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.1158, Val Loss=14.0661
Epoch [2/5]: Train Loss=9.3153, Val Loss=7.5584
Epoch [3/5]: Train Loss=4.8051, Val Loss=4.6051
Epoch [4/5]: Train Loss=2.7422, Val Loss=3.1468
Epoch [5/5]: Train Loss=1.7067, Val Loss=2.2832
Reservoir Test CPC Loss: 2.5778
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4046, Val Loss=2.9889
Epoch [2/5]: Train Loss=4.7082, Val Loss=2.9892
Epoch [3/5]: Train Loss=3.9194, Val Loss=2.9905
Epoch [4/5]: Train Loss=3.4411, Val Loss=2.9907
Epoch [5/5]: Train Loss=3.2013, Val Loss=2.9914
BERT Test CPC Loss: 2.9910

--- Fish 12: Run 5 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=333.5165, Val Loss=1.6467
Epoch [2/5]: Train Loss=24.9299, Val Loss=1.4330
Epoch [3/5]: Train Loss=16.2830, Val Loss=1.4133
Epoch [4/5]: Train Loss=12.0111, Val Loss=1.4084
Epoch [5/5]: Train Loss=9.5649, Val Loss=1.4081
GPT2 Test CPC Loss: 1.4030
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5945, Val Loss=0.0305
Epoch [2/5]: Train Loss=0.0055, Val Loss=0.0028
Epoch [3/5]: Train Loss=0.0007, Val Loss=0.0016
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0013
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0011
LSTM Test CPC Loss: 0.0008
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.0548, Val Loss=5.0380
Epoch [2/5]: Train Loss=2.4439, Val Loss=2.9070
Epoch [3/5]: Train Loss=1.2442, Val Loss=2.1534
Epoch [4/5]: Train Loss=0.7203, Val Loss=1.7432
Epoch [5/5]: Train Loss=0.4332, Val Loss=1.5494
Reservoir Test CPC Loss: 0.8938
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0298, Val Loss=1.5156
Epoch [2/5]: Train Loss=4.8223, Val Loss=1.5728
Epoch [3/5]: Train Loss=3.7473, Val Loss=1.6092
Epoch [4/5]: Train Loss=2.9937, Val Loss=1.5578
Epoch [5/5]: Train Loss=2.4171, Val Loss=1.4934
BERT Test CPC Loss: 1.4961

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=353.9707, Val Loss=2.3246
Epoch [2/5]: Train Loss=26.5704, Val Loss=2.2594
Epoch [3/5]: Train Loss=18.0870, Val Loss=2.2379
Epoch [4/5]: Train Loss=13.8610, Val Loss=2.2178
Epoch [5/5]: Train Loss=10.9661, Val Loss=2.2021
GPT2 Test CPC Loss: 2.1997
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2772, Val Loss=0.5574
Epoch [2/5]: Train Loss=0.1450, Val Loss=0.0750
Epoch [3/5]: Train Loss=0.0104, Val Loss=0.0578
Epoch [4/5]: Train Loss=0.0025, Val Loss=0.0366
Epoch [5/5]: Train Loss=0.0012, Val Loss=0.0312
LSTM Test CPC Loss: 0.0064
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.8013, Val Loss=10.6993
Epoch [2/5]: Train Loss=7.1075, Val Loss=6.6899
Epoch [3/5]: Train Loss=4.1802, Val Loss=4.7842
Epoch [4/5]: Train Loss=2.6487, Val Loss=3.6493
Epoch [5/5]: Train Loss=1.7783, Val Loss=2.9475
Reservoir Test CPC Loss: 2.7646
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1377, Val Loss=2.2780
Epoch [2/5]: Train Loss=4.7946, Val Loss=2.2754
Epoch [3/5]: Train Loss=3.8184, Val Loss=2.2762
Epoch [4/5]: Train Loss=3.0956, Val Loss=2.2764
Epoch [5/5]: Train Loss=2.6704, Val Loss=2.2780
BERT Test CPC Loss: 2.2773

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=438.1569, Val Loss=3.5620
Epoch [2/5]: Train Loss=34.3631, Val Loss=2.7244
Epoch [3/5]: Train Loss=21.7700, Val Loss=2.6363
Epoch [4/5]: Train Loss=16.1061, Val Loss=2.6124
Epoch [5/5]: Train Loss=12.7744, Val Loss=2.6152
GPT2 Test CPC Loss: 2.6199
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8582, Val Loss=1.1394
Epoch [2/5]: Train Loss=0.5721, Val Loss=0.5429
Epoch [3/5]: Train Loss=0.1066, Val Loss=0.1064
Epoch [4/5]: Train Loss=0.0149, Val Loss=0.0482
Epoch [5/5]: Train Loss=0.0049, Val Loss=0.0294
LSTM Test CPC Loss: 0.0212
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.2618, Val Loss=13.1192
Epoch [2/5]: Train Loss=8.9277, Val Loss=7.7701
Epoch [3/5]: Train Loss=4.9872, Val Loss=5.1496
Epoch [4/5]: Train Loss=3.0195, Val Loss=3.7481
Epoch [5/5]: Train Loss=1.9501, Val Loss=2.9315
Reservoir Test CPC Loss: 2.5833
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.3652, Val Loss=2.6985
Epoch [2/5]: Train Loss=4.6314, Val Loss=2.6996
Epoch [3/5]: Train Loss=3.8075, Val Loss=2.7010
Epoch [4/5]: Train Loss=3.2798, Val Loss=2.7011
Epoch [5/5]: Train Loss=2.9898, Val Loss=2.7018
BERT Test CPC Loss: 2.7015

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=307.4999, Val Loss=2.9868
Epoch [2/5]: Train Loss=19.8071, Val Loss=2.9143
Epoch [3/5]: Train Loss=14.4359, Val Loss=2.9174
Epoch [4/5]: Train Loss=11.6909, Val Loss=2.9320
Epoch [5/5]: Train Loss=9.9914, Val Loss=2.9302
GPT2 Test CPC Loss: 2.9305
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8366, Val Loss=1.2347
Epoch [2/5]: Train Loss=0.6587, Val Loss=0.5002
Epoch [3/5]: Train Loss=0.1357, Val Loss=0.1218
Epoch [4/5]: Train Loss=0.0154, Val Loss=0.0681
Epoch [5/5]: Train Loss=0.0045, Val Loss=0.0494
LSTM Test CPC Loss: 0.0209
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.0044, Val Loss=13.1493
Epoch [2/5]: Train Loss=8.9818, Val Loss=7.8159
Epoch [3/5]: Train Loss=5.1129, Val Loss=5.2462
Epoch [4/5]: Train Loss=3.1622, Val Loss=3.6957
Epoch [5/5]: Train Loss=2.0734, Val Loss=2.7500
Reservoir Test CPC Loss: 2.5695
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6409, Val Loss=2.9870
Epoch [2/5]: Train Loss=4.7379, Val Loss=2.9877
Epoch [3/5]: Train Loss=3.9098, Val Loss=2.9886
Epoch [4/5]: Train Loss=3.3940, Val Loss=2.9898
Epoch [5/5]: Train Loss=3.1701, Val Loss=2.9906
BERT Test CPC Loss: 2.9903

--- Fish 12: Run 6 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=365.1432, Val Loss=3.6744
Epoch [2/5]: Train Loss=24.6374, Val Loss=3.3920
Epoch [3/5]: Train Loss=17.1724, Val Loss=2.3791
Epoch [4/5]: Train Loss=13.2061, Val Loss=2.2214
Epoch [5/5]: Train Loss=10.2655, Val Loss=2.0273
GPT2 Test CPC Loss: 2.0680
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7360, Val Loss=0.0608
Epoch [2/5]: Train Loss=0.0135, Val Loss=0.0027
Epoch [3/5]: Train Loss=0.0010, Val Loss=0.0019
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0012
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0009
LSTM Test CPC Loss: 0.0011
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.0988, Val Loss=3.3600
Epoch [2/5]: Train Loss=2.5656, Val Loss=1.8186
Epoch [3/5]: Train Loss=1.3921, Val Loss=1.3313
Epoch [4/5]: Train Loss=0.8538, Val Loss=1.0691
Epoch [5/5]: Train Loss=0.5613, Val Loss=0.8466
Reservoir Test CPC Loss: 1.0126
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2198, Val Loss=1.5173
Epoch [2/5]: Train Loss=4.8788, Val Loss=1.5633
Epoch [3/5]: Train Loss=3.8113, Val Loss=1.6198
Epoch [4/5]: Train Loss=3.0791, Val Loss=1.5799
Epoch [5/5]: Train Loss=2.5248, Val Loss=1.4992
BERT Test CPC Loss: 1.5033

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=583.2476, Val Loss=2.3821
Epoch [2/5]: Train Loss=39.6773, Val Loss=2.2537
Epoch [3/5]: Train Loss=21.3915, Val Loss=2.1957
Epoch [4/5]: Train Loss=14.6858, Val Loss=2.1831
Epoch [5/5]: Train Loss=11.4845, Val Loss=2.1790
GPT2 Test CPC Loss: 2.1829
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2474, Val Loss=0.4910
Epoch [2/5]: Train Loss=0.1403, Val Loss=0.1351
Epoch [3/5]: Train Loss=0.0110, Val Loss=0.0540
Epoch [4/5]: Train Loss=0.0031, Val Loss=0.0486
Epoch [5/5]: Train Loss=0.0015, Val Loss=0.0407
LSTM Test CPC Loss: 0.0094
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.0491, Val Loss=11.0439
Epoch [2/5]: Train Loss=7.3330, Val Loss=7.1245
Epoch [3/5]: Train Loss=4.3364, Val Loss=4.8476
Epoch [4/5]: Train Loss=2.7466, Val Loss=3.6063
Epoch [5/5]: Train Loss=1.8391, Val Loss=2.7694
Reservoir Test CPC Loss: 2.5013
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6940, Val Loss=2.2793
Epoch [2/5]: Train Loss=4.7180, Val Loss=2.2796
Epoch [3/5]: Train Loss=3.7465, Val Loss=2.2807
Epoch [4/5]: Train Loss=3.0652, Val Loss=2.2815
Epoch [5/5]: Train Loss=2.6520, Val Loss=2.2817
BERT Test CPC Loss: 2.2812

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=544.9235, Val Loss=4.0266
Epoch [2/5]: Train Loss=38.4241, Val Loss=3.2739
Epoch [3/5]: Train Loss=25.6391, Val Loss=3.1723
Epoch [4/5]: Train Loss=19.2690, Val Loss=3.0541
Epoch [5/5]: Train Loss=15.5406, Val Loss=3.0336
GPT2 Test CPC Loss: 3.0605
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6364, Val Loss=0.9297
Epoch [2/5]: Train Loss=0.3843, Val Loss=0.2872
Epoch [3/5]: Train Loss=0.0530, Val Loss=0.0868
Epoch [4/5]: Train Loss=0.0098, Val Loss=0.0512
Epoch [5/5]: Train Loss=0.0037, Val Loss=0.0347
LSTM Test CPC Loss: 0.0268
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.4703, Val Loss=13.5810
Epoch [2/5]: Train Loss=9.2287, Val Loss=8.0039
Epoch [3/5]: Train Loss=5.3519, Val Loss=5.2301
Epoch [4/5]: Train Loss=3.3150, Val Loss=3.7224
Epoch [5/5]: Train Loss=2.1905, Val Loss=2.8164
Reservoir Test CPC Loss: 2.7293
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4018, Val Loss=2.6991
Epoch [2/5]: Train Loss=4.6263, Val Loss=2.6997
Epoch [3/5]: Train Loss=3.7476, Val Loss=2.7003
Epoch [4/5]: Train Loss=3.1831, Val Loss=2.7010
Epoch [5/5]: Train Loss=2.9252, Val Loss=2.7014
BERT Test CPC Loss: 2.7010

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=499.7058, Val Loss=2.9757
Epoch [2/5]: Train Loss=23.7102, Val Loss=2.9169
Epoch [3/5]: Train Loss=18.1650, Val Loss=2.9134
Epoch [4/5]: Train Loss=14.8087, Val Loss=2.9214
Epoch [5/5]: Train Loss=12.8977, Val Loss=2.9248
GPT2 Test CPC Loss: 2.9247
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9697, Val Loss=1.3552
Epoch [2/5]: Train Loss=0.7833, Val Loss=0.7348
Epoch [3/5]: Train Loss=0.2734, Val Loss=0.2811
Epoch [4/5]: Train Loss=0.0563, Val Loss=0.0852
Epoch [5/5]: Train Loss=0.0114, Val Loss=0.0316
LSTM Test CPC Loss: 0.0353
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.2980, Val Loss=14.6394
Epoch [2/5]: Train Loss=10.2512, Val Loss=8.4472
Epoch [3/5]: Train Loss=5.7480, Val Loss=5.3538
Epoch [4/5]: Train Loss=3.4677, Val Loss=3.6726
Epoch [5/5]: Train Loss=2.2323, Val Loss=2.6914
Reservoir Test CPC Loss: 2.6022
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6286, Val Loss=2.9888
Epoch [2/5]: Train Loss=4.7120, Val Loss=2.9896
Epoch [3/5]: Train Loss=3.9321, Val Loss=2.9905
Epoch [4/5]: Train Loss=3.4524, Val Loss=2.9911
Epoch [5/5]: Train Loss=3.2041, Val Loss=2.9915
BERT Test CPC Loss: 2.9911

--- Fish 12: Run 7 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=329.9667, Val Loss=9.5320
Epoch [2/5]: Train Loss=27.3473, Val Loss=2.0108
Epoch [3/5]: Train Loss=16.3884, Val Loss=1.4972
Epoch [4/5]: Train Loss=12.0969, Val Loss=1.4367
Epoch [5/5]: Train Loss=9.7537, Val Loss=1.3993
GPT2 Test CPC Loss: 1.4013
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6831, Val Loss=0.0756
Epoch [2/5]: Train Loss=0.0125, Val Loss=0.0048
Epoch [3/5]: Train Loss=0.0013, Val Loss=0.0020
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0015
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0010
LSTM Test CPC Loss: 0.0014
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.0730, Val Loss=3.9899
Epoch [2/5]: Train Loss=2.7393, Val Loss=2.1129
Epoch [3/5]: Train Loss=1.4329, Val Loss=1.4550
Epoch [4/5]: Train Loss=0.8196, Val Loss=1.1420
Epoch [5/5]: Train Loss=0.4958, Val Loss=0.9610
Reservoir Test CPC Loss: 1.2921
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2570, Val Loss=1.5591
Epoch [2/5]: Train Loss=4.7903, Val Loss=1.6348
Epoch [3/5]: Train Loss=3.7573, Val Loss=1.6337
Epoch [4/5]: Train Loss=2.9653, Val Loss=1.5784
Epoch [5/5]: Train Loss=2.4283, Val Loss=1.4960
BERT Test CPC Loss: 1.4971

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=326.0916, Val Loss=2.4617
Epoch [2/5]: Train Loss=20.3189, Val Loss=3.4933
Epoch [3/5]: Train Loss=14.8598, Val Loss=2.9216
Epoch [4/5]: Train Loss=11.9141, Val Loss=2.6553
Epoch [5/5]: Train Loss=9.7152, Val Loss=2.5165
GPT2 Test CPC Loss: 2.5099
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2726, Val Loss=0.5487
Epoch [2/5]: Train Loss=0.2193, Val Loss=0.1175
Epoch [3/5]: Train Loss=0.0227, Val Loss=0.0542
Epoch [4/5]: Train Loss=0.0049, Val Loss=0.0450
Epoch [5/5]: Train Loss=0.0023, Val Loss=0.0337
LSTM Test CPC Loss: 0.0274
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.5952, Val Loss=12.2997
Epoch [2/5]: Train Loss=8.2084, Val Loss=7.2764
Epoch [3/5]: Train Loss=4.5868, Val Loss=4.9845
Epoch [4/5]: Train Loss=2.8078, Val Loss=3.6697
Epoch [5/5]: Train Loss=1.8228, Val Loss=2.8950
Reservoir Test CPC Loss: 2.5130
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7818, Val Loss=2.2753
Epoch [2/5]: Train Loss=4.7125, Val Loss=2.2751
Epoch [3/5]: Train Loss=3.7548, Val Loss=2.2769
Epoch [4/5]: Train Loss=3.0664, Val Loss=2.2774
Epoch [5/5]: Train Loss=2.6557, Val Loss=2.2801
BERT Test CPC Loss: 2.2794

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=403.5480, Val Loss=2.8342
Epoch [2/5]: Train Loss=24.7141, Val Loss=2.6917
Epoch [3/5]: Train Loss=17.6693, Val Loss=2.7054
Epoch [4/5]: Train Loss=13.5649, Val Loss=2.6595
Epoch [5/5]: Train Loss=11.3521, Val Loss=2.6644
GPT2 Test CPC Loss: 2.6613
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5541, Val Loss=0.8578
Epoch [2/5]: Train Loss=0.4013, Val Loss=0.2699
Epoch [3/5]: Train Loss=0.0597, Val Loss=0.0705
Epoch [4/5]: Train Loss=0.0092, Val Loss=0.0368
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0250
LSTM Test CPC Loss: 0.0210
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.4626, Val Loss=14.2443
Epoch [2/5]: Train Loss=9.3671, Val Loss=8.0288
Epoch [3/5]: Train Loss=5.2045, Val Loss=5.2055
Epoch [4/5]: Train Loss=3.1359, Val Loss=3.6950
Epoch [5/5]: Train Loss=2.0258, Val Loss=2.7577
Reservoir Test CPC Loss: 2.9201
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8564, Val Loss=2.6975
Epoch [2/5]: Train Loss=4.7088, Val Loss=2.6981
Epoch [3/5]: Train Loss=3.8460, Val Loss=2.6988
Epoch [4/5]: Train Loss=3.2957, Val Loss=2.6999
Epoch [5/5]: Train Loss=2.9870, Val Loss=2.7005
BERT Test CPC Loss: 2.6998

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=299.8026, Val Loss=7.3394
Epoch [2/5]: Train Loss=18.8889, Val Loss=4.0675
Epoch [3/5]: Train Loss=13.7074, Val Loss=3.3585
Epoch [4/5]: Train Loss=11.0265, Val Loss=3.0724
Epoch [5/5]: Train Loss=9.4128, Val Loss=3.0511
GPT2 Test CPC Loss: 3.0272
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8811, Val Loss=1.3615
Epoch [2/5]: Train Loss=0.6893, Val Loss=0.5822
Epoch [3/5]: Train Loss=0.1672, Val Loss=0.1375
Epoch [4/5]: Train Loss=0.0242, Val Loss=0.0436
Epoch [5/5]: Train Loss=0.0060, Val Loss=0.0296
LSTM Test CPC Loss: 0.0303
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.9736, Val Loss=12.5939
Epoch [2/5]: Train Loss=8.5514, Val Loss=7.3993
Epoch [3/5]: Train Loss=4.8210, Val Loss=4.8915
Epoch [4/5]: Train Loss=2.9360, Val Loss=3.4711
Epoch [5/5]: Train Loss=1.9022, Val Loss=2.5964
Reservoir Test CPC Loss: 2.4372
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6234, Val Loss=2.9901
Epoch [2/5]: Train Loss=4.7181, Val Loss=2.9905
Epoch [3/5]: Train Loss=3.9322, Val Loss=2.9913
Epoch [4/5]: Train Loss=3.4464, Val Loss=2.9922
Epoch [5/5]: Train Loss=3.2022, Val Loss=2.9925
BERT Test CPC Loss: 2.9921

--- Fish 12: Run 8 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=404.9834, Val Loss=1.6312
Epoch [2/5]: Train Loss=25.3880, Val Loss=1.6431
Epoch [3/5]: Train Loss=16.7347, Val Loss=1.7312
Epoch [4/5]: Train Loss=12.8365, Val Loss=1.8381
Epoch [5/5]: Train Loss=10.4077, Val Loss=1.8832
GPT2 Test CPC Loss: 1.8870
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5938, Val Loss=0.0425
Epoch [2/5]: Train Loss=0.0074, Val Loss=0.0037
Epoch [3/5]: Train Loss=0.0009, Val Loss=0.0021
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0015
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0011
LSTM Test CPC Loss: 0.0007
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.0836, Val Loss=3.9716
Epoch [2/5]: Train Loss=2.5220, Val Loss=2.6205
Epoch [3/5]: Train Loss=1.3794, Val Loss=2.0266
Epoch [4/5]: Train Loss=0.8440, Val Loss=1.7019
Epoch [5/5]: Train Loss=0.5488, Val Loss=1.4341
Reservoir Test CPC Loss: 1.2007
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3118, Val Loss=1.5274
Epoch [2/5]: Train Loss=4.8093, Val Loss=1.5425
Epoch [3/5]: Train Loss=3.7991, Val Loss=1.5705
Epoch [4/5]: Train Loss=3.0584, Val Loss=1.5499
Epoch [5/5]: Train Loss=2.5082, Val Loss=1.4910
BERT Test CPC Loss: 1.4929

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=441.2615, Val Loss=2.4179
Epoch [2/5]: Train Loss=26.1866, Val Loss=2.3517
Epoch [3/5]: Train Loss=17.8172, Val Loss=2.2844
Epoch [4/5]: Train Loss=13.2136, Val Loss=2.2457
Epoch [5/5]: Train Loss=10.5772, Val Loss=2.2400
GPT2 Test CPC Loss: 2.2413
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2438, Val Loss=0.4622
Epoch [2/5]: Train Loss=0.1681, Val Loss=0.0988
Epoch [3/5]: Train Loss=0.0165, Val Loss=0.0461
Epoch [4/5]: Train Loss=0.0041, Val Loss=0.0407
Epoch [5/5]: Train Loss=0.0021, Val Loss=0.0312
LSTM Test CPC Loss: 0.0143
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.8268, Val Loss=10.4014
Epoch [2/5]: Train Loss=7.5321, Val Loss=6.5025
Epoch [3/5]: Train Loss=4.3767, Val Loss=4.6384
Epoch [4/5]: Train Loss=2.7638, Val Loss=3.4863
Epoch [5/5]: Train Loss=1.8407, Val Loss=2.7262
Reservoir Test CPC Loss: 2.6876
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9215, Val Loss=2.2721
Epoch [2/5]: Train Loss=4.7488, Val Loss=2.2722
Epoch [3/5]: Train Loss=3.7990, Val Loss=2.2735
Epoch [4/5]: Train Loss=3.1131, Val Loss=2.2751
Epoch [5/5]: Train Loss=2.6870, Val Loss=2.2774
BERT Test CPC Loss: 2.2767

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=292.6705, Val Loss=3.5980
Epoch [2/5]: Train Loss=19.4461, Val Loss=3.1482
Epoch [3/5]: Train Loss=14.5290, Val Loss=3.1363
Epoch [4/5]: Train Loss=11.8817, Val Loss=3.0722
Epoch [5/5]: Train Loss=9.8514, Val Loss=2.8795
GPT2 Test CPC Loss: 2.8525
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5567, Val Loss=0.8512
Epoch [2/5]: Train Loss=0.3926, Val Loss=0.2480
Epoch [3/5]: Train Loss=0.0515, Val Loss=0.0687
Epoch [4/5]: Train Loss=0.0095, Val Loss=0.0485
Epoch [5/5]: Train Loss=0.0035, Val Loss=0.0367
LSTM Test CPC Loss: 0.0428
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.4235, Val Loss=13.2478
Epoch [2/5]: Train Loss=8.4016, Val Loss=7.7477
Epoch [3/5]: Train Loss=4.7293, Val Loss=5.1969
Epoch [4/5]: Train Loss=2.8895, Val Loss=3.7450
Epoch [5/5]: Train Loss=1.8923, Val Loss=2.8911
Reservoir Test CPC Loss: 2.4200
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.3306, Val Loss=2.7002
Epoch [2/5]: Train Loss=4.6588, Val Loss=2.7006
Epoch [3/5]: Train Loss=3.8025, Val Loss=2.7013
Epoch [4/5]: Train Loss=3.2590, Val Loss=2.7015
Epoch [5/5]: Train Loss=2.9720, Val Loss=2.7016
BERT Test CPC Loss: 2.7013

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=241.3327, Val Loss=3.5966
Epoch [2/5]: Train Loss=18.4272, Val Loss=3.4141
Epoch [3/5]: Train Loss=12.8147, Val Loss=3.2595
Epoch [4/5]: Train Loss=10.2536, Val Loss=3.1711
Epoch [5/5]: Train Loss=8.7647, Val Loss=3.0784
GPT2 Test CPC Loss: 3.0630
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1133, Val Loss=1.5148
Epoch [2/5]: Train Loss=0.8702, Val Loss=0.7533
Epoch [3/5]: Train Loss=0.2931, Val Loss=0.2304
Epoch [4/5]: Train Loss=0.0610, Val Loss=0.0898
Epoch [5/5]: Train Loss=0.0118, Val Loss=0.0472
LSTM Test CPC Loss: 0.0548
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.0963, Val Loss=14.7178
Epoch [2/5]: Train Loss=10.0076, Val Loss=8.7591
Epoch [3/5]: Train Loss=5.7317, Val Loss=5.7776
Epoch [4/5]: Train Loss=3.4920, Val Loss=4.0561
Epoch [5/5]: Train Loss=2.2521, Val Loss=3.0408
Reservoir Test CPC Loss: 2.9556
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4808, Val Loss=2.9919
Epoch [2/5]: Train Loss=4.7154, Val Loss=2.9924
Epoch [3/5]: Train Loss=3.9193, Val Loss=2.9932
Epoch [4/5]: Train Loss=3.4391, Val Loss=2.9932
Epoch [5/5]: Train Loss=3.2011, Val Loss=2.9932
BERT Test CPC Loss: 2.9928

--- Fish 12: Run 9 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=470.1357, Val Loss=1.8235
Epoch [2/5]: Train Loss=37.5936, Val Loss=1.9165
Epoch [3/5]: Train Loss=23.7628, Val Loss=1.9259
Epoch [4/5]: Train Loss=16.8178, Val Loss=2.0402
Epoch [5/5]: Train Loss=12.5154, Val Loss=2.0904
GPT2 Test CPC Loss: 2.1105
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6958, Val Loss=0.0626
Epoch [2/5]: Train Loss=0.0104, Val Loss=0.0045
Epoch [3/5]: Train Loss=0.0012, Val Loss=0.0018
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0016
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0011
LSTM Test CPC Loss: 0.0022
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.5693, Val Loss=5.5550
Epoch [2/5]: Train Loss=3.5651, Val Loss=3.2345
Epoch [3/5]: Train Loss=1.9483, Val Loss=2.2864
Epoch [4/5]: Train Loss=1.2218, Val Loss=1.8541
Epoch [5/5]: Train Loss=0.8002, Val Loss=1.5486
Reservoir Test CPC Loss: 1.5859
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5829, Val Loss=1.5437
Epoch [2/5]: Train Loss=4.7403, Val Loss=1.5923
Epoch [3/5]: Train Loss=3.7142, Val Loss=1.6265
Epoch [4/5]: Train Loss=3.0070, Val Loss=1.5828
Epoch [5/5]: Train Loss=2.5205, Val Loss=1.4927
BERT Test CPC Loss: 1.4972

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=439.1600, Val Loss=2.4231
Epoch [2/5]: Train Loss=26.5996, Val Loss=2.3496
Epoch [3/5]: Train Loss=16.4725, Val Loss=2.2702
Epoch [4/5]: Train Loss=12.6260, Val Loss=2.2442
Epoch [5/5]: Train Loss=9.9633, Val Loss=2.2300
GPT2 Test CPC Loss: 2.2277
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4605, Val Loss=0.7435
Epoch [2/5]: Train Loss=0.2894, Val Loss=0.1981
Epoch [3/5]: Train Loss=0.0325, Val Loss=0.0415
Epoch [4/5]: Train Loss=0.0064, Val Loss=0.0219
Epoch [5/5]: Train Loss=0.0031, Val Loss=0.0171
LSTM Test CPC Loss: 0.0149
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.8232, Val Loss=10.4507
Epoch [2/5]: Train Loss=8.2137, Val Loss=6.3552
Epoch [3/5]: Train Loss=4.8467, Val Loss=4.4035
Epoch [4/5]: Train Loss=3.0428, Val Loss=3.2151
Epoch [5/5]: Train Loss=2.0278, Val Loss=2.6089
Reservoir Test CPC Loss: 2.7233
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2055, Val Loss=2.2766
Epoch [2/5]: Train Loss=4.7389, Val Loss=2.2781
Epoch [3/5]: Train Loss=3.6583, Val Loss=2.2802
Epoch [4/5]: Train Loss=2.8311, Val Loss=2.2854
Epoch [5/5]: Train Loss=2.5165, Val Loss=2.2871
BERT Test CPC Loss: 2.2866

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=551.9129, Val Loss=3.3408
Epoch [2/5]: Train Loss=28.4572, Val Loss=3.2931
Epoch [3/5]: Train Loss=20.9439, Val Loss=2.9148
Epoch [4/5]: Train Loss=16.7923, Val Loss=2.8382
Epoch [5/5]: Train Loss=13.9527, Val Loss=2.7434
GPT2 Test CPC Loss: 2.7301
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6672, Val Loss=0.9748
Epoch [2/5]: Train Loss=0.4713, Val Loss=0.3456
Epoch [3/5]: Train Loss=0.0984, Val Loss=0.1256
Epoch [4/5]: Train Loss=0.0172, Val Loss=0.0653
Epoch [5/5]: Train Loss=0.0059, Val Loss=0.0464
LSTM Test CPC Loss: 0.0203
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.7430, Val Loss=13.6928
Epoch [2/5]: Train Loss=9.6178, Val Loss=7.9692
Epoch [3/5]: Train Loss=5.5528, Val Loss=5.2729
Epoch [4/5]: Train Loss=3.4500, Val Loss=3.7226
Epoch [5/5]: Train Loss=2.2739, Val Loss=2.7848
Reservoir Test CPC Loss: 3.0905
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4496, Val Loss=2.7003
Epoch [2/5]: Train Loss=4.6247, Val Loss=2.7008
Epoch [3/5]: Train Loss=3.8049, Val Loss=2.7010
Epoch [4/5]: Train Loss=3.2623, Val Loss=2.7012
Epoch [5/5]: Train Loss=2.9722, Val Loss=2.7015
BERT Test CPC Loss: 2.7012

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=422.5627, Val Loss=3.6677
Epoch [2/5]: Train Loss=34.6528, Val Loss=3.0219
Epoch [3/5]: Train Loss=23.9142, Val Loss=2.9332
Epoch [4/5]: Train Loss=17.9909, Val Loss=2.9218
Epoch [5/5]: Train Loss=14.7677, Val Loss=2.9123
GPT2 Test CPC Loss: 2.9143
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8598, Val Loss=1.2282
Epoch [2/5]: Train Loss=0.6250, Val Loss=0.5096
Epoch [3/5]: Train Loss=0.1189, Val Loss=0.1640
Epoch [4/5]: Train Loss=0.0142, Val Loss=0.0509
Epoch [5/5]: Train Loss=0.0044, Val Loss=0.0282
LSTM Test CPC Loss: 0.0238
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.3456, Val Loss=15.4856
Epoch [2/5]: Train Loss=10.4490, Val Loss=8.6648
Epoch [3/5]: Train Loss=5.5857, Val Loss=5.4662
Epoch [4/5]: Train Loss=3.2751, Val Loss=3.7287
Epoch [5/5]: Train Loss=2.0642, Val Loss=2.7744
Reservoir Test CPC Loss: 2.6578
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7516, Val Loss=2.9892
Epoch [2/5]: Train Loss=4.7539, Val Loss=2.9898
Epoch [3/5]: Train Loss=3.9498, Val Loss=2.9902
Epoch [4/5]: Train Loss=3.4858, Val Loss=2.9906
Epoch [5/5]: Train Loss=3.2499, Val Loss=2.9910
BERT Test CPC Loss: 2.9905

--- Fish 12: Run 10 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=529.3797, Val Loss=1.5401
Epoch [2/5]: Train Loss=29.7967, Val Loss=1.5446
Epoch [3/5]: Train Loss=21.0544, Val Loss=1.6317
Epoch [4/5]: Train Loss=16.7098, Val Loss=1.6299
Epoch [5/5]: Train Loss=13.4988, Val Loss=1.6919
GPT2 Test CPC Loss: 1.6957
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5913, Val Loss=0.0412
Epoch [2/5]: Train Loss=0.0111, Val Loss=0.0030
Epoch [3/5]: Train Loss=0.0011, Val Loss=0.0015
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0013
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0010
LSTM Test CPC Loss: 0.0011
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.2309, Val Loss=3.1179
Epoch [2/5]: Train Loss=2.1701, Val Loss=1.9025
Epoch [3/5]: Train Loss=1.1480, Val Loss=1.4416
Epoch [4/5]: Train Loss=0.6813, Val Loss=1.1547
Epoch [5/5]: Train Loss=0.4168, Val Loss=1.0039
Reservoir Test CPC Loss: 1.0690
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8554, Val Loss=1.5220
Epoch [2/5]: Train Loss=4.8272, Val Loss=1.5420
Epoch [3/5]: Train Loss=3.7746, Val Loss=1.5723
Epoch [4/5]: Train Loss=3.0103, Val Loss=1.5566
Epoch [5/5]: Train Loss=2.3907, Val Loss=1.4881
BERT Test CPC Loss: 1.4896

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=387.2094, Val Loss=4.4017
Epoch [2/5]: Train Loss=27.0245, Val Loss=2.4604
Epoch [3/5]: Train Loss=16.0837, Val Loss=2.2861
Epoch [4/5]: Train Loss=11.6879, Val Loss=2.2386
Epoch [5/5]: Train Loss=9.2687, Val Loss=2.2243
GPT2 Test CPC Loss: 2.2225
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2748, Val Loss=0.5066
Epoch [2/5]: Train Loss=0.1664, Val Loss=0.0676
Epoch [3/5]: Train Loss=0.0133, Val Loss=0.0294
Epoch [4/5]: Train Loss=0.0034, Val Loss=0.0136
Epoch [5/5]: Train Loss=0.0016, Val Loss=0.0104
LSTM Test CPC Loss: 0.0059
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.5747, Val Loss=12.0891
Epoch [2/5]: Train Loss=8.2238, Val Loss=7.1917
Epoch [3/5]: Train Loss=4.7000, Val Loss=4.9115
Epoch [4/5]: Train Loss=2.9368, Val Loss=3.7404
Epoch [5/5]: Train Loss=1.9615, Val Loss=2.9392
Reservoir Test CPC Loss: 3.0745
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6019, Val Loss=2.2778
Epoch [2/5]: Train Loss=4.6939, Val Loss=2.2800
Epoch [3/5]: Train Loss=3.7817, Val Loss=2.2825
Epoch [4/5]: Train Loss=3.1291, Val Loss=2.2834
Epoch [5/5]: Train Loss=2.7002, Val Loss=2.2834
BERT Test CPC Loss: 2.2825

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=525.5086, Val Loss=4.9822
Epoch [2/5]: Train Loss=36.9576, Val Loss=3.2322
Epoch [3/5]: Train Loss=24.3924, Val Loss=2.7036
Epoch [4/5]: Train Loss=18.6037, Val Loss=2.6736
Epoch [5/5]: Train Loss=14.7979, Val Loss=2.6746
GPT2 Test CPC Loss: 2.6802
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9119, Val Loss=1.1068
Epoch [2/5]: Train Loss=0.5532, Val Loss=0.3484
Epoch [3/5]: Train Loss=0.0863, Val Loss=0.0799
Epoch [4/5]: Train Loss=0.0106, Val Loss=0.0339
Epoch [5/5]: Train Loss=0.0035, Val Loss=0.0257
LSTM Test CPC Loss: 0.0185
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.2386, Val Loss=15.2741
Epoch [2/5]: Train Loss=10.5592, Val Loss=9.1284
Epoch [3/5]: Train Loss=5.9642, Val Loss=5.9930
Epoch [4/5]: Train Loss=3.6508, Val Loss=4.2557
Epoch [5/5]: Train Loss=2.3716, Val Loss=3.2417
Reservoir Test CPC Loss: 3.3379
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6732, Val Loss=2.6971
Epoch [2/5]: Train Loss=4.6589, Val Loss=2.6969
Epoch [3/5]: Train Loss=3.8101, Val Loss=2.6981
Epoch [4/5]: Train Loss=3.2597, Val Loss=2.6988
Epoch [5/5]: Train Loss=2.9741, Val Loss=2.6994
BERT Test CPC Loss: 2.6991

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=340.7417, Val Loss=2.9733
Epoch [2/5]: Train Loss=25.3856, Val Loss=2.9320
Epoch [3/5]: Train Loss=16.3342, Val Loss=2.9372
Epoch [4/5]: Train Loss=12.3001, Val Loss=2.9371
Epoch [5/5]: Train Loss=10.0193, Val Loss=2.9360
GPT2 Test CPC Loss: 2.9373
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9668, Val Loss=1.4124
Epoch [2/5]: Train Loss=0.7749, Val Loss=0.6646
Epoch [3/5]: Train Loss=0.2388, Val Loss=0.2394
Epoch [4/5]: Train Loss=0.0472, Val Loss=0.0857
Epoch [5/5]: Train Loss=0.0103, Val Loss=0.0358
LSTM Test CPC Loss: 0.0335
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.6357, Val Loss=14.9995
Epoch [2/5]: Train Loss=9.5238, Val Loss=8.6307
Epoch [3/5]: Train Loss=5.3228, Val Loss=5.4346
Epoch [4/5]: Train Loss=3.2068, Val Loss=3.7293
Epoch [5/5]: Train Loss=2.0754, Val Loss=2.7419
Reservoir Test CPC Loss: 2.7929
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4855, Val Loss=2.9893
Epoch [2/5]: Train Loss=4.7158, Val Loss=2.9897
Epoch [3/5]: Train Loss=3.9112, Val Loss=2.9906
Epoch [4/5]: Train Loss=3.4251, Val Loss=2.9908
Epoch [5/5]: Train Loss=3.1925, Val Loss=2.9912
BERT Test CPC Loss: 2.9907

========== Processing Fish 13 ==========
Fish 13: Neural data shape: (2793, 9336)

--- Fish 13: Run 1 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=387.2247, Val Loss=37.1994
Epoch [2/5]: Train Loss=26.2236, Val Loss=33.0508
Epoch [3/5]: Train Loss=16.0129, Val Loss=18.8973
Epoch [4/5]: Train Loss=10.8864, Val Loss=14.3097
Epoch [5/5]: Train Loss=8.5048, Val Loss=13.6663
GPT2 Test CPC Loss: 11.4041
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6728, Val Loss=0.0812
Epoch [2/5]: Train Loss=0.0159, Val Loss=0.0072
Epoch [3/5]: Train Loss=0.0017, Val Loss=0.0039
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0025
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0018
LSTM Test CPC Loss: 0.0020
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.7620, Val Loss=3.7309
Epoch [2/5]: Train Loss=2.5818, Val Loss=1.6423
Epoch [3/5]: Train Loss=1.3204, Val Loss=0.9364
Epoch [4/5]: Train Loss=0.7711, Val Loss=0.6868
Epoch [5/5]: Train Loss=0.4676, Val Loss=0.5610
Reservoir Test CPC Loss: 1.3026
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1432, Val Loss=1.6244
Epoch [2/5]: Train Loss=4.7784, Val Loss=1.7906
Epoch [3/5]: Train Loss=3.8039, Val Loss=1.8460
Epoch [4/5]: Train Loss=3.1475, Val Loss=1.7227
Epoch [5/5]: Train Loss=2.6455, Val Loss=1.6118
BERT Test CPC Loss: 1.5853

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=441.3303, Val Loss=2.6306
Epoch [2/5]: Train Loss=26.9364, Val Loss=2.2055
Epoch [3/5]: Train Loss=19.1924, Val Loss=2.2302
Epoch [4/5]: Train Loss=15.2174, Val Loss=2.2508
Epoch [5/5]: Train Loss=12.7776, Val Loss=2.2513
GPT2 Test CPC Loss: 2.2363
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1647, Val Loss=0.4285
Epoch [2/5]: Train Loss=0.1178, Val Loss=0.0628
Epoch [3/5]: Train Loss=0.0120, Val Loss=0.0207
Epoch [4/5]: Train Loss=0.0024, Val Loss=0.0166
Epoch [5/5]: Train Loss=0.0013, Val Loss=0.0132
LSTM Test CPC Loss: 0.0254
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.7643, Val Loss=10.2978
Epoch [2/5]: Train Loss=7.0493, Val Loss=5.8775
Epoch [3/5]: Train Loss=3.9041, Val Loss=3.7409
Epoch [4/5]: Train Loss=2.3598, Val Loss=2.6334
Epoch [5/5]: Train Loss=1.5199, Val Loss=1.9912
Reservoir Test CPC Loss: 2.5693
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1229, Val Loss=2.2710
Epoch [2/5]: Train Loss=4.8083, Val Loss=2.2705
Epoch [3/5]: Train Loss=3.8544, Val Loss=2.2712
Epoch [4/5]: Train Loss=3.1760, Val Loss=2.2700
Epoch [5/5]: Train Loss=2.7425, Val Loss=2.2688
BERT Test CPC Loss: 2.2706

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=425.2753, Val Loss=2.8321
Epoch [2/5]: Train Loss=22.5641, Val Loss=2.6421
Epoch [3/5]: Train Loss=16.1186, Val Loss=2.6453
Epoch [4/5]: Train Loss=12.7910, Val Loss=2.6425
Epoch [5/5]: Train Loss=10.8719, Val Loss=2.6382
GPT2 Test CPC Loss: 2.6262
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4721, Val Loss=0.8625
Epoch [2/5]: Train Loss=0.3809, Val Loss=0.1950
Epoch [3/5]: Train Loss=0.0457, Val Loss=0.0673
Epoch [4/5]: Train Loss=0.0089, Val Loss=0.0406
Epoch [5/5]: Train Loss=0.0033, Val Loss=0.0269
LSTM Test CPC Loss: 0.0561
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.8666, Val Loss=17.3054
Epoch [2/5]: Train Loss=9.9367, Val Loss=8.5406
Epoch [3/5]: Train Loss=5.1622, Val Loss=4.9499
Epoch [4/5]: Train Loss=2.9740, Val Loss=3.1836
Epoch [5/5]: Train Loss=1.8706, Val Loss=2.3252
Reservoir Test CPC Loss: 2.9514
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8989, Val Loss=2.6943
Epoch [2/5]: Train Loss=4.7051, Val Loss=2.6964
Epoch [3/5]: Train Loss=3.8492, Val Loss=2.6978
Epoch [4/5]: Train Loss=3.2898, Val Loss=2.6988
Epoch [5/5]: Train Loss=2.9832, Val Loss=2.6991
BERT Test CPC Loss: 2.6997

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=288.0425, Val Loss=2.9208
Epoch [2/5]: Train Loss=16.1485, Val Loss=2.9440
Epoch [3/5]: Train Loss=12.1754, Val Loss=2.9584
Epoch [4/5]: Train Loss=9.9832, Val Loss=2.9567
Epoch [5/5]: Train Loss=8.5409, Val Loss=2.9570
GPT2 Test CPC Loss: 2.9358
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9648, Val Loss=1.3198
Epoch [2/5]: Train Loss=0.6914, Val Loss=0.3995
Epoch [3/5]: Train Loss=0.1239, Val Loss=0.0747
Epoch [4/5]: Train Loss=0.0175, Val Loss=0.0370
Epoch [5/5]: Train Loss=0.0054, Val Loss=0.0275
LSTM Test CPC Loss: 0.0382
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.3633, Val Loss=14.8400
Epoch [2/5]: Train Loss=9.8167, Val Loss=7.8559
Epoch [3/5]: Train Loss=5.0907, Val Loss=4.7220
Epoch [4/5]: Train Loss=2.9057, Val Loss=3.2049
Epoch [5/5]: Train Loss=1.8189, Val Loss=2.3280
Reservoir Test CPC Loss: 3.8102
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1721, Val Loss=2.9865
Epoch [2/5]: Train Loss=4.7118, Val Loss=2.9883
Epoch [3/5]: Train Loss=3.9345, Val Loss=2.9900
Epoch [4/5]: Train Loss=3.4713, Val Loss=2.9902
Epoch [5/5]: Train Loss=3.2301, Val Loss=2.9907
BERT Test CPC Loss: 2.9908

--- Fish 13: Run 2 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=330.0029, Val Loss=23.8405
Epoch [2/5]: Train Loss=24.6207, Val Loss=19.4976
Epoch [3/5]: Train Loss=15.5521, Val Loss=18.8594
Epoch [4/5]: Train Loss=11.6054, Val Loss=15.9524
Epoch [5/5]: Train Loss=9.0661, Val Loss=14.3801
GPT2 Test CPC Loss: 12.1265
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6684, Val Loss=0.0544
Epoch [2/5]: Train Loss=0.0084, Val Loss=0.0065
Epoch [3/5]: Train Loss=0.0012, Val Loss=0.0036
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0027
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0021
LSTM Test CPC Loss: 0.0012
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.2060, Val Loss=3.9679
Epoch [2/5]: Train Loss=2.4234, Val Loss=2.1743
Epoch [3/5]: Train Loss=1.2476, Val Loss=1.5646
Epoch [4/5]: Train Loss=0.7500, Val Loss=1.1539
Epoch [5/5]: Train Loss=0.4668, Val Loss=0.9678
Reservoir Test CPC Loss: 2.0741
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4928, Val Loss=1.5294
Epoch [2/5]: Train Loss=4.9563, Val Loss=1.6480
Epoch [3/5]: Train Loss=3.9217, Val Loss=1.7244
Epoch [4/5]: Train Loss=3.2021, Val Loss=1.6618
Epoch [5/5]: Train Loss=2.6426, Val Loss=1.5772
BERT Test CPC Loss: 1.5560

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=499.7331, Val Loss=3.5251
Epoch [2/5]: Train Loss=32.8232, Val Loss=2.5401
Epoch [3/5]: Train Loss=19.0354, Val Loss=2.2369
Epoch [4/5]: Train Loss=13.2533, Val Loss=2.2091
Epoch [5/5]: Train Loss=10.3340, Val Loss=2.2015
GPT2 Test CPC Loss: 2.1827
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1750, Val Loss=0.4447
Epoch [2/5]: Train Loss=0.1099, Val Loss=0.0740
Epoch [3/5]: Train Loss=0.0089, Val Loss=0.0370
Epoch [4/5]: Train Loss=0.0026, Val Loss=0.0251
Epoch [5/5]: Train Loss=0.0013, Val Loss=0.0205
LSTM Test CPC Loss: 0.0114
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.6037, Val Loss=9.4008
Epoch [2/5]: Train Loss=6.9939, Val Loss=4.9498
Epoch [3/5]: Train Loss=3.9044, Val Loss=3.2104
Epoch [4/5]: Train Loss=2.3920, Val Loss=2.1984
Epoch [5/5]: Train Loss=1.5517, Val Loss=1.7023
Reservoir Test CPC Loss: 2.6323
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0565, Val Loss=2.2670
Epoch [2/5]: Train Loss=4.7217, Val Loss=2.2649
Epoch [3/5]: Train Loss=3.7710, Val Loss=2.2627
Epoch [4/5]: Train Loss=3.0874, Val Loss=2.2629
Epoch [5/5]: Train Loss=2.6676, Val Loss=2.2646
BERT Test CPC Loss: 2.2663

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=363.7900, Val Loss=2.7205
Epoch [2/5]: Train Loss=22.9839, Val Loss=2.6950
Epoch [3/5]: Train Loss=16.5383, Val Loss=2.6710
Epoch [4/5]: Train Loss=13.1443, Val Loss=2.6882
Epoch [5/5]: Train Loss=11.0755, Val Loss=2.6860
GPT2 Test CPC Loss: 2.6739
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7146, Val Loss=0.9001
Epoch [2/5]: Train Loss=0.4025, Val Loss=0.2217
Epoch [3/5]: Train Loss=0.0517, Val Loss=0.0650
Epoch [4/5]: Train Loss=0.0097, Val Loss=0.0342
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0250
LSTM Test CPC Loss: 0.0254
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.4543, Val Loss=13.5129
Epoch [2/5]: Train Loss=8.5861, Val Loss=6.9866
Epoch [3/5]: Train Loss=4.5312, Val Loss=4.1854
Epoch [4/5]: Train Loss=2.6306, Val Loss=2.8292
Epoch [5/5]: Train Loss=1.6491, Val Loss=2.0847
Reservoir Test CPC Loss: 3.3456
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8535, Val Loss=2.6885
Epoch [2/5]: Train Loss=4.6931, Val Loss=2.6902
Epoch [3/5]: Train Loss=3.8317, Val Loss=2.6922
Epoch [4/5]: Train Loss=3.2914, Val Loss=2.6920
Epoch [5/5]: Train Loss=2.9905, Val Loss=2.6927
BERT Test CPC Loss: 2.6935

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=302.0210, Val Loss=3.2589
Epoch [2/5]: Train Loss=24.7438, Val Loss=3.0229
Epoch [3/5]: Train Loss=17.1588, Val Loss=2.9820
Epoch [4/5]: Train Loss=13.2573, Val Loss=2.9662
Epoch [5/5]: Train Loss=10.8447, Val Loss=2.9484
GPT2 Test CPC Loss: 2.9246
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1577, Val Loss=1.4760
Epoch [2/5]: Train Loss=0.8173, Val Loss=0.6042
Epoch [3/5]: Train Loss=0.1880, Val Loss=0.1346
Epoch [4/5]: Train Loss=0.0278, Val Loss=0.0525
Epoch [5/5]: Train Loss=0.0077, Val Loss=0.0378
LSTM Test CPC Loss: 0.0985
[Model: Reservoir]
Epoch [1/5]: Train Loss=28.0187, Val Loss=16.9690
Epoch [2/5]: Train Loss=10.8625, Val Loss=8.1741
Epoch [3/5]: Train Loss=5.4078, Val Loss=4.6303
Epoch [4/5]: Train Loss=3.0313, Val Loss=2.9538
Epoch [5/5]: Train Loss=1.8734, Val Loss=2.0816
Reservoir Test CPC Loss: 2.8370
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7807, Val Loss=2.9867
Epoch [2/5]: Train Loss=4.7210, Val Loss=2.9877
Epoch [3/5]: Train Loss=3.9518, Val Loss=2.9894
Epoch [4/5]: Train Loss=3.4730, Val Loss=2.9901
Epoch [5/5]: Train Loss=3.2107, Val Loss=2.9906
BERT Test CPC Loss: 2.9908

--- Fish 13: Run 3 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=384.1830, Val Loss=3.4124
Epoch [2/5]: Train Loss=31.3003, Val Loss=1.6359
Epoch [3/5]: Train Loss=20.1021, Val Loss=1.4713
Epoch [4/5]: Train Loss=14.6628, Val Loss=1.4360
Epoch [5/5]: Train Loss=11.7376, Val Loss=1.4177
GPT2 Test CPC Loss: 1.4067
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6665, Val Loss=0.0848
Epoch [2/5]: Train Loss=0.0081, Val Loss=0.0085
Epoch [3/5]: Train Loss=0.0009, Val Loss=0.0071
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0053
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0039
LSTM Test CPC Loss: 0.0014
[Model: Reservoir]
Epoch [1/5]: Train Loss=13.1841, Val Loss=5.4271
Epoch [2/5]: Train Loss=3.6647, Val Loss=2.3199
Epoch [3/5]: Train Loss=1.9203, Val Loss=1.3223
Epoch [4/5]: Train Loss=1.1302, Val Loss=0.9114
Epoch [5/5]: Train Loss=0.6976, Val Loss=0.6950
Reservoir Test CPC Loss: 1.8060
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1178, Val Loss=1.5420
Epoch [2/5]: Train Loss=4.8031, Val Loss=1.7176
Epoch [3/5]: Train Loss=3.7724, Val Loss=1.7987
Epoch [4/5]: Train Loss=3.0541, Val Loss=1.6930
Epoch [5/5]: Train Loss=2.5067, Val Loss=1.5533
BERT Test CPC Loss: 1.5336

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=543.5929, Val Loss=12.6345
Epoch [2/5]: Train Loss=31.6313, Val Loss=9.9854
Epoch [3/5]: Train Loss=21.6639, Val Loss=6.7735
Epoch [4/5]: Train Loss=17.0183, Val Loss=4.7087
Epoch [5/5]: Train Loss=14.1656, Val Loss=5.9635
GPT2 Test CPC Loss: 4.8795
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3563, Val Loss=0.5654
Epoch [2/5]: Train Loss=0.1361, Val Loss=0.0921
Epoch [3/5]: Train Loss=0.0107, Val Loss=0.0762
Epoch [4/5]: Train Loss=0.0030, Val Loss=0.0564
Epoch [5/5]: Train Loss=0.0016, Val Loss=0.0428
LSTM Test CPC Loss: 0.0288
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.1836, Val Loss=12.6371
Epoch [2/5]: Train Loss=6.7360, Val Loss=6.9981
Epoch [3/5]: Train Loss=3.6511, Val Loss=4.5583
Epoch [4/5]: Train Loss=2.1973, Val Loss=3.2141
Epoch [5/5]: Train Loss=1.4186, Val Loss=2.4692
Reservoir Test CPC Loss: 3.0385
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9824, Val Loss=2.2728
Epoch [2/5]: Train Loss=4.7364, Val Loss=2.2722
Epoch [3/5]: Train Loss=3.7843, Val Loss=2.2715
Epoch [4/5]: Train Loss=3.0629, Val Loss=2.2730
Epoch [5/5]: Train Loss=2.6169, Val Loss=2.2759
BERT Test CPC Loss: 2.2771

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=436.9368, Val Loss=2.6798
Epoch [2/5]: Train Loss=18.8305, Val Loss=2.6312
Epoch [3/5]: Train Loss=13.8708, Val Loss=2.6507
Epoch [4/5]: Train Loss=11.3741, Val Loss=2.6711
Epoch [5/5]: Train Loss=9.6466, Val Loss=2.6788
GPT2 Test CPC Loss: 2.6696
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7639, Val Loss=0.9709
Epoch [2/5]: Train Loss=0.4642, Val Loss=0.2144
Epoch [3/5]: Train Loss=0.0723, Val Loss=0.1011
Epoch [4/5]: Train Loss=0.0123, Val Loss=0.0353
Epoch [5/5]: Train Loss=0.0043, Val Loss=0.0252
LSTM Test CPC Loss: 0.1074
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.9527, Val Loss=12.8635
Epoch [2/5]: Train Loss=9.0896, Val Loss=6.9664
Epoch [3/5]: Train Loss=4.9720, Val Loss=4.3076
Epoch [4/5]: Train Loss=2.9640, Val Loss=2.9681
Epoch [5/5]: Train Loss=1.8951, Val Loss=2.2644
Reservoir Test CPC Loss: 3.5933
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3693, Val Loss=2.6978
Epoch [2/5]: Train Loss=4.7787, Val Loss=2.6974
Epoch [3/5]: Train Loss=3.8819, Val Loss=2.6986
Epoch [4/5]: Train Loss=3.2722, Val Loss=2.6994
Epoch [5/5]: Train Loss=2.9579, Val Loss=2.6998
BERT Test CPC Loss: 2.7004

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=392.5388, Val Loss=2.9898
Epoch [2/5]: Train Loss=22.3669, Val Loss=2.9622
Epoch [3/5]: Train Loss=15.2064, Val Loss=2.9617
Epoch [4/5]: Train Loss=11.3592, Val Loss=2.9614
Epoch [5/5]: Train Loss=9.3482, Val Loss=2.9592
GPT2 Test CPC Loss: 2.9393
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9135, Val Loss=1.3193
Epoch [2/5]: Train Loss=0.6505, Val Loss=0.3591
Epoch [3/5]: Train Loss=0.0947, Val Loss=0.0603
Epoch [4/5]: Train Loss=0.0118, Val Loss=0.0225
Epoch [5/5]: Train Loss=0.0037, Val Loss=0.0164
LSTM Test CPC Loss: 0.0451
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.5956, Val Loss=18.8059
Epoch [2/5]: Train Loss=10.9156, Val Loss=10.1752
Epoch [3/5]: Train Loss=5.9139, Val Loss=6.3402
Epoch [4/5]: Train Loss=3.5077, Val Loss=4.3300
Epoch [5/5]: Train Loss=2.2242, Val Loss=3.1642
Reservoir Test CPC Loss: 3.3587
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0854, Val Loss=2.9902
Epoch [2/5]: Train Loss=4.7816, Val Loss=2.9888
Epoch [3/5]: Train Loss=3.9963, Val Loss=2.9891
Epoch [4/5]: Train Loss=3.5142, Val Loss=2.9894
Epoch [5/5]: Train Loss=3.2484, Val Loss=2.9898
BERT Test CPC Loss: 2.9899

--- Fish 13: Run 4 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=423.1027, Val Loss=16.6275
Epoch [2/5]: Train Loss=30.4356, Val Loss=7.0277
Epoch [3/5]: Train Loss=21.1087, Val Loss=5.3832
Epoch [4/5]: Train Loss=16.0514, Val Loss=3.6198
Epoch [5/5]: Train Loss=12.4996, Val Loss=3.4832
GPT2 Test CPC Loss: 2.9533
[Model: LSTM]
Epoch [1/5]: Train Loss=0.8376, Val Loss=0.1275
Epoch [2/5]: Train Loss=0.0164, Val Loss=0.0075
Epoch [3/5]: Train Loss=0.0014, Val Loss=0.0038
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0026
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0020
LSTM Test CPC Loss: 0.0017
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.2368, Val Loss=4.8078
Epoch [2/5]: Train Loss=3.1912, Val Loss=2.0781
Epoch [3/5]: Train Loss=1.6420, Val Loss=1.2867
Epoch [4/5]: Train Loss=0.9757, Val Loss=0.9042
Epoch [5/5]: Train Loss=0.6139, Val Loss=0.7461
Reservoir Test CPC Loss: 1.5353
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.7299, Val Loss=1.6528
Epoch [2/5]: Train Loss=4.9762, Val Loss=1.7591
Epoch [3/5]: Train Loss=3.9420, Val Loss=1.8266
Epoch [4/5]: Train Loss=3.2124, Val Loss=1.7510
Epoch [5/5]: Train Loss=2.6115, Val Loss=1.5853
BERT Test CPC Loss: 1.5628

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=419.5365, Val Loss=2.3217
Epoch [2/5]: Train Loss=24.6256, Val Loss=2.2309
Epoch [3/5]: Train Loss=15.8723, Val Loss=2.2101
Epoch [4/5]: Train Loss=11.8238, Val Loss=2.2030
Epoch [5/5]: Train Loss=9.4104, Val Loss=2.2054
GPT2 Test CPC Loss: 2.1996
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2915, Val Loss=0.4408
Epoch [2/5]: Train Loss=0.1377, Val Loss=0.0682
Epoch [3/5]: Train Loss=0.0125, Val Loss=0.0271
Epoch [4/5]: Train Loss=0.0034, Val Loss=0.0188
Epoch [5/5]: Train Loss=0.0016, Val Loss=0.0143
LSTM Test CPC Loss: 0.0373
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.4940, Val Loss=12.1281
Epoch [2/5]: Train Loss=7.7134, Val Loss=6.6140
Epoch [3/5]: Train Loss=4.1443, Val Loss=4.1630
Epoch [4/5]: Train Loss=2.4362, Val Loss=2.8690
Epoch [5/5]: Train Loss=1.5401, Val Loss=2.1657
Reservoir Test CPC Loss: 2.5769
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.5302, Val Loss=2.2664
Epoch [2/5]: Train Loss=4.8442, Val Loss=2.2663
Epoch [3/5]: Train Loss=3.9099, Val Loss=2.2708
Epoch [4/5]: Train Loss=3.2527, Val Loss=2.2701
Epoch [5/5]: Train Loss=2.8158, Val Loss=2.2684
BERT Test CPC Loss: 2.2695

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=270.7287, Val Loss=2.9324
Epoch [2/5]: Train Loss=17.9384, Val Loss=2.5729
Epoch [3/5]: Train Loss=13.0947, Val Loss=2.5981
Epoch [4/5]: Train Loss=10.5538, Val Loss=2.6069
Epoch [5/5]: Train Loss=9.0036, Val Loss=2.6009
GPT2 Test CPC Loss: 2.5985
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7603, Val Loss=0.8898
Epoch [2/5]: Train Loss=0.3762, Val Loss=0.2031
Epoch [3/5]: Train Loss=0.0418, Val Loss=0.0492
Epoch [4/5]: Train Loss=0.0077, Val Loss=0.0259
Epoch [5/5]: Train Loss=0.0033, Val Loss=0.0231
LSTM Test CPC Loss: 0.0284
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.8495, Val Loss=16.2887
Epoch [2/5]: Train Loss=8.7053, Val Loss=8.4070
Epoch [3/5]: Train Loss=4.4164, Val Loss=4.9401
Epoch [4/5]: Train Loss=2.5218, Val Loss=3.3110
Epoch [5/5]: Train Loss=1.5779, Val Loss=2.4557
Reservoir Test CPC Loss: 2.9635
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9979, Val Loss=2.7001
Epoch [2/5]: Train Loss=4.6857, Val Loss=2.6986
Epoch [3/5]: Train Loss=3.7934, Val Loss=2.7000
Epoch [4/5]: Train Loss=3.2091, Val Loss=2.7007
Epoch [5/5]: Train Loss=2.9376, Val Loss=2.7008
BERT Test CPC Loss: 2.7011

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=453.3081, Val Loss=4.1429
Epoch [2/5]: Train Loss=23.1077, Val Loss=3.0114
Epoch [3/5]: Train Loss=17.3768, Val Loss=3.0175
Epoch [4/5]: Train Loss=14.0165, Val Loss=3.0405
Epoch [5/5]: Train Loss=12.0568, Val Loss=3.0017
GPT2 Test CPC Loss: 2.9535
[Model: LSTM]
Epoch [1/5]: Train Loss=2.2235, Val Loss=1.4643
Epoch [2/5]: Train Loss=0.8715, Val Loss=0.5434
Epoch [3/5]: Train Loss=0.1936, Val Loss=0.1034
Epoch [4/5]: Train Loss=0.0232, Val Loss=0.0412
Epoch [5/5]: Train Loss=0.0062, Val Loss=0.0267
LSTM Test CPC Loss: 0.0500
[Model: Reservoir]
Epoch [1/5]: Train Loss=27.4596, Val Loss=19.0855
Epoch [2/5]: Train Loss=10.6204, Val Loss=9.5584
Epoch [3/5]: Train Loss=5.3104, Val Loss=5.5095
Epoch [4/5]: Train Loss=2.9458, Val Loss=3.5571
Epoch [5/5]: Train Loss=1.8060, Val Loss=2.5810
Reservoir Test CPC Loss: 4.0399
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9277, Val Loss=2.9880
Epoch [2/5]: Train Loss=4.7271, Val Loss=2.9872
Epoch [3/5]: Train Loss=3.8853, Val Loss=2.9872
Epoch [4/5]: Train Loss=3.4008, Val Loss=2.9875
Epoch [5/5]: Train Loss=3.1893, Val Loss=2.9882
BERT Test CPC Loss: 2.9885

--- Fish 13: Run 5 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=400.0234, Val Loss=2.3263
Epoch [2/5]: Train Loss=32.4625, Val Loss=2.9161
Epoch [3/5]: Train Loss=20.3611, Val Loss=2.1077
Epoch [4/5]: Train Loss=14.0751, Val Loss=1.8470
Epoch [5/5]: Train Loss=11.0196, Val Loss=1.7099
GPT2 Test CPC Loss: 1.6614
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6804, Val Loss=0.0711
Epoch [2/5]: Train Loss=0.0124, Val Loss=0.0088
Epoch [3/5]: Train Loss=0.0016, Val Loss=0.0062
Epoch [4/5]: Train Loss=0.0008, Val Loss=0.0041
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0035
LSTM Test CPC Loss: 0.0045
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.4143, Val Loss=4.2596
Epoch [2/5]: Train Loss=2.6810, Val Loss=2.2052
Epoch [3/5]: Train Loss=1.3067, Val Loss=1.5078
Epoch [4/5]: Train Loss=0.7221, Val Loss=1.2551
Epoch [5/5]: Train Loss=0.4452, Val Loss=1.0704
Reservoir Test CPC Loss: 2.0736
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0831, Val Loss=1.5700
Epoch [2/5]: Train Loss=4.8261, Val Loss=1.6719
Epoch [3/5]: Train Loss=3.7710, Val Loss=1.7318
Epoch [4/5]: Train Loss=2.9897, Val Loss=1.6408
Epoch [5/5]: Train Loss=2.4059, Val Loss=1.5285
BERT Test CPC Loss: 1.5146

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=371.8938, Val Loss=2.2634
Epoch [2/5]: Train Loss=20.6260, Val Loss=2.2534
Epoch [3/5]: Train Loss=12.8955, Val Loss=2.2350
Epoch [4/5]: Train Loss=9.5240, Val Loss=2.2171
Epoch [5/5]: Train Loss=7.7699, Val Loss=2.2160
GPT2 Test CPC Loss: 2.2129
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1783, Val Loss=0.3770
Epoch [2/5]: Train Loss=0.1136, Val Loss=0.0555
Epoch [3/5]: Train Loss=0.0089, Val Loss=0.0197
Epoch [4/5]: Train Loss=0.0028, Val Loss=0.0135
Epoch [5/5]: Train Loss=0.0014, Val Loss=0.0118
LSTM Test CPC Loss: 0.0160
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.1223, Val Loss=13.2296
Epoch [2/5]: Train Loss=6.7820, Val Loss=7.0536
Epoch [3/5]: Train Loss=3.5705, Val Loss=4.3895
Epoch [4/5]: Train Loss=2.0943, Val Loss=3.1314
Epoch [5/5]: Train Loss=1.3195, Val Loss=2.3698
Reservoir Test CPC Loss: 3.2524
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4559, Val Loss=2.2830
Epoch [2/5]: Train Loss=4.8213, Val Loss=2.2789
Epoch [3/5]: Train Loss=3.8337, Val Loss=2.2790
Epoch [4/5]: Train Loss=3.1020, Val Loss=2.2792
Epoch [5/5]: Train Loss=2.6702, Val Loss=2.2806
BERT Test CPC Loss: 2.2818

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=445.2384, Val Loss=2.8324
Epoch [2/5]: Train Loss=30.7014, Val Loss=2.6597
Epoch [3/5]: Train Loss=19.0611, Val Loss=2.6618
Epoch [4/5]: Train Loss=13.8096, Val Loss=2.6594
Epoch [5/5]: Train Loss=11.1393, Val Loss=2.6553
GPT2 Test CPC Loss: 2.6350
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4743, Val Loss=0.7407
Epoch [2/5]: Train Loss=0.2821, Val Loss=0.1390
Epoch [3/5]: Train Loss=0.0367, Val Loss=0.0448
Epoch [4/5]: Train Loss=0.0083, Val Loss=0.0356
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0197
LSTM Test CPC Loss: 0.0526
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.1222, Val Loss=13.0847
Epoch [2/5]: Train Loss=8.9378, Val Loss=6.9157
Epoch [3/5]: Train Loss=4.7690, Val Loss=4.1797
Epoch [4/5]: Train Loss=2.8021, Val Loss=2.7726
Epoch [5/5]: Train Loss=1.7836, Val Loss=2.0046
Reservoir Test CPC Loss: 2.6231
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4605, Val Loss=2.6937
Epoch [2/5]: Train Loss=4.6283, Val Loss=2.6960
Epoch [3/5]: Train Loss=3.6859, Val Loss=2.6962
Epoch [4/5]: Train Loss=3.1022, Val Loss=2.6982
Epoch [5/5]: Train Loss=2.8774, Val Loss=2.6995
BERT Test CPC Loss: 2.7001

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=376.3042, Val Loss=3.3768
Epoch [2/5]: Train Loss=24.9194, Val Loss=3.0508
Epoch [3/5]: Train Loss=16.7484, Val Loss=3.0293
Epoch [4/5]: Train Loss=13.0502, Val Loss=2.9935
Epoch [5/5]: Train Loss=10.6384, Val Loss=3.0145
GPT2 Test CPC Loss: 2.9777
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9386, Val Loss=1.2722
Epoch [2/5]: Train Loss=0.6044, Val Loss=0.3541
Epoch [3/5]: Train Loss=0.1011, Val Loss=0.0895
Epoch [4/5]: Train Loss=0.0151, Val Loss=0.0497
Epoch [5/5]: Train Loss=0.0047, Val Loss=0.0302
LSTM Test CPC Loss: 0.0593
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.0426, Val Loss=15.4565
Epoch [2/5]: Train Loss=8.9745, Val Loss=8.0008
Epoch [3/5]: Train Loss=4.7782, Val Loss=4.7358
Epoch [4/5]: Train Loss=2.7434, Val Loss=3.0610
Epoch [5/5]: Train Loss=1.7170, Val Loss=2.1819
Reservoir Test CPC Loss: 2.7876
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1965, Val Loss=2.9917
Epoch [2/5]: Train Loss=4.7784, Val Loss=2.9908
Epoch [3/5]: Train Loss=3.9097, Val Loss=2.9902
Epoch [4/5]: Train Loss=3.3709, Val Loss=2.9901
Epoch [5/5]: Train Loss=3.1579, Val Loss=2.9907
BERT Test CPC Loss: 2.9910

--- Fish 13: Run 6 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=386.9908, Val Loss=3.0836
Epoch [2/5]: Train Loss=29.2189, Val Loss=1.5949
Epoch [3/5]: Train Loss=18.0374, Val Loss=1.4299
Epoch [4/5]: Train Loss=12.7532, Val Loss=1.4074
Epoch [5/5]: Train Loss=10.2266, Val Loss=1.3972
GPT2 Test CPC Loss: 1.3909
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7795, Val Loss=0.0660
Epoch [2/5]: Train Loss=0.0080, Val Loss=0.0039
Epoch [3/5]: Train Loss=0.0008, Val Loss=0.0022
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0017
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0012
LSTM Test CPC Loss: 0.0012
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.8279, Val Loss=4.3149
Epoch [2/5]: Train Loss=2.5810, Val Loss=2.3762
Epoch [3/5]: Train Loss=1.3223, Val Loss=1.6325
Epoch [4/5]: Train Loss=0.7584, Val Loss=1.1762
Epoch [5/5]: Train Loss=0.4566, Val Loss=0.9527
Reservoir Test CPC Loss: 1.9052
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4915, Val Loss=1.5694
Epoch [2/5]: Train Loss=4.8930, Val Loss=1.7061
Epoch [3/5]: Train Loss=3.9710, Val Loss=1.7394
Epoch [4/5]: Train Loss=3.2555, Val Loss=1.7410
Epoch [5/5]: Train Loss=2.7074, Val Loss=1.5990
BERT Test CPC Loss: 1.5725

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=464.1974, Val Loss=3.5233
Epoch [2/5]: Train Loss=24.7013, Val Loss=2.2580
Epoch [3/5]: Train Loss=18.0764, Val Loss=2.2017
Epoch [4/5]: Train Loss=14.4890, Val Loss=2.2251
Epoch [5/5]: Train Loss=12.0960, Val Loss=2.2334
GPT2 Test CPC Loss: 2.2403
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3326, Val Loss=0.5638
Epoch [2/5]: Train Loss=0.1738, Val Loss=0.1197
Epoch [3/5]: Train Loss=0.0155, Val Loss=0.0414
Epoch [4/5]: Train Loss=0.0043, Val Loss=0.0378
Epoch [5/5]: Train Loss=0.0021, Val Loss=0.0290
LSTM Test CPC Loss: 0.0415
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.4609, Val Loss=13.5938
Epoch [2/5]: Train Loss=8.5635, Val Loss=7.5387
Epoch [3/5]: Train Loss=4.8552, Val Loss=4.6727
Epoch [4/5]: Train Loss=2.9491, Val Loss=3.1518
Epoch [5/5]: Train Loss=1.9219, Val Loss=2.4180
Reservoir Test CPC Loss: 3.4050
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1371, Val Loss=2.2705
Epoch [2/5]: Train Loss=4.7997, Val Loss=2.2709
Epoch [3/5]: Train Loss=3.8521, Val Loss=2.2701
Epoch [4/5]: Train Loss=3.1238, Val Loss=2.2715
Epoch [5/5]: Train Loss=2.6625, Val Loss=2.2740
BERT Test CPC Loss: 2.2757

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=446.5667, Val Loss=5.9863
Epoch [2/5]: Train Loss=29.8582, Val Loss=3.1833
Epoch [3/5]: Train Loss=18.2180, Val Loss=2.6123
Epoch [4/5]: Train Loss=13.5726, Val Loss=2.5568
Epoch [5/5]: Train Loss=10.9271, Val Loss=2.5675
GPT2 Test CPC Loss: 2.5697
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7788, Val Loss=0.9425
Epoch [2/5]: Train Loss=0.4588, Val Loss=0.2471
Epoch [3/5]: Train Loss=0.0605, Val Loss=0.0512
Epoch [4/5]: Train Loss=0.0107, Val Loss=0.0290
Epoch [5/5]: Train Loss=0.0038, Val Loss=0.0183
LSTM Test CPC Loss: 0.0667
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.2186, Val Loss=13.9990
Epoch [2/5]: Train Loss=8.1581, Val Loss=7.6845
Epoch [3/5]: Train Loss=4.3164, Val Loss=4.9063
Epoch [4/5]: Train Loss=2.5195, Val Loss=3.3396
Epoch [5/5]: Train Loss=1.5957, Val Loss=2.4845
Reservoir Test CPC Loss: 3.3325
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3047, Val Loss=2.6951
Epoch [2/5]: Train Loss=4.7783, Val Loss=2.6962
Epoch [3/5]: Train Loss=3.9082, Val Loss=2.6965
Epoch [4/5]: Train Loss=3.2954, Val Loss=2.6983
Epoch [5/5]: Train Loss=2.9474, Val Loss=2.6999
BERT Test CPC Loss: 2.7003

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=429.7736, Val Loss=3.2262
Epoch [2/5]: Train Loss=30.9517, Val Loss=3.0467
Epoch [3/5]: Train Loss=20.0263, Val Loss=3.0040
Epoch [4/5]: Train Loss=14.4695, Val Loss=2.9704
Epoch [5/5]: Train Loss=11.5306, Val Loss=2.9548
GPT2 Test CPC Loss: 2.9300
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9713, Val Loss=1.3783
Epoch [2/5]: Train Loss=0.6808, Val Loss=0.4252
Epoch [3/5]: Train Loss=0.1152, Val Loss=0.0902
Epoch [4/5]: Train Loss=0.0159, Val Loss=0.0420
Epoch [5/5]: Train Loss=0.0053, Val Loss=0.0285
LSTM Test CPC Loss: 0.0305
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.7150, Val Loss=16.4113
Epoch [2/5]: Train Loss=9.9585, Val Loss=8.1155
Epoch [3/5]: Train Loss=5.1525, Val Loss=4.5954
Epoch [4/5]: Train Loss=2.9741, Val Loss=2.9632
Epoch [5/5]: Train Loss=1.8732, Val Loss=2.0710
Reservoir Test CPC Loss: 3.1747
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6131, Val Loss=2.9879
Epoch [2/5]: Train Loss=4.7236, Val Loss=2.9880
Epoch [3/5]: Train Loss=3.9339, Val Loss=2.9883
Epoch [4/5]: Train Loss=3.4596, Val Loss=2.9882
Epoch [5/5]: Train Loss=3.2178, Val Loss=2.9888
BERT Test CPC Loss: 2.9893

--- Fish 13: Run 7 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=342.6379, Val Loss=43.1486
Epoch [2/5]: Train Loss=24.8891, Val Loss=23.1206
Epoch [3/5]: Train Loss=16.2041, Val Loss=18.1511
Epoch [4/5]: Train Loss=11.9075, Val Loss=18.0923
Epoch [5/5]: Train Loss=8.9460, Val Loss=14.8844
GPT2 Test CPC Loss: 12.3098
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6169, Val Loss=0.0628
Epoch [2/5]: Train Loss=0.0079, Val Loss=0.0084
Epoch [3/5]: Train Loss=0.0012, Val Loss=0.0066
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0044
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0043
LSTM Test CPC Loss: 0.0027
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.4841, Val Loss=3.0869
Epoch [2/5]: Train Loss=2.0561, Val Loss=1.4602
Epoch [3/5]: Train Loss=1.0209, Val Loss=1.0064
Epoch [4/5]: Train Loss=0.5668, Val Loss=0.8024
Epoch [5/5]: Train Loss=0.3398, Val Loss=0.7023
Reservoir Test CPC Loss: 1.3481
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3636, Val Loss=1.5826
Epoch [2/5]: Train Loss=4.9165, Val Loss=1.7045
Epoch [3/5]: Train Loss=3.8576, Val Loss=1.8368
Epoch [4/5]: Train Loss=3.1316, Val Loss=1.7255
Epoch [5/5]: Train Loss=2.6165, Val Loss=1.6065
BERT Test CPC Loss: 1.5812

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=453.5570, Val Loss=13.4426
Epoch [2/5]: Train Loss=29.1565, Val Loss=22.5160
Epoch [3/5]: Train Loss=20.4139, Val Loss=21.3329
Epoch [4/5]: Train Loss=15.6661, Val Loss=19.2027
Epoch [5/5]: Train Loss=12.7049, Val Loss=17.4115
GPT2 Test CPC Loss: 15.1607
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1444, Val Loss=0.5008
Epoch [2/5]: Train Loss=0.1370, Val Loss=0.0772
Epoch [3/5]: Train Loss=0.0174, Val Loss=0.0367
Epoch [4/5]: Train Loss=0.0034, Val Loss=0.0280
Epoch [5/5]: Train Loss=0.0018, Val Loss=0.0219
LSTM Test CPC Loss: 0.0221
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.1605, Val Loss=12.3998
Epoch [2/5]: Train Loss=7.0913, Val Loss=6.7844
Epoch [3/5]: Train Loss=3.8653, Val Loss=4.3493
Epoch [4/5]: Train Loss=2.3207, Val Loss=3.0790
Epoch [5/5]: Train Loss=1.4926, Val Loss=2.3193
Reservoir Test CPC Loss: 2.6907
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0559, Val Loss=2.2773
Epoch [2/5]: Train Loss=4.7552, Val Loss=2.2774
Epoch [3/5]: Train Loss=3.7778, Val Loss=2.2778
Epoch [4/5]: Train Loss=3.1115, Val Loss=2.2768
Epoch [5/5]: Train Loss=2.6911, Val Loss=2.2766
BERT Test CPC Loss: 2.2781

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=387.9763, Val Loss=2.6589
Epoch [2/5]: Train Loss=20.8624, Val Loss=2.6435
Epoch [3/5]: Train Loss=15.3201, Val Loss=2.6746
Epoch [4/5]: Train Loss=12.5986, Val Loss=2.6258
Epoch [5/5]: Train Loss=10.6799, Val Loss=2.6421
GPT2 Test CPC Loss: 2.6377
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6421, Val Loss=0.8429
Epoch [2/5]: Train Loss=0.3821, Val Loss=0.1897
Epoch [3/5]: Train Loss=0.0459, Val Loss=0.0589
Epoch [4/5]: Train Loss=0.0085, Val Loss=0.0332
Epoch [5/5]: Train Loss=0.0034, Val Loss=0.0249
LSTM Test CPC Loss: 0.0330
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.9791, Val Loss=13.2602
Epoch [2/5]: Train Loss=8.6109, Val Loss=7.5816
Epoch [3/5]: Train Loss=4.7989, Val Loss=4.9015
Epoch [4/5]: Train Loss=2.9022, Val Loss=3.4018
Epoch [5/5]: Train Loss=1.8800, Val Loss=2.5784
Reservoir Test CPC Loss: 3.5673
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2812, Val Loss=2.6895
Epoch [2/5]: Train Loss=4.7319, Val Loss=2.6920
Epoch [3/5]: Train Loss=3.8652, Val Loss=2.6942
Epoch [4/5]: Train Loss=3.3171, Val Loss=2.6951
Epoch [5/5]: Train Loss=2.9959, Val Loss=2.6961
BERT Test CPC Loss: 2.6967

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=442.5845, Val Loss=2.8811
Epoch [2/5]: Train Loss=22.5825, Val Loss=2.8818
Epoch [3/5]: Train Loss=13.6293, Val Loss=2.8922
Epoch [4/5]: Train Loss=10.1826, Val Loss=2.9056
Epoch [5/5]: Train Loss=8.1697, Val Loss=2.9158
GPT2 Test CPC Loss: 2.9032
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9641, Val Loss=1.2815
Epoch [2/5]: Train Loss=0.6093, Val Loss=0.3480
Epoch [3/5]: Train Loss=0.0887, Val Loss=0.0631
Epoch [4/5]: Train Loss=0.0127, Val Loss=0.0285
Epoch [5/5]: Train Loss=0.0045, Val Loss=0.0165
LSTM Test CPC Loss: 0.0328
[Model: Reservoir]
Epoch [1/5]: Train Loss=26.1639, Val Loss=19.4939
Epoch [2/5]: Train Loss=10.7340, Val Loss=9.7463
Epoch [3/5]: Train Loss=5.4813, Val Loss=5.6752
Epoch [4/5]: Train Loss=3.1288, Val Loss=3.7504
Epoch [5/5]: Train Loss=1.9366, Val Loss=2.6743
Reservoir Test CPC Loss: 2.9883
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1810, Val Loss=2.9881
Epoch [2/5]: Train Loss=4.7819, Val Loss=2.9885
Epoch [3/5]: Train Loss=4.0058, Val Loss=2.9900
Epoch [4/5]: Train Loss=3.5166, Val Loss=2.9907
Epoch [5/5]: Train Loss=3.2387, Val Loss=2.9911
BERT Test CPC Loss: 2.9913

--- Fish 13: Run 8 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=408.4753, Val Loss=1.4534
Epoch [2/5]: Train Loss=28.5631, Val Loss=1.4246
Epoch [3/5]: Train Loss=17.2890, Val Loss=1.3949
Epoch [4/5]: Train Loss=12.3176, Val Loss=1.3870
Epoch [5/5]: Train Loss=9.4773, Val Loss=1.3812
GPT2 Test CPC Loss: 1.3776
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5766, Val Loss=0.0801
Epoch [2/5]: Train Loss=0.0088, Val Loss=0.0120
Epoch [3/5]: Train Loss=0.0014, Val Loss=0.0078
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0052
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0038
LSTM Test CPC Loss: 0.0028
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.9816, Val Loss=5.0185
Epoch [2/5]: Train Loss=2.7633, Val Loss=2.1609
Epoch [3/5]: Train Loss=1.3400, Val Loss=1.3527
Epoch [4/5]: Train Loss=0.7572, Val Loss=1.0515
Epoch [5/5]: Train Loss=0.4514, Val Loss=0.8402
Reservoir Test CPC Loss: 1.5729
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3833, Val Loss=1.6113
Epoch [2/5]: Train Loss=4.9274, Val Loss=1.6909
Epoch [3/5]: Train Loss=3.9185, Val Loss=1.7818
Epoch [4/5]: Train Loss=3.1503, Val Loss=1.7098
Epoch [5/5]: Train Loss=2.5916, Val Loss=1.5809
BERT Test CPC Loss: 1.5589

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=499.0206, Val Loss=3.3361
Epoch [2/5]: Train Loss=38.6706, Val Loss=2.3146
Epoch [3/5]: Train Loss=26.6883, Val Loss=2.3004
Epoch [4/5]: Train Loss=20.3226, Val Loss=2.2592
Epoch [5/5]: Train Loss=16.4907, Val Loss=2.2370
GPT2 Test CPC Loss: 2.2345
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2543, Val Loss=0.4468
Epoch [2/5]: Train Loss=0.1292, Val Loss=0.0822
Epoch [3/5]: Train Loss=0.0153, Val Loss=0.0342
Epoch [4/5]: Train Loss=0.0038, Val Loss=0.0199
Epoch [5/5]: Train Loss=0.0018, Val Loss=0.0185
LSTM Test CPC Loss: 0.0316
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.5509, Val Loss=13.2464
Epoch [2/5]: Train Loss=7.8371, Val Loss=7.4327
Epoch [3/5]: Train Loss=4.3044, Val Loss=4.6975
Epoch [4/5]: Train Loss=2.6052, Val Loss=3.2712
Epoch [5/5]: Train Loss=1.6877, Val Loss=2.5089
Reservoir Test CPC Loss: 3.3225
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2943, Val Loss=2.2723
Epoch [2/5]: Train Loss=4.7801, Val Loss=2.2726
Epoch [3/5]: Train Loss=3.7962, Val Loss=2.2719
Epoch [4/5]: Train Loss=3.0260, Val Loss=2.2749
Epoch [5/5]: Train Loss=2.6079, Val Loss=2.2775
BERT Test CPC Loss: 2.2791

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=432.1636, Val Loss=27.0195
Epoch [2/5]: Train Loss=30.4524, Val Loss=20.9321
Epoch [3/5]: Train Loss=20.8431, Val Loss=18.3651
Epoch [4/5]: Train Loss=16.0055, Val Loss=15.8313
Epoch [5/5]: Train Loss=13.1605, Val Loss=14.6759
GPT2 Test CPC Loss: 12.9230
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6065, Val Loss=0.8125
Epoch [2/5]: Train Loss=0.3425, Val Loss=0.1857
Epoch [3/5]: Train Loss=0.0433, Val Loss=0.0673
Epoch [4/5]: Train Loss=0.0083, Val Loss=0.0391
Epoch [5/5]: Train Loss=0.0033, Val Loss=0.0284
LSTM Test CPC Loss: 0.0319
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.1562, Val Loss=15.8482
Epoch [2/5]: Train Loss=9.1735, Val Loss=7.8427
Epoch [3/5]: Train Loss=4.6214, Val Loss=4.5852
Epoch [4/5]: Train Loss=2.6143, Val Loss=3.0196
Epoch [5/5]: Train Loss=1.6210, Val Loss=2.2068
Reservoir Test CPC Loss: 3.1713
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0570, Val Loss=2.6940
Epoch [2/5]: Train Loss=4.7656, Val Loss=2.6954
Epoch [3/5]: Train Loss=3.9112, Val Loss=2.6968
Epoch [4/5]: Train Loss=3.3609, Val Loss=2.6977
Epoch [5/5]: Train Loss=3.0319, Val Loss=2.6979
BERT Test CPC Loss: 2.6986

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=429.1570, Val Loss=7.5626
Epoch [2/5]: Train Loss=30.4068, Val Loss=4.0970
Epoch [3/5]: Train Loss=19.8450, Val Loss=3.1018
Epoch [4/5]: Train Loss=15.2094, Val Loss=2.9761
Epoch [5/5]: Train Loss=12.0738, Val Loss=2.9431
GPT2 Test CPC Loss: 2.9143
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7640, Val Loss=1.1622
Epoch [2/5]: Train Loss=0.5142, Val Loss=0.2702
Epoch [3/5]: Train Loss=0.0678, Val Loss=0.0456
Epoch [4/5]: Train Loss=0.0087, Val Loss=0.0236
Epoch [5/5]: Train Loss=0.0033, Val Loss=0.0147
LSTM Test CPC Loss: 0.0361
[Model: Reservoir]
Epoch [1/5]: Train Loss=26.4680, Val Loss=17.3522
Epoch [2/5]: Train Loss=9.9772, Val Loss=8.4607
Epoch [3/5]: Train Loss=4.7760, Val Loss=4.8390
Epoch [4/5]: Train Loss=2.6279, Val Loss=3.1699
Epoch [5/5]: Train Loss=1.6007, Val Loss=2.2867
Reservoir Test CPC Loss: 2.4451
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4334, Val Loss=2.9861
Epoch [2/5]: Train Loss=4.8665, Val Loss=2.9870
Epoch [3/5]: Train Loss=4.0738, Val Loss=2.9879
Epoch [4/5]: Train Loss=3.5660, Val Loss=2.9893
Epoch [5/5]: Train Loss=3.2720, Val Loss=2.9902
BERT Test CPC Loss: 2.9905

--- Fish 13: Run 9 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=516.9192, Val Loss=1.7189
Epoch [2/5]: Train Loss=36.8277, Val Loss=1.6117
Epoch [3/5]: Train Loss=21.6144, Val Loss=1.4865
Epoch [4/5]: Train Loss=15.2481, Val Loss=1.4558
Epoch [5/5]: Train Loss=11.5671, Val Loss=1.4495
GPT2 Test CPC Loss: 1.4322
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5864, Val Loss=0.0353
Epoch [2/5]: Train Loss=0.0068, Val Loss=0.0042
Epoch [3/5]: Train Loss=0.0008, Val Loss=0.0024
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0022
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0016
LSTM Test CPC Loss: 0.0022
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.1496, Val Loss=3.3389
Epoch [2/5]: Train Loss=2.1444, Val Loss=1.6353
Epoch [3/5]: Train Loss=1.0824, Val Loss=1.1090
Epoch [4/5]: Train Loss=0.6259, Val Loss=0.8135
Epoch [5/5]: Train Loss=0.3843, Val Loss=0.6470
Reservoir Test CPC Loss: 1.2345
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4256, Val Loss=1.5656
Epoch [2/5]: Train Loss=4.9109, Val Loss=1.6744
Epoch [3/5]: Train Loss=3.8530, Val Loss=1.7526
Epoch [4/5]: Train Loss=3.1212, Val Loss=1.6875
Epoch [5/5]: Train Loss=2.5177, Val Loss=1.5487
BERT Test CPC Loss: 1.5318

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=442.6448, Val Loss=5.3258
Epoch [2/5]: Train Loss=31.2087, Val Loss=2.6529
Epoch [3/5]: Train Loss=21.7164, Val Loss=2.3617
Epoch [4/5]: Train Loss=16.8835, Val Loss=2.2807
Epoch [5/5]: Train Loss=13.7291, Val Loss=2.2634
GPT2 Test CPC Loss: 2.2618
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1267, Val Loss=0.3794
Epoch [2/5]: Train Loss=0.1203, Val Loss=0.0709
Epoch [3/5]: Train Loss=0.0119, Val Loss=0.0257
Epoch [4/5]: Train Loss=0.0036, Val Loss=0.0181
Epoch [5/5]: Train Loss=0.0020, Val Loss=0.0156
LSTM Test CPC Loss: 0.0219
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.3659, Val Loss=9.6660
Epoch [2/5]: Train Loss=6.4805, Val Loss=5.2216
Epoch [3/5]: Train Loss=3.5716, Val Loss=3.2906
Epoch [4/5]: Train Loss=2.1570, Val Loss=2.2876
Epoch [5/5]: Train Loss=1.3860, Val Loss=1.7695
Reservoir Test CPC Loss: 2.8735
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0811, Val Loss=2.2729
Epoch [2/5]: Train Loss=4.7606, Val Loss=2.2735
Epoch [3/5]: Train Loss=3.8035, Val Loss=2.2759
Epoch [4/5]: Train Loss=3.0875, Val Loss=2.2776
Epoch [5/5]: Train Loss=2.6595, Val Loss=2.2797
BERT Test CPC Loss: 2.2811

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=657.1854, Val Loss=3.7374
Epoch [2/5]: Train Loss=40.7565, Val Loss=2.7775
Epoch [3/5]: Train Loss=23.6488, Val Loss=2.6947
Epoch [4/5]: Train Loss=16.7144, Val Loss=2.6748
Epoch [5/5]: Train Loss=12.9886, Val Loss=2.6579
GPT2 Test CPC Loss: 2.6420
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5396, Val Loss=0.7701
Epoch [2/5]: Train Loss=0.2901, Val Loss=0.1299
Epoch [3/5]: Train Loss=0.0287, Val Loss=0.0423
Epoch [4/5]: Train Loss=0.0066, Val Loss=0.0260
Epoch [5/5]: Train Loss=0.0028, Val Loss=0.0199
LSTM Test CPC Loss: 0.0285
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.2503, Val Loss=15.0354
Epoch [2/5]: Train Loss=9.3770, Val Loss=7.3831
Epoch [3/5]: Train Loss=4.8025, Val Loss=4.2564
Epoch [4/5]: Train Loss=2.7428, Val Loss=2.8382
Epoch [5/5]: Train Loss=1.7061, Val Loss=2.0393
Reservoir Test CPC Loss: 2.7245
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0232, Val Loss=2.6944
Epoch [2/5]: Train Loss=4.7304, Val Loss=2.6965
Epoch [3/5]: Train Loss=3.8497, Val Loss=2.6999
Epoch [4/5]: Train Loss=3.2458, Val Loss=2.7011
Epoch [5/5]: Train Loss=2.9288, Val Loss=2.7021
BERT Test CPC Loss: 2.7025

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=332.8657, Val Loss=2.9552
Epoch [2/5]: Train Loss=17.4402, Val Loss=2.9614
Epoch [3/5]: Train Loss=13.1916, Val Loss=2.9911
Epoch [4/5]: Train Loss=10.7507, Val Loss=2.9808
Epoch [5/5]: Train Loss=9.2617, Val Loss=2.9755
GPT2 Test CPC Loss: 2.9452
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6902, Val Loss=1.0788
Epoch [2/5]: Train Loss=0.4731, Val Loss=0.2418
Epoch [3/5]: Train Loss=0.0673, Val Loss=0.0563
Epoch [4/5]: Train Loss=0.0110, Val Loss=0.0309
Epoch [5/5]: Train Loss=0.0043, Val Loss=0.0180
LSTM Test CPC Loss: 0.0389
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.5802, Val Loss=18.5774
Epoch [2/5]: Train Loss=9.6902, Val Loss=9.7776
Epoch [3/5]: Train Loss=4.9395, Val Loss=5.8284
Epoch [4/5]: Train Loss=2.8217, Val Loss=3.8901
Epoch [5/5]: Train Loss=1.7654, Val Loss=2.8360
Reservoir Test CPC Loss: 3.5042
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4186, Val Loss=2.9924
Epoch [2/5]: Train Loss=4.8750, Val Loss=2.9927
Epoch [3/5]: Train Loss=4.0499, Val Loss=2.9925
Epoch [4/5]: Train Loss=3.5133, Val Loss=2.9923
Epoch [5/5]: Train Loss=3.2163, Val Loss=2.9925
BERT Test CPC Loss: 2.9926

--- Fish 13: Run 10 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=571.0715, Val Loss=58.9908
Epoch [2/5]: Train Loss=35.1325, Val Loss=42.5175
Epoch [3/5]: Train Loss=23.5609, Val Loss=37.0089
Epoch [4/5]: Train Loss=18.2716, Val Loss=29.7923
Epoch [5/5]: Train Loss=14.5631, Val Loss=23.7804
GPT2 Test CPC Loss: 20.0767
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7161, Val Loss=0.0682
Epoch [2/5]: Train Loss=0.0099, Val Loss=0.0087
Epoch [3/5]: Train Loss=0.0011, Val Loss=0.0036
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0026
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0019
LSTM Test CPC Loss: 0.0020
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.5992, Val Loss=2.6089
Epoch [2/5]: Train Loss=2.0269, Val Loss=1.1041
Epoch [3/5]: Train Loss=1.0399, Val Loss=0.6875
Epoch [4/5]: Train Loss=0.6081, Val Loss=0.5079
Epoch [5/5]: Train Loss=0.3715, Val Loss=0.4095
Reservoir Test CPC Loss: 0.9231
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4510, Val Loss=1.6878
Epoch [2/5]: Train Loss=4.8825, Val Loss=1.8529
Epoch [3/5]: Train Loss=3.8736, Val Loss=1.8809
Epoch [4/5]: Train Loss=3.2019, Val Loss=1.8027
Epoch [5/5]: Train Loss=2.6994, Val Loss=1.6447
BERT Test CPC Loss: 1.6126

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=394.9622, Val Loss=2.3891
Epoch [2/5]: Train Loss=26.8502, Val Loss=2.2428
Epoch [3/5]: Train Loss=16.6789, Val Loss=2.2085
Epoch [4/5]: Train Loss=11.9732, Val Loss=2.2042
Epoch [5/5]: Train Loss=9.5989, Val Loss=2.2070
GPT2 Test CPC Loss: 2.1993
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4190, Val Loss=0.6070
Epoch [2/5]: Train Loss=0.2508, Val Loss=0.1582
Epoch [3/5]: Train Loss=0.0341, Val Loss=0.0444
Epoch [4/5]: Train Loss=0.0075, Val Loss=0.0245
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0187
LSTM Test CPC Loss: 0.0246
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.7663, Val Loss=11.1756
Epoch [2/5]: Train Loss=7.3431, Val Loss=6.3330
Epoch [3/5]: Train Loss=4.0425, Val Loss=4.0615
Epoch [4/5]: Train Loss=2.4226, Val Loss=2.8665
Epoch [5/5]: Train Loss=1.5463, Val Loss=2.1711
Reservoir Test CPC Loss: 2.9268
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7549, Val Loss=2.2786
Epoch [2/5]: Train Loss=4.7022, Val Loss=2.2770
Epoch [3/5]: Train Loss=3.7388, Val Loss=2.2772
Epoch [4/5]: Train Loss=3.0277, Val Loss=2.2781
Epoch [5/5]: Train Loss=2.6207, Val Loss=2.2793
BERT Test CPC Loss: 2.2809

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=380.7812, Val Loss=8.3307
Epoch [2/5]: Train Loss=25.2275, Val Loss=5.8128
Epoch [3/5]: Train Loss=17.5825, Val Loss=6.8413
Epoch [4/5]: Train Loss=13.7234, Val Loss=7.1376
Epoch [5/5]: Train Loss=11.5512, Val Loss=6.1445
GPT2 Test CPC Loss: 5.0515
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7274, Val Loss=0.8679
Epoch [2/5]: Train Loss=0.3839, Val Loss=0.2077
Epoch [3/5]: Train Loss=0.0524, Val Loss=0.0761
Epoch [4/5]: Train Loss=0.0107, Val Loss=0.0353
Epoch [5/5]: Train Loss=0.0043, Val Loss=0.0279
LSTM Test CPC Loss: 0.0631
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.2442, Val Loss=14.9479
Epoch [2/5]: Train Loss=9.2299, Val Loss=8.0191
Epoch [3/5]: Train Loss=4.7071, Val Loss=4.8893
Epoch [4/5]: Train Loss=2.6507, Val Loss=3.3097
Epoch [5/5]: Train Loss=1.6277, Val Loss=2.4534
Reservoir Test CPC Loss: 3.2066
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2334, Val Loss=2.6912
Epoch [2/5]: Train Loss=4.7483, Val Loss=2.6912
Epoch [3/5]: Train Loss=3.8840, Val Loss=2.6919
Epoch [4/5]: Train Loss=3.3269, Val Loss=2.6917
Epoch [5/5]: Train Loss=3.0278, Val Loss=2.6924
BERT Test CPC Loss: 2.6935

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=391.7059, Val Loss=10.2763
Epoch [2/5]: Train Loss=24.4573, Val Loss=7.0798
Epoch [3/5]: Train Loss=17.8926, Val Loss=4.4227
Epoch [4/5]: Train Loss=14.1263, Val Loss=3.7097
Epoch [5/5]: Train Loss=11.8195, Val Loss=3.6935
GPT2 Test CPC Loss: 3.4991
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8117, Val Loss=1.2665
Epoch [2/5]: Train Loss=0.6023, Val Loss=0.3671
Epoch [3/5]: Train Loss=0.1086, Val Loss=0.0795
Epoch [4/5]: Train Loss=0.0187, Val Loss=0.0396
Epoch [5/5]: Train Loss=0.0057, Val Loss=0.0276
LSTM Test CPC Loss: 0.0389
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.9602, Val Loss=16.4000
Epoch [2/5]: Train Loss=10.3087, Val Loss=8.9780
Epoch [3/5]: Train Loss=5.4418, Val Loss=5.4617
Epoch [4/5]: Train Loss=3.1378, Val Loss=3.6500
Epoch [5/5]: Train Loss=1.9561, Val Loss=2.6591
Reservoir Test CPC Loss: 3.8981
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9747, Val Loss=2.9873
Epoch [2/5]: Train Loss=4.7362, Val Loss=2.9888
Epoch [3/5]: Train Loss=3.9157, Val Loss=2.9900
Epoch [4/5]: Train Loss=3.4007, Val Loss=2.9906
Epoch [5/5]: Train Loss=3.1659, Val Loss=2.9912
BERT Test CPC Loss: 2.9915

=== CPC Loss Results for seq_len=5 ===
GPT2: mean=3.0077, std=3.6736
LSTM: mean=0.0030, std=0.0026
Reservoir: mean=1.3294, std=0.3400
DeepSeek: mean=nan, std=nan
BERT: mean=1.5210, std=0.0280

Pairwise Significance Tests (MannWhitney U):
  GPT2 vs LSTM: p-value = 7.0661e-18
  GPT2 vs Reservoir: p-value = 7.2999e-07
  GPT2 vs DeepSeek: p-value = nan
  GPT2 vs BERT: p-value = 3.9074e-01
  LSTM vs Reservoir: p-value = 7.0661e-18
  LSTM vs DeepSeek: p-value = nan
  LSTM vs BERT: p-value = 7.0661e-18
  Reservoir vs DeepSeek: p-value = nan
  Reservoir vs BERT: p-value = 4.2701e-03
  DeepSeek vs BERT: p-value = nan

=== CPC Loss Results for seq_len=10 ===
GPT2: mean=2.8007, std=1.9886
LSTM: mean=0.0378, std=0.0462
Reservoir: mean=2.7512, std=0.3495
DeepSeek: mean=nan, std=nan
BERT: mean=2.2837, std=0.0076

Pairwise Significance Tests (MannWhitney U):
  GPT2 vs LSTM: p-value = 7.0661e-18
  GPT2 vs Reservoir: p-value = 1.5675e-05
  GPT2 vs DeepSeek: p-value = nan
  GPT2 vs BERT: p-value = 1.3921e-01
  LSTM vs Reservoir: p-value = 7.0661e-18
  LSTM vs DeepSeek: p-value = nan
  LSTM vs BERT: p-value = 7.0661e-18
  Reservoir vs DeepSeek: p-value = nan
  Reservoir vs BERT: p-value = 5.6109e-10
  DeepSeek vs BERT: p-value = nan

=== CPC Loss Results for seq_len=15 ===
GPT2: mean=3.0960, std=1.7837
LSTM: mean=0.0536, std=0.0250
Reservoir: mean=2.9901, std=0.3453
DeepSeek: mean=nan, std=nan
BERT: mean=2.7013, std=0.0026

Pairwise Significance Tests (MannWhitney U):
  GPT2 vs LSTM: p-value = 7.0661e-18
  GPT2 vs Reservoir: p-value = 1.6041e-04
  GPT2 vs DeepSeek: p-value = nan
  GPT2 vs BERT: p-value = 1.5211e-06
  LSTM vs Reservoir: p-value = 7.0661e-18
  LSTM vs DeepSeek: p-value = nan
  LSTM vs BERT: p-value = 7.0661e-18
  Reservoir vs DeepSeek: p-value = nan
  Reservoir vs BERT: p-value = 1.4196e-06
  DeepSeek vs BERT: p-value = nan

=== CPC Loss Results for seq_len=20 ===
GPT2: mean=3.0531, std=0.4201
LSTM: mean=0.0663, std=0.0337
Reservoir: mean=3.0987, std=0.4837
DeepSeek: mean=nan, std=nan
BERT: mean=2.9918, std=0.0014

Pairwise Significance Tests (MannWhitney U):
  GPT2 vs LSTM: p-value = 7.0661e-18
  GPT2 vs Reservoir: p-value = 5.0149e-01
  GPT2 vs DeepSeek: p-value = nan
  GPT2 vs BERT: p-value = 1.5177e-04
  LSTM vs Reservoir: p-value = 7.0661e-18
  LSTM vs DeepSeek: p-value = nan
  LSTM vs BERT: p-value = 7.0661e-18
  Reservoir vs DeepSeek: p-value = nan
  Reservoir vs BERT: p-value = 4.8842e-01
  DeepSeek vs BERT: p-value = nan
Bar plot saved to /hpc/group/naumannlab/jjm132/nlp4neuro/results/experiment_5/cpc_loss_comparison_seq5.png
Bar plot saved to /hpc/group/naumannlab/jjm132/nlp4neuro/results/experiment_5/cpc_loss_comparison_seq10.png
Bar plot saved to /hpc/group/naumannlab/jjm132/nlp4neuro/results/experiment_5/cpc_loss_comparison_seq15.png
Bar plot saved to /hpc/group/naumannlab/jjm132/nlp4neuro/results/experiment_5/cpc_loss_comparison_seq20.png
Self-supervised CPC experiment complete!
