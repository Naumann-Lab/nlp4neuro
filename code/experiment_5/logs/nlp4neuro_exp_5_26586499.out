Using device: cuda

========== Processing Fish 9 ==========
Fish 9: Neural data shape: (3047, 12499)

--- Fish 9: Run 1 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=341.7751, Val Loss=2.8142
Epoch [2/5]: Train Loss=22.4862, Val Loss=3.4166
Epoch [3/5]: Train Loss=15.8112, Val Loss=2.6872
Epoch [4/5]: Train Loss=11.6944, Val Loss=2.4798
Epoch [5/5]: Train Loss=9.2837, Val Loss=1.7093
GPT2 Test CPC Loss: 1.6805
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7059, Val Loss=0.0503
Epoch [2/5]: Train Loss=0.0112, Val Loss=0.0033
Epoch [3/5]: Train Loss=0.0011, Val Loss=0.0014
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0009
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0006
LSTM Test CPC Loss: 0.0011
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.7788, Val Loss=3.5463
Epoch [2/5]: Train Loss=2.4768, Val Loss=2.1345
Epoch [3/5]: Train Loss=1.3668, Val Loss=1.5820
Epoch [4/5]: Train Loss=0.8378, Val Loss=1.2677
Epoch [5/5]: Train Loss=0.5637, Val Loss=1.0405
Reservoir Test CPC Loss: 1.0364
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.9789, Val Loss=1.5444
Epoch [2/5]: Train Loss=4.5855, Val Loss=1.5318
Epoch [3/5]: Train Loss=3.5192, Val Loss=1.5180
Epoch [4/5]: Train Loss=2.6930, Val Loss=1.5046
Epoch [5/5]: Train Loss=2.1584, Val Loss=1.4835
BERT Test CPC Loss: 1.4834

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=360.0136, Val Loss=2.9241
Epoch [2/5]: Train Loss=24.5917, Val Loss=3.2887
Epoch [3/5]: Train Loss=16.9559, Val Loss=3.0834
Epoch [4/5]: Train Loss=13.1798, Val Loss=2.8482
Epoch [5/5]: Train Loss=10.8783, Val Loss=2.7667
GPT2 Test CPC Loss: 2.7697
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2510, Val Loss=0.5649
Epoch [2/5]: Train Loss=0.2334, Val Loss=0.1661
Epoch [3/5]: Train Loss=0.0314, Val Loss=0.0509
Epoch [4/5]: Train Loss=0.0065, Val Loss=0.0617
Epoch [5/5]: Train Loss=0.0026, Val Loss=0.0211
LSTM Test CPC Loss: 0.0318
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.6868, Val Loss=12.1211
Epoch [2/5]: Train Loss=7.3945, Val Loss=7.9340
Epoch [3/5]: Train Loss=4.6169, Val Loss=5.9595
Epoch [4/5]: Train Loss=3.0427, Val Loss=4.4948
Epoch [5/5]: Train Loss=2.0852, Val Loss=3.7144
Reservoir Test CPC Loss: 3.1520
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7921, Val Loss=2.2903
Epoch [2/5]: Train Loss=4.4143, Val Loss=2.2920
Epoch [3/5]: Train Loss=3.4017, Val Loss=2.2919
Epoch [4/5]: Train Loss=2.7733, Val Loss=2.2926
Epoch [5/5]: Train Loss=2.5188, Val Loss=2.2937
BERT Test CPC Loss: 2.2936

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=462.7155, Val Loss=3.1806
Epoch [2/5]: Train Loss=28.0701, Val Loss=2.7357
Epoch [3/5]: Train Loss=17.9048, Val Loss=2.6612
Epoch [4/5]: Train Loss=13.1879, Val Loss=2.6649
Epoch [5/5]: Train Loss=10.7114, Val Loss=2.6566
GPT2 Test CPC Loss: 2.6550
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9201, Val Loss=1.1211
Epoch [2/5]: Train Loss=0.7417, Val Loss=0.7481
Epoch [3/5]: Train Loss=0.2745, Val Loss=0.3185
Epoch [4/5]: Train Loss=0.0703, Val Loss=0.1725
Epoch [5/5]: Train Loss=0.0157, Val Loss=0.0786
LSTM Test CPC Loss: 0.1003
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.2060, Val Loss=11.7837
Epoch [2/5]: Train Loss=7.8962, Val Loss=7.8031
Epoch [3/5]: Train Loss=4.6357, Val Loss=5.4430
Epoch [4/5]: Train Loss=2.8870, Val Loss=4.0723
Epoch [5/5]: Train Loss=1.8965, Val Loss=3.2372
Reservoir Test CPC Loss: 2.9631
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0117, Val Loss=2.7050
Epoch [2/5]: Train Loss=4.5005, Val Loss=2.7038
Epoch [3/5]: Train Loss=3.6396, Val Loss=2.7038
Epoch [4/5]: Train Loss=3.1439, Val Loss=2.7040
Epoch [5/5]: Train Loss=2.9196, Val Loss=2.7045
BERT Test CPC Loss: 2.7044

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=297.8414, Val Loss=3.1648
Epoch [2/5]: Train Loss=20.0001, Val Loss=2.9836
Epoch [3/5]: Train Loss=14.8120, Val Loss=2.9566
Epoch [4/5]: Train Loss=12.0786, Val Loss=2.9503
Epoch [5/5]: Train Loss=10.2989, Val Loss=2.9580
GPT2 Test CPC Loss: 2.9574
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9440, Val Loss=1.4196
Epoch [2/5]: Train Loss=0.7959, Val Loss=0.7390
Epoch [3/5]: Train Loss=0.3744, Val Loss=0.4100
Epoch [4/5]: Train Loss=0.0812, Val Loss=0.1334
Epoch [5/5]: Train Loss=0.0178, Val Loss=0.0839
LSTM Test CPC Loss: 0.1058
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.6424, Val Loss=13.7430
Epoch [2/5]: Train Loss=9.1323, Val Loss=8.9439
Epoch [3/5]: Train Loss=5.3616, Val Loss=6.3072
Epoch [4/5]: Train Loss=3.3279, Val Loss=4.7984
Epoch [5/5]: Train Loss=2.1736, Val Loss=3.8821
Reservoir Test CPC Loss: 3.8295
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.5648, Val Loss=2.9944
Epoch [2/5]: Train Loss=4.4549, Val Loss=2.9937
Epoch [3/5]: Train Loss=3.6381, Val Loss=2.9937
Epoch [4/5]: Train Loss=3.2336, Val Loss=2.9937
Epoch [5/5]: Train Loss=3.1043, Val Loss=2.9942
BERT Test CPC Loss: 2.9941

--- Fish 9: Run 2 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=321.5528, Val Loss=1.6839
Epoch [2/5]: Train Loss=28.8711, Val Loss=1.5540
Epoch [3/5]: Train Loss=18.7320, Val Loss=1.4448
Epoch [4/5]: Train Loss=13.5421, Val Loss=1.4235
Epoch [5/5]: Train Loss=10.7503, Val Loss=1.4213
GPT2 Test CPC Loss: 1.4244
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6680, Val Loss=0.0513
Epoch [2/5]: Train Loss=0.0089, Val Loss=0.0047
Epoch [3/5]: Train Loss=0.0007, Val Loss=0.0022
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0015
Epoch [5/5]: Train Loss=0.0002, Val Loss=0.0011
LSTM Test CPC Loss: 0.0015
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.8708, Val Loss=4.8133
Epoch [2/5]: Train Loss=2.7578, Val Loss=3.0747
Epoch [3/5]: Train Loss=1.5885, Val Loss=2.4619
Epoch [4/5]: Train Loss=1.0215, Val Loss=1.9425
Epoch [5/5]: Train Loss=0.6617, Val Loss=1.6434
Reservoir Test CPC Loss: 1.2732
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.3395, Val Loss=1.5346
Epoch [2/5]: Train Loss=4.6655, Val Loss=1.5491
Epoch [3/5]: Train Loss=3.5899, Val Loss=1.5952
Epoch [4/5]: Train Loss=2.8003, Val Loss=1.5550
Epoch [5/5]: Train Loss=2.2677, Val Loss=1.4903
BERT Test CPC Loss: 1.4918

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=458.9281, Val Loss=5.2654
Epoch [2/5]: Train Loss=32.4397, Val Loss=2.4840
Epoch [3/5]: Train Loss=19.9587, Val Loss=2.1992
Epoch [4/5]: Train Loss=14.2798, Val Loss=2.1941
Epoch [5/5]: Train Loss=11.5434, Val Loss=2.1903
GPT2 Test CPC Loss: 2.1901
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1428, Val Loss=0.5206
Epoch [2/5]: Train Loss=0.1972, Val Loss=0.1612
Epoch [3/5]: Train Loss=0.0248, Val Loss=0.0503
Epoch [4/5]: Train Loss=0.0051, Val Loss=0.0243
Epoch [5/5]: Train Loss=0.0020, Val Loss=0.0229
LSTM Test CPC Loss: 0.0320
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.0388, Val Loss=10.1630
Epoch [2/5]: Train Loss=6.9546, Val Loss=6.4300
Epoch [3/5]: Train Loss=4.1460, Val Loss=4.4140
Epoch [4/5]: Train Loss=2.6362, Val Loss=3.3396
Epoch [5/5]: Train Loss=1.7695, Val Loss=2.6014
Reservoir Test CPC Loss: 2.7290
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.2146, Val Loss=2.2916
Epoch [2/5]: Train Loss=4.5219, Val Loss=2.2954
Epoch [3/5]: Train Loss=3.4649, Val Loss=2.2956
Epoch [4/5]: Train Loss=2.7533, Val Loss=2.2964
Epoch [5/5]: Train Loss=2.4928, Val Loss=2.2968
BERT Test CPC Loss: 2.2967

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=321.1625, Val Loss=3.0585
Epoch [2/5]: Train Loss=28.7529, Val Loss=2.6994
Epoch [3/5]: Train Loss=19.4461, Val Loss=2.6580
Epoch [4/5]: Train Loss=14.8578, Val Loss=2.6535
Epoch [5/5]: Train Loss=11.9872, Val Loss=2.6523
GPT2 Test CPC Loss: 2.6514
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6449, Val Loss=0.9806
Epoch [2/5]: Train Loss=0.5113, Val Loss=0.4052
Epoch [3/5]: Train Loss=0.1135, Val Loss=0.1599
Epoch [4/5]: Train Loss=0.0221, Val Loss=0.0684
Epoch [5/5]: Train Loss=0.0055, Val Loss=0.0396
LSTM Test CPC Loss: 0.0446
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.1407, Val Loss=12.5332
Epoch [2/5]: Train Loss=8.5408, Val Loss=8.3090
Epoch [3/5]: Train Loss=5.1521, Val Loss=5.9759
Epoch [4/5]: Train Loss=3.2869, Val Loss=4.6023
Epoch [5/5]: Train Loss=2.1877, Val Loss=3.5928
Reservoir Test CPC Loss: 3.2672
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7007, Val Loss=2.7023
Epoch [2/5]: Train Loss=4.5031, Val Loss=2.7036
Epoch [3/5]: Train Loss=3.6157, Val Loss=2.7039
Epoch [4/5]: Train Loss=3.0841, Val Loss=2.7045
Epoch [5/5]: Train Loss=2.8778, Val Loss=2.7051
BERT Test CPC Loss: 2.7051

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=446.6162, Val Loss=3.6086
Epoch [2/5]: Train Loss=32.1562, Val Loss=3.0526
Epoch [3/5]: Train Loss=20.3977, Val Loss=2.9970
Epoch [4/5]: Train Loss=15.1833, Val Loss=2.9856
Epoch [5/5]: Train Loss=12.2014, Val Loss=2.9762
GPT2 Test CPC Loss: 2.9799
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7990, Val Loss=1.4615
Epoch [2/5]: Train Loss=0.7969, Val Loss=1.4620
Epoch [3/5]: Train Loss=0.3282, Val Loss=0.3563
Epoch [4/5]: Train Loss=0.0668, Val Loss=0.1699
Epoch [5/5]: Train Loss=0.0164, Val Loss=0.1580
LSTM Test CPC Loss: 0.1436
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.6177, Val Loss=12.3724
Epoch [2/5]: Train Loss=8.3419, Val Loss=7.8581
Epoch [3/5]: Train Loss=4.8699, Val Loss=5.3899
Epoch [4/5]: Train Loss=2.9947, Val Loss=3.9982
Epoch [5/5]: Train Loss=1.9653, Val Loss=3.1069
Reservoir Test CPC Loss: 3.2397
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7167, Val Loss=2.9934
Epoch [2/5]: Train Loss=4.4769, Val Loss=2.9939
Epoch [3/5]: Train Loss=3.7003, Val Loss=2.9936
Epoch [4/5]: Train Loss=3.2863, Val Loss=2.9938
Epoch [5/5]: Train Loss=3.1239, Val Loss=2.9940
BERT Test CPC Loss: 2.9940

--- Fish 9: Run 3 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=324.0203, Val Loss=2.2216
Epoch [2/5]: Train Loss=25.2617, Val Loss=1.5623
Epoch [3/5]: Train Loss=14.9226, Val Loss=1.4157
Epoch [4/5]: Train Loss=10.9064, Val Loss=1.4034
Epoch [5/5]: Train Loss=8.5629, Val Loss=1.4031
GPT2 Test CPC Loss: 1.4049
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5595, Val Loss=0.0469
Epoch [2/5]: Train Loss=0.0078, Val Loss=0.0055
Epoch [3/5]: Train Loss=0.0010, Val Loss=0.0028
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0018
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0019
LSTM Test CPC Loss: 0.0058
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.4489, Val Loss=3.6539
Epoch [2/5]: Train Loss=2.3962, Val Loss=2.1752
Epoch [3/5]: Train Loss=1.3184, Val Loss=1.6382
Epoch [4/5]: Train Loss=0.8192, Val Loss=1.2753
Epoch [5/5]: Train Loss=0.5340, Val Loss=1.0840
Reservoir Test CPC Loss: 1.2949
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.9870, Val Loss=1.5179
Epoch [2/5]: Train Loss=4.6591, Val Loss=1.5133
Epoch [3/5]: Train Loss=3.5237, Val Loss=1.5215
Epoch [4/5]: Train Loss=2.6612, Val Loss=1.5101
Epoch [5/5]: Train Loss=2.0951, Val Loss=1.4902
BERT Test CPC Loss: 1.4908

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=275.5480, Val Loss=2.3217
Epoch [2/5]: Train Loss=22.9047, Val Loss=2.2337
Epoch [3/5]: Train Loss=15.0554, Val Loss=2.2275
Epoch [4/5]: Train Loss=11.4026, Val Loss=2.2341
Epoch [5/5]: Train Loss=9.0182, Val Loss=2.2388
GPT2 Test CPC Loss: 2.2393
[Model: LSTM]
Epoch [1/5]: Train Loss=1.0449, Val Loss=0.4654
Epoch [2/5]: Train Loss=0.1589, Val Loss=0.0794
Epoch [3/5]: Train Loss=0.0182, Val Loss=0.0228
Epoch [4/5]: Train Loss=0.0040, Val Loss=0.0135
Epoch [5/5]: Train Loss=0.0018, Val Loss=0.0091
LSTM Test CPC Loss: 0.0185
[Model: Reservoir]
Epoch [1/5]: Train Loss=13.1875, Val Loss=9.0431
Epoch [2/5]: Train Loss=5.8113, Val Loss=6.2045
Epoch [3/5]: Train Loss=3.6739, Val Loss=4.7227
Epoch [4/5]: Train Loss=2.4466, Val Loss=3.6765
Epoch [5/5]: Train Loss=1.7182, Val Loss=3.0379
Reservoir Test CPC Loss: 2.9523
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.8932, Val Loss=2.2855
Epoch [2/5]: Train Loss=4.4729, Val Loss=2.2877
Epoch [3/5]: Train Loss=3.4122, Val Loss=2.2890
Epoch [4/5]: Train Loss=2.7862, Val Loss=2.2908
Epoch [5/5]: Train Loss=2.5276, Val Loss=2.2924
BERT Test CPC Loss: 2.2923

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=445.7912, Val Loss=2.7943
Epoch [2/5]: Train Loss=26.1896, Val Loss=2.6445
Epoch [3/5]: Train Loss=18.9276, Val Loss=2.6512
Epoch [4/5]: Train Loss=15.5995, Val Loss=2.6596
Epoch [5/5]: Train Loss=12.8217, Val Loss=2.6700
GPT2 Test CPC Loss: 2.6672
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0248, Val Loss=1.2694
Epoch [2/5]: Train Loss=0.8198, Val Loss=0.6794
Epoch [3/5]: Train Loss=0.3161, Val Loss=0.3181
Epoch [4/5]: Train Loss=0.0835, Val Loss=0.1731
Epoch [5/5]: Train Loss=0.0206, Val Loss=0.0626
LSTM Test CPC Loss: 0.1243
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.3355, Val Loss=11.4619
Epoch [2/5]: Train Loss=7.9358, Val Loss=7.2061
Epoch [3/5]: Train Loss=4.5698, Val Loss=4.8308
Epoch [4/5]: Train Loss=2.8385, Val Loss=3.6038
Epoch [5/5]: Train Loss=1.8276, Val Loss=2.7406
Reservoir Test CPC Loss: 2.9355
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.5438, Val Loss=2.7029
Epoch [2/5]: Train Loss=4.3804, Val Loss=2.7035
Epoch [3/5]: Train Loss=3.5384, Val Loss=2.7037
Epoch [4/5]: Train Loss=3.0759, Val Loss=2.7038
Epoch [5/5]: Train Loss=2.8862, Val Loss=2.7046
BERT Test CPC Loss: 2.7047

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=386.0887, Val Loss=4.7882
Epoch [2/5]: Train Loss=23.1215, Val Loss=3.4451
Epoch [3/5]: Train Loss=16.6280, Val Loss=3.0219
Epoch [4/5]: Train Loss=13.3425, Val Loss=3.3142
Epoch [5/5]: Train Loss=11.3544, Val Loss=2.9699
GPT2 Test CPC Loss: 2.9701
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0282, Val Loss=1.4405
Epoch [2/5]: Train Loss=0.9282, Val Loss=1.1243
Epoch [3/5]: Train Loss=0.4416, Val Loss=0.5075
Epoch [4/5]: Train Loss=0.1010, Val Loss=0.3406
Epoch [5/5]: Train Loss=0.0325, Val Loss=0.1060
LSTM Test CPC Loss: 0.1033
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.9541, Val Loss=11.0893
Epoch [2/5]: Train Loss=8.4076, Val Loss=6.9166
Epoch [3/5]: Train Loss=5.0255, Val Loss=4.8693
Epoch [4/5]: Train Loss=3.1633, Val Loss=3.6342
Epoch [5/5]: Train Loss=2.0872, Val Loss=2.8369
Reservoir Test CPC Loss: 3.2021
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7518, Val Loss=2.9938
Epoch [2/5]: Train Loss=4.4959, Val Loss=2.9942
Epoch [3/5]: Train Loss=3.7584, Val Loss=2.9943
Epoch [4/5]: Train Loss=3.3611, Val Loss=2.9942
Epoch [5/5]: Train Loss=3.1771, Val Loss=2.9942
BERT Test CPC Loss: 2.9942

--- Fish 9: Run 4 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=416.9199, Val Loss=1.4748
Epoch [2/5]: Train Loss=28.8170, Val Loss=1.4493
Epoch [3/5]: Train Loss=18.3053, Val Loss=1.4542
Epoch [4/5]: Train Loss=13.3291, Val Loss=1.4545
Epoch [5/5]: Train Loss=10.4036, Val Loss=1.4464
GPT2 Test CPC Loss: 1.4502
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7818, Val Loss=0.1303
Epoch [2/5]: Train Loss=0.0327, Val Loss=0.0112
Epoch [3/5]: Train Loss=0.0020, Val Loss=0.0046
Epoch [4/5]: Train Loss=0.0008, Val Loss=0.0035
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0035
LSTM Test CPC Loss: 0.0019
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.7821, Val Loss=4.4937
Epoch [2/5]: Train Loss=2.9514, Val Loss=2.8520
Epoch [3/5]: Train Loss=1.6826, Val Loss=2.1273
Epoch [4/5]: Train Loss=1.0846, Val Loss=1.7038
Epoch [5/5]: Train Loss=0.7416, Val Loss=1.4522
Reservoir Test CPC Loss: 1.3057
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0830, Val Loss=1.5382
Epoch [2/5]: Train Loss=4.7063, Val Loss=1.5353
Epoch [3/5]: Train Loss=3.6673, Val Loss=1.5281
Epoch [4/5]: Train Loss=2.8329, Val Loss=1.5192
Epoch [5/5]: Train Loss=2.2619, Val Loss=1.5049
BERT Test CPC Loss: 1.5053

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=364.2805, Val Loss=7.3993
Epoch [2/5]: Train Loss=29.4988, Val Loss=4.5185
Epoch [3/5]: Train Loss=18.2868, Val Loss=2.8598
Epoch [4/5]: Train Loss=13.2433, Val Loss=2.3768
Epoch [5/5]: Train Loss=10.6630, Val Loss=2.2707
GPT2 Test CPC Loss: 2.2760
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3064, Val Loss=0.5695
Epoch [2/5]: Train Loss=0.2168, Val Loss=0.1344
Epoch [3/5]: Train Loss=0.0243, Val Loss=0.0710
Epoch [4/5]: Train Loss=0.0042, Val Loss=0.0496
Epoch [5/5]: Train Loss=0.0019, Val Loss=0.0369
LSTM Test CPC Loss: 0.0170
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.1506, Val Loss=11.7510
Epoch [2/5]: Train Loss=7.4505, Val Loss=7.5099
Epoch [3/5]: Train Loss=4.5124, Val Loss=5.2957
Epoch [4/5]: Train Loss=2.8856, Val Loss=4.0317
Epoch [5/5]: Train Loss=1.9541, Val Loss=3.1991
Reservoir Test CPC Loss: 2.9242
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.9746, Val Loss=2.2854
Epoch [2/5]: Train Loss=4.4669, Val Loss=2.2877
Epoch [3/5]: Train Loss=3.4574, Val Loss=2.2900
Epoch [4/5]: Train Loss=2.8341, Val Loss=2.2911
Epoch [5/5]: Train Loss=2.5564, Val Loss=2.2928
BERT Test CPC Loss: 2.2928

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=273.1647, Val Loss=3.0000
Epoch [2/5]: Train Loss=20.6616, Val Loss=3.1011
Epoch [3/5]: Train Loss=14.7032, Val Loss=2.7570
Epoch [4/5]: Train Loss=11.4401, Val Loss=2.7274
Epoch [5/5]: Train Loss=9.6302, Val Loss=2.7210
GPT2 Test CPC Loss: 2.7224
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6531, Val Loss=0.9602
Epoch [2/5]: Train Loss=0.4748, Val Loss=0.3155
Epoch [3/5]: Train Loss=0.0953, Val Loss=0.1174
Epoch [4/5]: Train Loss=0.0190, Val Loss=0.0765
Epoch [5/5]: Train Loss=0.0054, Val Loss=0.0477
LSTM Test CPC Loss: 0.0784
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.5970, Val Loss=10.6484
Epoch [2/5]: Train Loss=7.2669, Val Loss=7.2711
Epoch [3/5]: Train Loss=4.4376, Val Loss=5.3131
Epoch [4/5]: Train Loss=2.8459, Val Loss=4.1431
Epoch [5/5]: Train Loss=1.9239, Val Loss=3.3035
Reservoir Test CPC Loss: 3.1481
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.5065, Val Loss=2.6993
Epoch [2/5]: Train Loss=4.3988, Val Loss=2.7012
Epoch [3/5]: Train Loss=3.5430, Val Loss=2.7025
Epoch [4/5]: Train Loss=3.0659, Val Loss=2.7036
Epoch [5/5]: Train Loss=2.8796, Val Loss=2.7042
BERT Test CPC Loss: 2.7043

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=424.5957, Val Loss=6.5367
Epoch [2/5]: Train Loss=36.5252, Val Loss=3.1881
Epoch [3/5]: Train Loss=20.7334, Val Loss=3.0300
Epoch [4/5]: Train Loss=14.5486, Val Loss=3.0099
Epoch [5/5]: Train Loss=11.6131, Val Loss=2.9775
GPT2 Test CPC Loss: 2.9786
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0016, Val Loss=1.4520
Epoch [2/5]: Train Loss=0.9333, Val Loss=0.8292
Epoch [3/5]: Train Loss=0.4146, Val Loss=0.3826
Epoch [4/5]: Train Loss=0.1134, Val Loss=0.1464
Epoch [5/5]: Train Loss=0.0287, Val Loss=0.0806
LSTM Test CPC Loss: 0.1322
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.9318, Val Loss=12.1437
Epoch [2/5]: Train Loss=8.9362, Val Loss=8.1235
Epoch [3/5]: Train Loss=5.3097, Val Loss=5.7542
Epoch [4/5]: Train Loss=3.4065, Val Loss=4.2445
Epoch [5/5]: Train Loss=2.2316, Val Loss=3.3361
Reservoir Test CPC Loss: 3.4429
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.9584, Val Loss=2.9944
Epoch [2/5]: Train Loss=4.5214, Val Loss=2.9937
Epoch [3/5]: Train Loss=3.6960, Val Loss=2.9939
Epoch [4/5]: Train Loss=3.2763, Val Loss=2.9941
Epoch [5/5]: Train Loss=3.1345, Val Loss=2.9944
BERT Test CPC Loss: 2.9944

--- Fish 9: Run 5 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=445.3156, Val Loss=1.5057
Epoch [2/5]: Train Loss=30.0868, Val Loss=1.4659
Epoch [3/5]: Train Loss=20.7030, Val Loss=1.4774
Epoch [4/5]: Train Loss=15.9014, Val Loss=1.4701
Epoch [5/5]: Train Loss=13.2284, Val Loss=1.4558
GPT2 Test CPC Loss: 1.4648
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7233, Val Loss=0.1163
Epoch [2/5]: Train Loss=0.0263, Val Loss=0.0119
Epoch [3/5]: Train Loss=0.0019, Val Loss=0.0040
Epoch [4/5]: Train Loss=0.0008, Val Loss=0.0028
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0020
LSTM Test CPC Loss: 0.0028
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.5818, Val Loss=4.7962
Epoch [2/5]: Train Loss=2.7514, Val Loss=3.1041
Epoch [3/5]: Train Loss=1.5974, Val Loss=2.3627
Epoch [4/5]: Train Loss=1.0050, Val Loss=1.8781
Epoch [5/5]: Train Loss=0.6740, Val Loss=1.6637
Reservoir Test CPC Loss: 1.3246
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0106, Val Loss=1.5223
Epoch [2/5]: Train Loss=4.6689, Val Loss=1.5194
Epoch [3/5]: Train Loss=3.5625, Val Loss=1.5133
Epoch [4/5]: Train Loss=2.6887, Val Loss=1.5059
Epoch [5/5]: Train Loss=2.1004, Val Loss=1.4924
BERT Test CPC Loss: 1.4926

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=502.9469, Val Loss=5.4151
Epoch [2/5]: Train Loss=41.1029, Val Loss=2.2927
Epoch [3/5]: Train Loss=28.0922, Val Loss=2.2833
Epoch [4/5]: Train Loss=20.5325, Val Loss=2.2361
Epoch [5/5]: Train Loss=15.9953, Val Loss=2.2491
GPT2 Test CPC Loss: 2.2445
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4817, Val Loss=0.7702
Epoch [2/5]: Train Loss=0.3962, Val Loss=0.3147
Epoch [3/5]: Train Loss=0.0738, Val Loss=0.0848
Epoch [4/5]: Train Loss=0.0139, Val Loss=0.0362
Epoch [5/5]: Train Loss=0.0047, Val Loss=0.0265
LSTM Test CPC Loss: 0.0348
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.8764, Val Loss=9.9054
Epoch [2/5]: Train Loss=6.9371, Val Loss=6.4320
Epoch [3/5]: Train Loss=4.1298, Val Loss=4.5312
Epoch [4/5]: Train Loss=2.6349, Val Loss=3.4550
Epoch [5/5]: Train Loss=1.7644, Val Loss=2.7548
Reservoir Test CPC Loss: 2.9008
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7307, Val Loss=2.2850
Epoch [2/5]: Train Loss=4.4000, Val Loss=2.2848
Epoch [3/5]: Train Loss=3.4471, Val Loss=2.2863
Epoch [4/5]: Train Loss=2.8299, Val Loss=2.2881
Epoch [5/5]: Train Loss=2.5459, Val Loss=2.2896
BERT Test CPC Loss: 2.2896

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=401.7663, Val Loss=4.5233
Epoch [2/5]: Train Loss=22.1510, Val Loss=3.4421
Epoch [3/5]: Train Loss=16.2729, Val Loss=3.2145
Epoch [4/5]: Train Loss=13.3166, Val Loss=3.1035
Epoch [5/5]: Train Loss=11.1827, Val Loss=2.9400
GPT2 Test CPC Loss: 2.8443
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4166, Val Loss=0.6779
Epoch [2/5]: Train Loss=0.3336, Val Loss=0.2230
Epoch [3/5]: Train Loss=0.0532, Val Loss=0.0973
Epoch [4/5]: Train Loss=0.0101, Val Loss=0.0392
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0320
LSTM Test CPC Loss: 0.0352
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.2021, Val Loss=11.0260
Epoch [2/5]: Train Loss=7.6968, Val Loss=7.3888
Epoch [3/5]: Train Loss=4.7683, Val Loss=5.1472
Epoch [4/5]: Train Loss=3.0902, Val Loss=3.9254
Epoch [5/5]: Train Loss=2.1110, Val Loss=3.0252
Reservoir Test CPC Loss: 3.0850
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.4443, Val Loss=2.7039
Epoch [2/5]: Train Loss=4.3818, Val Loss=2.7042
Epoch [3/5]: Train Loss=3.5332, Val Loss=2.7045
Epoch [4/5]: Train Loss=3.0506, Val Loss=2.7048
Epoch [5/5]: Train Loss=2.8589, Val Loss=2.7051
BERT Test CPC Loss: 2.7050

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=440.8051, Val Loss=2.9226
Epoch [2/5]: Train Loss=25.9783, Val Loss=2.9241
Epoch [3/5]: Train Loss=18.5506, Val Loss=2.9464
Epoch [4/5]: Train Loss=14.7221, Val Loss=2.9614
Epoch [5/5]: Train Loss=12.2425, Val Loss=2.9540
GPT2 Test CPC Loss: 2.9543
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7706, Val Loss=1.1467
Epoch [2/5]: Train Loss=0.6736, Val Loss=0.5622
Epoch [3/5]: Train Loss=0.1913, Val Loss=0.2934
Epoch [4/5]: Train Loss=0.0396, Val Loss=0.0705
Epoch [5/5]: Train Loss=0.0094, Val Loss=0.0453
LSTM Test CPC Loss: 0.0499
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.3411, Val Loss=10.6247
Epoch [2/5]: Train Loss=7.4105, Val Loss=6.9630
Epoch [3/5]: Train Loss=4.5192, Val Loss=4.9160
Epoch [4/5]: Train Loss=2.8406, Val Loss=3.6855
Epoch [5/5]: Train Loss=1.9092, Val Loss=2.9454
Reservoir Test CPC Loss: 3.0272
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.8180, Val Loss=2.9920
Epoch [2/5]: Train Loss=4.4434, Val Loss=2.9920
Epoch [3/5]: Train Loss=3.6549, Val Loss=2.9926
Epoch [4/5]: Train Loss=3.2638, Val Loss=2.9932
Epoch [5/5]: Train Loss=3.1266, Val Loss=2.9936
BERT Test CPC Loss: 2.9936

--- Fish 9: Run 6 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=307.4117, Val Loss=2.1772
Epoch [2/5]: Train Loss=24.1472, Val Loss=1.4748
Epoch [3/5]: Train Loss=14.6261, Val Loss=1.4102
Epoch [4/5]: Train Loss=10.4305, Val Loss=1.4025
Epoch [5/5]: Train Loss=8.4213, Val Loss=1.3994
GPT2 Test CPC Loss: 1.4005
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7336, Val Loss=0.1219
Epoch [2/5]: Train Loss=0.0273, Val Loss=0.0066
Epoch [3/5]: Train Loss=0.0019, Val Loss=0.0031
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0018
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0013
LSTM Test CPC Loss: 0.0013
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.5187, Val Loss=6.1160
Epoch [2/5]: Train Loss=3.4592, Val Loss=3.9437
Epoch [3/5]: Train Loss=1.9180, Val Loss=2.8909
Epoch [4/5]: Train Loss=1.1883, Val Loss=2.3342
Epoch [5/5]: Train Loss=0.7815, Val Loss=2.0472
Reservoir Test CPC Loss: 2.2064
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0203, Val Loss=1.5267
Epoch [2/5]: Train Loss=4.6743, Val Loss=1.5252
Epoch [3/5]: Train Loss=3.6314, Val Loss=1.5212
Epoch [4/5]: Train Loss=2.8368, Val Loss=1.5149
Epoch [5/5]: Train Loss=2.2443, Val Loss=1.4907
BERT Test CPC Loss: 1.4919

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=421.5351, Val Loss=2.4706
Epoch [2/5]: Train Loss=28.3643, Val Loss=2.3427
Epoch [3/5]: Train Loss=18.4029, Val Loss=2.2804
Epoch [4/5]: Train Loss=14.1189, Val Loss=2.2646
Epoch [5/5]: Train Loss=11.1067, Val Loss=2.2577
GPT2 Test CPC Loss: 2.2583
[Model: LSTM]
Epoch [1/5]: Train Loss=0.9331, Val Loss=0.4214
Epoch [2/5]: Train Loss=0.1217, Val Loss=0.0746
Epoch [3/5]: Train Loss=0.0158, Val Loss=0.0234
Epoch [4/5]: Train Loss=0.0043, Val Loss=0.0149
Epoch [5/5]: Train Loss=0.0019, Val Loss=0.0098
LSTM Test CPC Loss: 0.0255
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.1470, Val Loss=11.6613
Epoch [2/5]: Train Loss=7.5172, Val Loss=7.2575
Epoch [3/5]: Train Loss=4.5135, Val Loss=5.2878
Epoch [4/5]: Train Loss=2.8995, Val Loss=3.9833
Epoch [5/5]: Train Loss=1.9798, Val Loss=3.1381
Reservoir Test CPC Loss: 2.6815
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.1428, Val Loss=2.2854
Epoch [2/5]: Train Loss=4.5375, Val Loss=2.2842
Epoch [3/5]: Train Loss=3.5025, Val Loss=2.2861
Epoch [4/5]: Train Loss=2.8088, Val Loss=2.2897
Epoch [5/5]: Train Loss=2.5287, Val Loss=2.2913
BERT Test CPC Loss: 2.2912

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=294.5777, Val Loss=2.8306
Epoch [2/5]: Train Loss=17.1386, Val Loss=2.6722
Epoch [3/5]: Train Loss=12.5980, Val Loss=2.6836
Epoch [4/5]: Train Loss=10.1774, Val Loss=2.6568
Epoch [5/5]: Train Loss=8.5997, Val Loss=2.6649
GPT2 Test CPC Loss: 2.6648
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3921, Val Loss=0.7891
Epoch [2/5]: Train Loss=0.3925, Val Loss=0.2434
Epoch [3/5]: Train Loss=0.0688, Val Loss=0.1007
Epoch [4/5]: Train Loss=0.0116, Val Loss=0.0520
Epoch [5/5]: Train Loss=0.0039, Val Loss=0.0530
LSTM Test CPC Loss: 0.0669
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.5948, Val Loss=12.0909
Epoch [2/5]: Train Loss=7.9743, Val Loss=7.9916
Epoch [3/5]: Train Loss=4.6042, Val Loss=5.7899
Epoch [4/5]: Train Loss=2.8393, Val Loss=4.2440
Epoch [5/5]: Train Loss=1.8622, Val Loss=3.3927
Reservoir Test CPC Loss: 2.8276
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.6463, Val Loss=2.7034
Epoch [2/5]: Train Loss=4.3794, Val Loss=2.7046
Epoch [3/5]: Train Loss=3.4658, Val Loss=2.7050
Epoch [4/5]: Train Loss=2.9890, Val Loss=2.7050
Epoch [5/5]: Train Loss=2.8408, Val Loss=2.7057
BERT Test CPC Loss: 2.7055

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=334.6741, Val Loss=3.2825
Epoch [2/5]: Train Loss=27.3123, Val Loss=3.1838
Epoch [3/5]: Train Loss=17.8053, Val Loss=2.9744
Epoch [4/5]: Train Loss=14.0095, Val Loss=2.9413
Epoch [5/5]: Train Loss=11.5290, Val Loss=2.9362
GPT2 Test CPC Loss: 2.9262
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9619, Val Loss=1.4205
Epoch [2/5]: Train Loss=0.9011, Val Loss=0.8241
Epoch [3/5]: Train Loss=0.3878, Val Loss=0.4466
Epoch [4/5]: Train Loss=0.1047, Val Loss=0.1519
Epoch [5/5]: Train Loss=0.0202, Val Loss=0.0703
LSTM Test CPC Loss: 0.0708
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.1811, Val Loss=14.0723
Epoch [2/5]: Train Loss=8.5903, Val Loss=9.5088
Epoch [3/5]: Train Loss=5.1728, Val Loss=6.7680
Epoch [4/5]: Train Loss=3.2694, Val Loss=5.2153
Epoch [5/5]: Train Loss=2.1661, Val Loss=4.1700
Reservoir Test CPC Loss: 3.3277
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.8966, Val Loss=2.9909
Epoch [2/5]: Train Loss=4.5260, Val Loss=2.9923
Epoch [3/5]: Train Loss=3.8056, Val Loss=2.9926
Epoch [4/5]: Train Loss=3.4040, Val Loss=2.9931
Epoch [5/5]: Train Loss=3.2130, Val Loss=2.9935
BERT Test CPC Loss: 2.9935

--- Fish 9: Run 7 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=340.3925, Val Loss=1.6414
Epoch [2/5]: Train Loss=27.7859, Val Loss=1.4611
Epoch [3/5]: Train Loss=18.5182, Val Loss=1.4837
Epoch [4/5]: Train Loss=13.5354, Val Loss=1.5185
Epoch [5/5]: Train Loss=10.7071, Val Loss=1.5093
GPT2 Test CPC Loss: 1.5301
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7979, Val Loss=0.1408
Epoch [2/5]: Train Loss=0.0293, Val Loss=0.0128
Epoch [3/5]: Train Loss=0.0025, Val Loss=0.0045
Epoch [4/5]: Train Loss=0.0010, Val Loss=0.0030
Epoch [5/5]: Train Loss=0.0006, Val Loss=0.0019
LSTM Test CPC Loss: 0.0019
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.7397, Val Loss=4.7062
Epoch [2/5]: Train Loss=2.5907, Val Loss=2.6990
Epoch [3/5]: Train Loss=1.4482, Val Loss=2.1339
Epoch [4/5]: Train Loss=0.9012, Val Loss=1.6794
Epoch [5/5]: Train Loss=0.5970, Val Loss=1.4072
Reservoir Test CPC Loss: 1.4083
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0156, Val Loss=1.5107
Epoch [2/5]: Train Loss=4.6141, Val Loss=1.5427
Epoch [3/5]: Train Loss=3.5323, Val Loss=1.5935
Epoch [4/5]: Train Loss=2.7955, Val Loss=1.5341
Epoch [5/5]: Train Loss=2.2825, Val Loss=1.4766
BERT Test CPC Loss: 1.4776

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=348.9803, Val Loss=2.3232
Epoch [2/5]: Train Loss=26.8460, Val Loss=2.2838
Epoch [3/5]: Train Loss=18.9451, Val Loss=2.2739
Epoch [4/5]: Train Loss=14.9129, Val Loss=2.2788
Epoch [5/5]: Train Loss=12.1396, Val Loss=2.2648
GPT2 Test CPC Loss: 2.2663
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5578, Val Loss=0.7749
Epoch [2/5]: Train Loss=0.3797, Val Loss=0.1784
Epoch [3/5]: Train Loss=0.0534, Val Loss=0.0637
Epoch [4/5]: Train Loss=0.0101, Val Loss=0.0295
Epoch [5/5]: Train Loss=0.0037, Val Loss=0.0215
LSTM Test CPC Loss: 0.0275
[Model: Reservoir]
Epoch [1/5]: Train Loss=13.8425, Val Loss=8.2715
Epoch [2/5]: Train Loss=6.1267, Val Loss=5.4042
Epoch [3/5]: Train Loss=3.6822, Val Loss=3.9541
Epoch [4/5]: Train Loss=2.3964, Val Loss=3.0585
Epoch [5/5]: Train Loss=1.6625, Val Loss=2.5201
Reservoir Test CPC Loss: 2.1915
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7936, Val Loss=2.2871
Epoch [2/5]: Train Loss=4.3804, Val Loss=2.2896
Epoch [3/5]: Train Loss=3.3848, Val Loss=2.2907
Epoch [4/5]: Train Loss=2.7529, Val Loss=2.2915
Epoch [5/5]: Train Loss=2.5081, Val Loss=2.2927
BERT Test CPC Loss: 2.2925

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=653.5495, Val Loss=11.1098
Epoch [2/5]: Train Loss=38.2908, Val Loss=2.8549
Epoch [3/5]: Train Loss=21.8102, Val Loss=2.6318
Epoch [4/5]: Train Loss=15.8168, Val Loss=2.6343
Epoch [5/5]: Train Loss=12.5848, Val Loss=2.6227
GPT2 Test CPC Loss: 2.6288
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7321, Val Loss=1.0099
Epoch [2/5]: Train Loss=0.6003, Val Loss=0.4134
Epoch [3/5]: Train Loss=0.1550, Val Loss=0.1801
Epoch [4/5]: Train Loss=0.0265, Val Loss=0.0788
Epoch [5/5]: Train Loss=0.0068, Val Loss=0.0603
LSTM Test CPC Loss: 0.0466
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.5313, Val Loss=11.1239
Epoch [2/5]: Train Loss=7.2574, Val Loss=7.1526
Epoch [3/5]: Train Loss=4.4266, Val Loss=5.0355
Epoch [4/5]: Train Loss=2.8247, Val Loss=3.8234
Epoch [5/5]: Train Loss=1.8877, Val Loss=3.0657
Reservoir Test CPC Loss: 3.0709
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7747, Val Loss=2.7032
Epoch [2/5]: Train Loss=4.4648, Val Loss=2.7041
Epoch [3/5]: Train Loss=3.5648, Val Loss=2.7042
Epoch [4/5]: Train Loss=3.0402, Val Loss=2.7047
Epoch [5/5]: Train Loss=2.8557, Val Loss=2.7055
BERT Test CPC Loss: 2.7054

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=491.9295, Val Loss=6.0006
Epoch [2/5]: Train Loss=26.3670, Val Loss=4.9522
Epoch [3/5]: Train Loss=18.0182, Val Loss=5.3975
Epoch [4/5]: Train Loss=14.4651, Val Loss=4.3232
Epoch [5/5]: Train Loss=11.8568, Val Loss=4.4847
GPT2 Test CPC Loss: 4.7213
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1548, Val Loss=1.4384
Epoch [2/5]: Train Loss=1.0636, Val Loss=0.9293
Epoch [3/5]: Train Loss=0.5464, Val Loss=0.5815
Epoch [4/5]: Train Loss=0.1922, Val Loss=0.2080
Epoch [5/5]: Train Loss=0.0446, Val Loss=0.1298
LSTM Test CPC Loss: 0.1277
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.7741, Val Loss=13.5825
Epoch [2/5]: Train Loss=9.5313, Val Loss=8.8276
Epoch [3/5]: Train Loss=5.5415, Val Loss=6.2535
Epoch [4/5]: Train Loss=3.4763, Val Loss=4.6616
Epoch [5/5]: Train Loss=2.3209, Val Loss=3.6442
Reservoir Test CPC Loss: 3.9248
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.6793, Val Loss=2.9898
Epoch [2/5]: Train Loss=4.4147, Val Loss=2.9908
Epoch [3/5]: Train Loss=3.6841, Val Loss=2.9915
Epoch [4/5]: Train Loss=3.3152, Val Loss=2.9919
Epoch [5/5]: Train Loss=3.1598, Val Loss=2.9926
BERT Test CPC Loss: 2.9926

--- Fish 9: Run 8 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=277.2212, Val Loss=1.6297
Epoch [2/5]: Train Loss=21.3141, Val Loss=1.5188
Epoch [3/5]: Train Loss=14.2199, Val Loss=1.4609
Epoch [4/5]: Train Loss=10.2353, Val Loss=1.4338
Epoch [5/5]: Train Loss=7.9038, Val Loss=1.4211
GPT2 Test CPC Loss: 1.4220
[Model: LSTM]
Epoch [1/5]: Train Loss=0.3938, Val Loss=0.0185
Epoch [2/5]: Train Loss=0.0048, Val Loss=0.0042
Epoch [3/5]: Train Loss=0.0011, Val Loss=0.0029
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0021
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0015
LSTM Test CPC Loss: 0.0015
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.5467, Val Loss=4.1666
Epoch [2/5]: Train Loss=2.5849, Val Loss=2.5587
Epoch [3/5]: Train Loss=1.5007, Val Loss=1.8937
Epoch [4/5]: Train Loss=0.9809, Val Loss=1.5196
Epoch [5/5]: Train Loss=0.6613, Val Loss=1.3192
Reservoir Test CPC Loss: 1.2015
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0122, Val Loss=1.5195
Epoch [2/5]: Train Loss=4.6246, Val Loss=1.5217
Epoch [3/5]: Train Loss=3.5542, Val Loss=1.5369
Epoch [4/5]: Train Loss=2.7603, Val Loss=1.5256
Epoch [5/5]: Train Loss=2.2173, Val Loss=1.4819
BERT Test CPC Loss: 1.4829

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=344.7800, Val Loss=2.5334
Epoch [2/5]: Train Loss=25.1009, Val Loss=2.4372
Epoch [3/5]: Train Loss=16.8063, Val Loss=2.3302
Epoch [4/5]: Train Loss=12.7688, Val Loss=2.2904
Epoch [5/5]: Train Loss=10.3395, Val Loss=2.2788
GPT2 Test CPC Loss: 2.2744
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4926, Val Loss=0.7250
Epoch [2/5]: Train Loss=0.3838, Val Loss=0.4618
Epoch [3/5]: Train Loss=0.0782, Val Loss=0.0693
Epoch [4/5]: Train Loss=0.0139, Val Loss=0.0425
Epoch [5/5]: Train Loss=0.0046, Val Loss=0.0401
LSTM Test CPC Loss: 0.0756
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.9346, Val Loss=11.3647
Epoch [2/5]: Train Loss=8.3143, Val Loss=7.3453
Epoch [3/5]: Train Loss=5.1069, Val Loss=5.1469
Epoch [4/5]: Train Loss=3.3231, Val Loss=3.9049
Epoch [5/5]: Train Loss=2.2566, Val Loss=3.0563
Reservoir Test CPC Loss: 3.3436
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.1128, Val Loss=2.2874
Epoch [2/5]: Train Loss=4.5611, Val Loss=2.2884
Epoch [3/5]: Train Loss=3.6069, Val Loss=2.2893
Epoch [4/5]: Train Loss=2.9366, Val Loss=2.2899
Epoch [5/5]: Train Loss=2.5988, Val Loss=2.2923
BERT Test CPC Loss: 2.2923

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=431.0501, Val Loss=2.7496
Epoch [2/5]: Train Loss=23.1628, Val Loss=2.6443
Epoch [3/5]: Train Loss=16.9536, Val Loss=2.6428
Epoch [4/5]: Train Loss=13.5919, Val Loss=2.6561
Epoch [5/5]: Train Loss=11.5557, Val Loss=2.6625
GPT2 Test CPC Loss: 2.6577
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6782, Val Loss=0.9595
Epoch [2/5]: Train Loss=0.5292, Val Loss=0.4829
Epoch [3/5]: Train Loss=0.1400, Val Loss=0.1757
Epoch [4/5]: Train Loss=0.0261, Val Loss=0.0933
Epoch [5/5]: Train Loss=0.0064, Val Loss=0.0458
LSTM Test CPC Loss: 0.0628
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.0209, Val Loss=13.0524
Epoch [2/5]: Train Loss=8.9612, Val Loss=7.6526
Epoch [3/5]: Train Loss=4.9829, Val Loss=5.0511
Epoch [4/5]: Train Loss=2.9754, Val Loss=3.5378
Epoch [5/5]: Train Loss=1.9056, Val Loss=2.6506
Reservoir Test CPC Loss: 3.1682
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.5705, Val Loss=2.7006
Epoch [2/5]: Train Loss=4.4013, Val Loss=2.7020
Epoch [3/5]: Train Loss=3.5294, Val Loss=2.7032
Epoch [4/5]: Train Loss=3.0332, Val Loss=2.7042
Epoch [5/5]: Train Loss=2.8591, Val Loss=2.7047
BERT Test CPC Loss: 2.7047

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=313.1662, Val Loss=3.0361
Epoch [2/5]: Train Loss=21.6838, Val Loss=2.9813
Epoch [3/5]: Train Loss=15.7327, Val Loss=2.9333
Epoch [4/5]: Train Loss=12.5695, Val Loss=2.9406
Epoch [5/5]: Train Loss=10.5440, Val Loss=2.9467
GPT2 Test CPC Loss: 2.9447
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0934, Val Loss=1.3640
Epoch [2/5]: Train Loss=0.8752, Val Loss=0.7004
Epoch [3/5]: Train Loss=0.3283, Val Loss=0.3909
Epoch [4/5]: Train Loss=0.0864, Val Loss=0.1288
Epoch [5/5]: Train Loss=0.0245, Val Loss=0.0547
LSTM Test CPC Loss: 0.0729
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.0691, Val Loss=12.2577
Epoch [2/5]: Train Loss=8.3518, Val Loss=8.4501
Epoch [3/5]: Train Loss=5.2179, Val Loss=5.9466
Epoch [4/5]: Train Loss=3.4210, Val Loss=4.5613
Epoch [5/5]: Train Loss=2.3260, Val Loss=3.5842
Reservoir Test CPC Loss: 3.9041
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.6586, Val Loss=2.9917
Epoch [2/5]: Train Loss=4.5224, Val Loss=2.9919
Epoch [3/5]: Train Loss=3.7810, Val Loss=2.9919
Epoch [4/5]: Train Loss=3.3779, Val Loss=2.9921
Epoch [5/5]: Train Loss=3.1921, Val Loss=2.9925
BERT Test CPC Loss: 2.9925

--- Fish 9: Run 9 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=320.5421, Val Loss=3.9709
Epoch [2/5]: Train Loss=27.6813, Val Loss=1.5407
Epoch [3/5]: Train Loss=17.3986, Val Loss=1.4669
Epoch [4/5]: Train Loss=12.5414, Val Loss=1.4405
Epoch [5/5]: Train Loss=9.9279, Val Loss=1.4321
GPT2 Test CPC Loss: 1.4416
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5737, Val Loss=0.0757
Epoch [2/5]: Train Loss=0.0118, Val Loss=0.0134
Epoch [3/5]: Train Loss=0.0014, Val Loss=0.0063
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0036
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0028
LSTM Test CPC Loss: 0.0029
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.0929, Val Loss=4.7904
Epoch [2/5]: Train Loss=2.8529, Val Loss=2.8336
Epoch [3/5]: Train Loss=1.5893, Val Loss=1.9560
Epoch [4/5]: Train Loss=0.9568, Val Loss=1.5043
Epoch [5/5]: Train Loss=0.5957, Val Loss=1.2090
Reservoir Test CPC Loss: 1.0876
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4679, Val Loss=1.5243
Epoch [2/5]: Train Loss=4.7619, Val Loss=1.5203
Epoch [3/5]: Train Loss=3.7021, Val Loss=1.5252
Epoch [4/5]: Train Loss=2.8552, Val Loss=1.5193
Epoch [5/5]: Train Loss=2.2515, Val Loss=1.4965
BERT Test CPC Loss: 1.4971

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=398.1495, Val Loss=4.1596
Epoch [2/5]: Train Loss=37.9410, Val Loss=2.6752
Epoch [3/5]: Train Loss=26.4930, Val Loss=2.3399
Epoch [4/5]: Train Loss=20.1691, Val Loss=2.2339
Epoch [5/5]: Train Loss=15.9285, Val Loss=2.2157
GPT2 Test CPC Loss: 2.2175
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4545, Val Loss=0.7638
Epoch [2/5]: Train Loss=0.3828, Val Loss=0.2631
Epoch [3/5]: Train Loss=0.0687, Val Loss=0.1878
Epoch [4/5]: Train Loss=0.0129, Val Loss=0.1023
Epoch [5/5]: Train Loss=0.0046, Val Loss=0.0824
LSTM Test CPC Loss: 0.0777
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.8121, Val Loss=10.7112
Epoch [2/5]: Train Loss=7.5906, Val Loss=6.9589
Epoch [3/5]: Train Loss=4.7313, Val Loss=5.0141
Epoch [4/5]: Train Loss=3.1430, Val Loss=3.8555
Epoch [5/5]: Train Loss=2.1855, Val Loss=3.0742
Reservoir Test CPC Loss: 3.1910
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.5794, Val Loss=2.2834
Epoch [2/5]: Train Loss=4.3945, Val Loss=2.2836
Epoch [3/5]: Train Loss=3.3563, Val Loss=2.2866
Epoch [4/5]: Train Loss=2.7260, Val Loss=2.2895
Epoch [5/5]: Train Loss=2.5014, Val Loss=2.2911
BERT Test CPC Loss: 2.2911

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=452.3483, Val Loss=5.9354
Epoch [2/5]: Train Loss=40.8895, Val Loss=3.7772
Epoch [3/5]: Train Loss=27.8977, Val Loss=2.9042
Epoch [4/5]: Train Loss=20.6327, Val Loss=2.7209
Epoch [5/5]: Train Loss=16.6926, Val Loss=2.6646
GPT2 Test CPC Loss: 2.6754
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4288, Val Loss=0.8569
Epoch [2/5]: Train Loss=0.3812, Val Loss=0.2410
Epoch [3/5]: Train Loss=0.0610, Val Loss=0.1259
Epoch [4/5]: Train Loss=0.0117, Val Loss=0.1197
Epoch [5/5]: Train Loss=0.0049, Val Loss=0.0754
LSTM Test CPC Loss: 0.0690
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.3725, Val Loss=11.6604
Epoch [2/5]: Train Loss=8.7242, Val Loss=7.4739
Epoch [3/5]: Train Loss=5.0677, Val Loss=5.2472
Epoch [4/5]: Train Loss=3.1678, Val Loss=3.9633
Epoch [5/5]: Train Loss=2.0473, Val Loss=3.1172
Reservoir Test CPC Loss: 3.0474
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.8982, Val Loss=2.7034
Epoch [2/5]: Train Loss=4.4288, Val Loss=2.7039
Epoch [3/5]: Train Loss=3.5772, Val Loss=2.7039
Epoch [4/5]: Train Loss=3.1003, Val Loss=2.7044
Epoch [5/5]: Train Loss=2.8996, Val Loss=2.7047
BERT Test CPC Loss: 2.7047

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=309.5678, Val Loss=2.9630
Epoch [2/5]: Train Loss=21.3034, Val Loss=2.9303
Epoch [3/5]: Train Loss=16.1041, Val Loss=2.9536
Epoch [4/5]: Train Loss=13.3976, Val Loss=2.9512
Epoch [5/5]: Train Loss=11.3136, Val Loss=2.9463
GPT2 Test CPC Loss: 2.9500
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9806, Val Loss=1.4638
Epoch [2/5]: Train Loss=0.9230, Val Loss=0.8438
Epoch [3/5]: Train Loss=0.3776, Val Loss=0.5702
Epoch [4/5]: Train Loss=0.0987, Val Loss=0.2240
Epoch [5/5]: Train Loss=0.0244, Val Loss=0.1253
LSTM Test CPC Loss: 0.1100
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.3723, Val Loss=12.6952
Epoch [2/5]: Train Loss=8.1051, Val Loss=8.8429
Epoch [3/5]: Train Loss=5.3776, Val Loss=6.7036
Epoch [4/5]: Train Loss=3.6123, Val Loss=5.2558
Epoch [5/5]: Train Loss=2.5162, Val Loss=4.2588
Reservoir Test CPC Loss: 4.3282
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.7587, Val Loss=2.9912
Epoch [2/5]: Train Loss=4.5181, Val Loss=2.9918
Epoch [3/5]: Train Loss=3.7835, Val Loss=2.9926
Epoch [4/5]: Train Loss=3.3624, Val Loss=2.9930
Epoch [5/5]: Train Loss=3.1702, Val Loss=2.9934
BERT Test CPC Loss: 2.9934

--- Fish 9: Run 10 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=450.0152, Val Loss=2.3029
Epoch [2/5]: Train Loss=41.9478, Val Loss=1.5624
Epoch [3/5]: Train Loss=29.2538, Val Loss=1.4735
Epoch [4/5]: Train Loss=22.0507, Val Loss=1.4993
Epoch [5/5]: Train Loss=17.6334, Val Loss=1.5247
GPT2 Test CPC Loss: 1.5455
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7078, Val Loss=0.1264
Epoch [2/5]: Train Loss=0.0240, Val Loss=0.0115
Epoch [3/5]: Train Loss=0.0019, Val Loss=0.0056
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0057
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0040
LSTM Test CPC Loss: 0.0025
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.8576, Val Loss=4.2640
Epoch [2/5]: Train Loss=2.5812, Val Loss=2.6611
Epoch [3/5]: Train Loss=1.4030, Val Loss=1.9567
Epoch [4/5]: Train Loss=0.8662, Val Loss=1.6906
Epoch [5/5]: Train Loss=0.5727, Val Loss=1.4445
Reservoir Test CPC Loss: 1.4788
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.3408, Val Loss=1.5168
Epoch [2/5]: Train Loss=4.7104, Val Loss=1.5125
Epoch [3/5]: Train Loss=3.6629, Val Loss=1.5124
Epoch [4/5]: Train Loss=2.8660, Val Loss=1.5177
Epoch [5/5]: Train Loss=2.2984, Val Loss=1.4942
BERT Test CPC Loss: 1.4949

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=275.7340, Val Loss=3.3219
Epoch [2/5]: Train Loss=22.3235, Val Loss=2.6596
Epoch [3/5]: Train Loss=15.2528, Val Loss=2.6310
Epoch [4/5]: Train Loss=12.1565, Val Loss=2.6544
Epoch [5/5]: Train Loss=10.0614, Val Loss=2.5556
GPT2 Test CPC Loss: 2.5381
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2859, Val Loss=0.5847
Epoch [2/5]: Train Loss=0.2336, Val Loss=0.1583
Epoch [3/5]: Train Loss=0.0305, Val Loss=0.0520
Epoch [4/5]: Train Loss=0.0064, Val Loss=0.0514
Epoch [5/5]: Train Loss=0.0027, Val Loss=0.0305
LSTM Test CPC Loss: 0.0594
[Model: Reservoir]
Epoch [1/5]: Train Loss=13.3367, Val Loss=8.6046
Epoch [2/5]: Train Loss=5.8969, Val Loss=5.5918
Epoch [3/5]: Train Loss=3.4674, Val Loss=3.9251
Epoch [4/5]: Train Loss=2.1820, Val Loss=2.9306
Epoch [5/5]: Train Loss=1.4463, Val Loss=2.3540
Reservoir Test CPC Loss: 2.5849
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.8978, Val Loss=2.2894
Epoch [2/5]: Train Loss=4.4972, Val Loss=2.2924
Epoch [3/5]: Train Loss=3.5411, Val Loss=2.2941
Epoch [4/5]: Train Loss=2.9118, Val Loss=2.2945
Epoch [5/5]: Train Loss=2.5971, Val Loss=2.2952
BERT Test CPC Loss: 2.2952

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=849.3984, Val Loss=3.6935
Epoch [2/5]: Train Loss=54.1047, Val Loss=2.8571
Epoch [3/5]: Train Loss=32.0714, Val Loss=2.8043
Epoch [4/5]: Train Loss=23.1877, Val Loss=2.8460
Epoch [5/5]: Train Loss=18.1668, Val Loss=2.8405
GPT2 Test CPC Loss: 2.8717
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6845, Val Loss=0.9614
Epoch [2/5]: Train Loss=0.5311, Val Loss=0.3292
Epoch [3/5]: Train Loss=0.1122, Val Loss=0.1498
Epoch [4/5]: Train Loss=0.0191, Val Loss=0.0722
Epoch [5/5]: Train Loss=0.0057, Val Loss=0.0640
LSTM Test CPC Loss: 0.0773
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.2342, Val Loss=13.6460
Epoch [2/5]: Train Loss=9.4301, Val Loss=8.9337
Epoch [3/5]: Train Loss=5.6568, Val Loss=6.0391
Epoch [4/5]: Train Loss=3.5742, Val Loss=4.4679
Epoch [5/5]: Train Loss=2.3503, Val Loss=3.4811
Reservoir Test CPC Loss: 3.5798
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.6992, Val Loss=2.7010
Epoch [2/5]: Train Loss=4.4141, Val Loss=2.7028
Epoch [3/5]: Train Loss=3.5295, Val Loss=2.7038
Epoch [4/5]: Train Loss=3.0378, Val Loss=2.7042
Epoch [5/5]: Train Loss=2.8574, Val Loss=2.7050
BERT Test CPC Loss: 2.7050

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=383.5972, Val Loss=3.9796
Epoch [2/5]: Train Loss=28.7867, Val Loss=3.0366
Epoch [3/5]: Train Loss=18.1345, Val Loss=2.9453
Epoch [4/5]: Train Loss=13.3976, Val Loss=2.9453
Epoch [5/5]: Train Loss=10.7628, Val Loss=2.9576
GPT2 Test CPC Loss: 2.9598
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1288, Val Loss=1.4056
Epoch [2/5]: Train Loss=0.9554, Val Loss=0.9089
Epoch [3/5]: Train Loss=0.4696, Val Loss=0.3948
Epoch [4/5]: Train Loss=0.1221, Val Loss=0.1191
Epoch [5/5]: Train Loss=0.0232, Val Loss=0.0641
LSTM Test CPC Loss: 0.0758
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.9891, Val Loss=15.8899
Epoch [2/5]: Train Loss=9.8754, Val Loss=10.0853
Epoch [3/5]: Train Loss=5.6555, Val Loss=6.9909
Epoch [4/5]: Train Loss=3.3754, Val Loss=5.2856
Epoch [5/5]: Train Loss=2.2033, Val Loss=4.2293
Reservoir Test CPC Loss: 3.5943
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=9.8716, Val Loss=2.9893
Epoch [2/5]: Train Loss=4.5679, Val Loss=2.9907
Epoch [3/5]: Train Loss=3.7540, Val Loss=2.9919
Epoch [4/5]: Train Loss=3.3437, Val Loss=2.9925
Epoch [5/5]: Train Loss=3.1796, Val Loss=2.9930
BERT Test CPC Loss: 2.9929

========== Processing Fish 10 ==========
Fish 10: Neural data shape: (2793, 7441)

--- Fish 10: Run 1 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=428.5537, Val Loss=3.6122
Epoch [2/5]: Train Loss=29.5902, Val Loss=1.5516
Epoch [3/5]: Train Loss=13.5427, Val Loss=1.4748
Epoch [4/5]: Train Loss=9.3374, Val Loss=1.4467
Epoch [5/5]: Train Loss=7.4642, Val Loss=1.4132
GPT2 Test CPC Loss: 1.4289
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6989, Val Loss=0.0648
Epoch [2/5]: Train Loss=0.0138, Val Loss=0.0096
Epoch [3/5]: Train Loss=0.0022, Val Loss=0.0027
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0028
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0022
LSTM Test CPC Loss: 0.0046
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.0366, Val Loss=6.4314
Epoch [2/5]: Train Loss=3.5308, Val Loss=4.1296
Epoch [3/5]: Train Loss=1.9104, Val Loss=3.2371
Epoch [4/5]: Train Loss=1.1092, Val Loss=2.6433
Epoch [5/5]: Train Loss=0.6576, Val Loss=2.3161
Reservoir Test CPC Loss: 1.6727
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0364, Val Loss=1.5400
Epoch [2/5]: Train Loss=4.7931, Val Loss=1.6079
Epoch [3/5]: Train Loss=3.7670, Val Loss=1.6664
Epoch [4/5]: Train Loss=3.0604, Val Loss=1.6193
Epoch [5/5]: Train Loss=2.5287, Val Loss=1.5411
BERT Test CPC Loss: 1.5648

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=420.3212, Val Loss=2.5920
Epoch [2/5]: Train Loss=29.0177, Val Loss=2.2768
Epoch [3/5]: Train Loss=19.0044, Val Loss=2.2254
Epoch [4/5]: Train Loss=13.8949, Val Loss=2.2112
Epoch [5/5]: Train Loss=10.9638, Val Loss=2.2054
GPT2 Test CPC Loss: 2.2179
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2616, Val Loss=0.5400
Epoch [2/5]: Train Loss=0.1842, Val Loss=0.1159
Epoch [3/5]: Train Loss=0.0220, Val Loss=0.0480
Epoch [4/5]: Train Loss=0.0058, Val Loss=0.0417
Epoch [5/5]: Train Loss=0.0023, Val Loss=0.0286
LSTM Test CPC Loss: 0.0576
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.6432, Val Loss=11.6733
Epoch [2/5]: Train Loss=8.3918, Val Loss=7.1062
Epoch [3/5]: Train Loss=4.8314, Val Loss=4.9023
Epoch [4/5]: Train Loss=2.9995, Val Loss=3.7091
Epoch [5/5]: Train Loss=1.9629, Val Loss=2.9699
Reservoir Test CPC Loss: 3.2126
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0195, Val Loss=2.2803
Epoch [2/5]: Train Loss=4.7116, Val Loss=2.2816
Epoch [3/5]: Train Loss=3.7719, Val Loss=2.2828
Epoch [4/5]: Train Loss=3.1123, Val Loss=2.2840
Epoch [5/5]: Train Loss=2.7027, Val Loss=2.2865
BERT Test CPC Loss: 2.2852

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=459.0368, Val Loss=3.0073
Epoch [2/5]: Train Loss=25.2718, Val Loss=2.7136
Epoch [3/5]: Train Loss=17.2819, Val Loss=2.7277
Epoch [4/5]: Train Loss=13.3521, Val Loss=2.7263
Epoch [5/5]: Train Loss=10.9873, Val Loss=2.7247
GPT2 Test CPC Loss: 2.7299
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6827, Val Loss=1.0253
Epoch [2/5]: Train Loss=0.4366, Val Loss=0.2584
Epoch [3/5]: Train Loss=0.0529, Val Loss=0.0740
Epoch [4/5]: Train Loss=0.0086, Val Loss=0.0353
Epoch [5/5]: Train Loss=0.0032, Val Loss=0.0243
LSTM Test CPC Loss: 0.0499
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.0086, Val Loss=14.7453
Epoch [2/5]: Train Loss=10.0157, Val Loss=8.4617
Epoch [3/5]: Train Loss=5.1469, Val Loss=5.4146
Epoch [4/5]: Train Loss=2.8877, Val Loss=3.8961
Epoch [5/5]: Train Loss=1.7616, Val Loss=2.9837
Reservoir Test CPC Loss: 2.7215
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0779, Val Loss=2.6976
Epoch [2/5]: Train Loss=4.6702, Val Loss=2.6987
Epoch [3/5]: Train Loss=3.8110, Val Loss=2.6992
Epoch [4/5]: Train Loss=3.2796, Val Loss=2.6990
Epoch [5/5]: Train Loss=2.9989, Val Loss=2.6999
BERT Test CPC Loss: 2.6994

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=413.4891, Val Loss=2.9989
Epoch [2/5]: Train Loss=21.9807, Val Loss=2.9862
Epoch [3/5]: Train Loss=14.0522, Val Loss=2.9463
Epoch [4/5]: Train Loss=10.4458, Val Loss=2.9364
Epoch [5/5]: Train Loss=8.4923, Val Loss=2.9406
GPT2 Test CPC Loss: 2.9627
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8711, Val Loss=1.3404
Epoch [2/5]: Train Loss=0.7330, Val Loss=0.6466
Epoch [3/5]: Train Loss=0.1730, Val Loss=0.2178
Epoch [4/5]: Train Loss=0.0262, Val Loss=0.1025
Epoch [5/5]: Train Loss=0.0076, Val Loss=0.0727
LSTM Test CPC Loss: 0.0871
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.5661, Val Loss=17.2135
Epoch [2/5]: Train Loss=10.6682, Val Loss=9.9865
Epoch [3/5]: Train Loss=5.3783, Val Loss=6.4762
Epoch [4/5]: Train Loss=3.0285, Val Loss=4.6459
Epoch [5/5]: Train Loss=1.8559, Val Loss=3.5775
Reservoir Test CPC Loss: 2.8667
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7839, Val Loss=2.9898
Epoch [2/5]: Train Loss=4.6776, Val Loss=2.9903
Epoch [3/5]: Train Loss=3.8613, Val Loss=2.9907
Epoch [4/5]: Train Loss=3.3703, Val Loss=2.9915
Epoch [5/5]: Train Loss=3.1571, Val Loss=2.9921
BERT Test CPC Loss: 2.9920

--- Fish 10: Run 2 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=303.1555, Val Loss=3.5316
Epoch [2/5]: Train Loss=23.1423, Val Loss=4.1338
Epoch [3/5]: Train Loss=14.6484, Val Loss=3.0457
Epoch [4/5]: Train Loss=10.9589, Val Loss=3.6059
Epoch [5/5]: Train Loss=8.8848, Val Loss=3.1543
GPT2 Test CPC Loss: 5.7107
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7738, Val Loss=0.1070
Epoch [2/5]: Train Loss=0.0229, Val Loss=0.0118
Epoch [3/5]: Train Loss=0.0043, Val Loss=0.0066
Epoch [4/5]: Train Loss=0.0011, Val Loss=0.0015
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0012
LSTM Test CPC Loss: 0.0032
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.6741, Val Loss=5.8147
Epoch [2/5]: Train Loss=3.3610, Val Loss=3.6085
Epoch [3/5]: Train Loss=1.8506, Val Loss=2.6297
Epoch [4/5]: Train Loss=1.1362, Val Loss=2.0996
Epoch [5/5]: Train Loss=0.7377, Val Loss=1.7765
Reservoir Test CPC Loss: 1.6635
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0174, Val Loss=1.5763
Epoch [2/5]: Train Loss=4.7225, Val Loss=1.6538
Epoch [3/5]: Train Loss=3.6770, Val Loss=1.6954
Epoch [4/5]: Train Loss=2.9960, Val Loss=1.6089
Epoch [5/5]: Train Loss=2.4965, Val Loss=1.5288
BERT Test CPC Loss: 1.5433

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=329.3866, Val Loss=8.4962
Epoch [2/5]: Train Loss=20.4300, Val Loss=5.6992
Epoch [3/5]: Train Loss=14.0271, Val Loss=8.3356
Epoch [4/5]: Train Loss=10.7576, Val Loss=6.7240
Epoch [5/5]: Train Loss=9.0945, Val Loss=5.2166
GPT2 Test CPC Loss: 7.3865
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1787, Val Loss=0.5172
Epoch [2/5]: Train Loss=0.1819, Val Loss=0.1065
Epoch [3/5]: Train Loss=0.0184, Val Loss=0.0523
Epoch [4/5]: Train Loss=0.0060, Val Loss=0.0310
Epoch [5/5]: Train Loss=0.0021, Val Loss=0.0284
LSTM Test CPC Loss: 0.1030
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.7778, Val Loss=12.6650
Epoch [2/5]: Train Loss=9.0980, Val Loss=7.0586
Epoch [3/5]: Train Loss=5.0031, Val Loss=4.5669
Epoch [4/5]: Train Loss=3.0121, Val Loss=3.2740
Epoch [5/5]: Train Loss=1.9252, Val Loss=2.5301
Reservoir Test CPC Loss: 2.6074
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2202, Val Loss=2.2800
Epoch [2/5]: Train Loss=4.7438, Val Loss=2.2797
Epoch [3/5]: Train Loss=3.7843, Val Loss=2.2784
Epoch [4/5]: Train Loss=3.1077, Val Loss=2.2773
Epoch [5/5]: Train Loss=2.6806, Val Loss=2.2777
BERT Test CPC Loss: 2.2762

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=462.8980, Val Loss=3.0402
Epoch [2/5]: Train Loss=31.2078, Val Loss=2.7695
Epoch [3/5]: Train Loss=18.7765, Val Loss=2.6997
Epoch [4/5]: Train Loss=13.9232, Val Loss=2.6704
Epoch [5/5]: Train Loss=11.1676, Val Loss=2.6636
GPT2 Test CPC Loss: 2.7073
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8210, Val Loss=1.0757
Epoch [2/5]: Train Loss=0.5149, Val Loss=0.3070
Epoch [3/5]: Train Loss=0.0757, Val Loss=0.0676
Epoch [4/5]: Train Loss=0.0134, Val Loss=0.0461
Epoch [5/5]: Train Loss=0.0048, Val Loss=0.0251
LSTM Test CPC Loss: 0.0617
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.8341, Val Loss=15.2570
Epoch [2/5]: Train Loss=10.9884, Val Loss=8.9847
Epoch [3/5]: Train Loss=5.9321, Val Loss=5.8525
Epoch [4/5]: Train Loss=3.4072, Val Loss=4.2205
Epoch [5/5]: Train Loss=2.1089, Val Loss=3.2325
Reservoir Test CPC Loss: 2.9336
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2746, Val Loss=2.6940
Epoch [2/5]: Train Loss=4.7488, Val Loss=2.6950
Epoch [3/5]: Train Loss=3.8432, Val Loss=2.6970
Epoch [4/5]: Train Loss=3.2280, Val Loss=2.6989
Epoch [5/5]: Train Loss=2.9412, Val Loss=2.6998
BERT Test CPC Loss: 2.6991

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=414.2886, Val Loss=2.9509
Epoch [2/5]: Train Loss=20.1410, Val Loss=3.0318
Epoch [3/5]: Train Loss=13.8923, Val Loss=3.0457
Epoch [4/5]: Train Loss=10.6459, Val Loss=3.0385
Epoch [5/5]: Train Loss=8.9146, Val Loss=3.0202
GPT2 Test CPC Loss: 3.0345
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8664, Val Loss=1.4151
Epoch [2/5]: Train Loss=0.7545, Val Loss=0.5796
Epoch [3/5]: Train Loss=0.1589, Val Loss=0.1403
Epoch [4/5]: Train Loss=0.0203, Val Loss=0.0581
Epoch [5/5]: Train Loss=0.0077, Val Loss=0.0334
LSTM Test CPC Loss: 0.0679
[Model: Reservoir]
Epoch [1/5]: Train Loss=27.2209, Val Loss=18.0794
Epoch [2/5]: Train Loss=11.6107, Val Loss=10.2352
Epoch [3/5]: Train Loss=6.0642, Val Loss=6.4004
Epoch [4/5]: Train Loss=3.4112, Val Loss=4.3462
Epoch [5/5]: Train Loss=2.0809, Val Loss=3.1877
Reservoir Test CPC Loss: 2.7432
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6296, Val Loss=2.9885
Epoch [2/5]: Train Loss=4.6634, Val Loss=2.9898
Epoch [3/5]: Train Loss=3.9340, Val Loss=2.9909
Epoch [4/5]: Train Loss=3.5063, Val Loss=2.9913
Epoch [5/5]: Train Loss=3.2637, Val Loss=2.9918
BERT Test CPC Loss: 2.9916

--- Fish 10: Run 3 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=333.0978, Val Loss=10.8068
Epoch [2/5]: Train Loss=25.9908, Val Loss=6.2061
Epoch [3/5]: Train Loss=17.2467, Val Loss=3.8698
Epoch [4/5]: Train Loss=12.1449, Val Loss=2.1856
Epoch [5/5]: Train Loss=9.2477, Val Loss=2.0875
GPT2 Test CPC Loss: 2.7875
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7903, Val Loss=0.1603
Epoch [2/5]: Train Loss=0.0279, Val Loss=0.0114
Epoch [3/5]: Train Loss=0.0018, Val Loss=0.0040
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0027
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0025
LSTM Test CPC Loss: 0.0021
[Model: Reservoir]
Epoch [1/5]: Train Loss=12.1315, Val Loss=6.0517
Epoch [2/5]: Train Loss=3.9715, Val Loss=3.4978
Epoch [3/5]: Train Loss=2.1610, Val Loss=2.4330
Epoch [4/5]: Train Loss=1.3254, Val Loss=1.8928
Epoch [5/5]: Train Loss=0.8493, Val Loss=1.5443
Reservoir Test CPC Loss: 1.4812
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3906, Val Loss=1.5287
Epoch [2/5]: Train Loss=4.8656, Val Loss=1.5561
Epoch [3/5]: Train Loss=3.7964, Val Loss=1.5918
Epoch [4/5]: Train Loss=2.9996, Val Loss=1.5594
Epoch [5/5]: Train Loss=2.3470, Val Loss=1.5035
BERT Test CPC Loss: 1.5086

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=386.0315, Val Loss=3.1079
Epoch [2/5]: Train Loss=24.4722, Val Loss=3.6543
Epoch [3/5]: Train Loss=16.3633, Val Loss=3.1533
Epoch [4/5]: Train Loss=12.5448, Val Loss=2.9645
Epoch [5/5]: Train Loss=10.3529, Val Loss=2.6663
GPT2 Test CPC Loss: 2.6854
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3662, Val Loss=0.7141
Epoch [2/5]: Train Loss=0.2462, Val Loss=0.1464
Epoch [3/5]: Train Loss=0.0294, Val Loss=0.0662
Epoch [4/5]: Train Loss=0.0092, Val Loss=0.0433
Epoch [5/5]: Train Loss=0.0043, Val Loss=0.0431
LSTM Test CPC Loss: 0.0820
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.9372, Val Loss=13.9067
Epoch [2/5]: Train Loss=8.6209, Val Loss=8.4881
Epoch [3/5]: Train Loss=4.8729, Val Loss=5.8754
Epoch [4/5]: Train Loss=2.9808, Val Loss=4.3765
Epoch [5/5]: Train Loss=1.9182, Val Loss=3.4263
Reservoir Test CPC Loss: 3.1633
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0300, Val Loss=2.2830
Epoch [2/5]: Train Loss=4.7570, Val Loss=2.2829
Epoch [3/5]: Train Loss=3.8039, Val Loss=2.2833
Epoch [4/5]: Train Loss=3.1212, Val Loss=2.2847
Epoch [5/5]: Train Loss=2.6924, Val Loss=2.2860
BERT Test CPC Loss: 2.2847

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=647.3600, Val Loss=7.1217
Epoch [2/5]: Train Loss=40.5534, Val Loss=3.7651
Epoch [3/5]: Train Loss=25.9127, Val Loss=3.1960
Epoch [4/5]: Train Loss=19.3257, Val Loss=3.1624
Epoch [5/5]: Train Loss=15.6561, Val Loss=2.9987
GPT2 Test CPC Loss: 2.9425
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6929, Val Loss=0.9599
Epoch [2/5]: Train Loss=0.4254, Val Loss=0.3669
Epoch [3/5]: Train Loss=0.0500, Val Loss=0.0982
Epoch [4/5]: Train Loss=0.0090, Val Loss=0.0450
Epoch [5/5]: Train Loss=0.0030, Val Loss=0.0294
LSTM Test CPC Loss: 0.0921
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.0674, Val Loss=15.0172
Epoch [2/5]: Train Loss=10.5330, Val Loss=9.3891
Epoch [3/5]: Train Loss=6.0661, Val Loss=6.3493
Epoch [4/5]: Train Loss=3.7037, Val Loss=4.6263
Epoch [5/5]: Train Loss=2.3839, Val Loss=3.5551
Reservoir Test CPC Loss: 3.9320
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8993, Val Loss=2.6945
Epoch [2/5]: Train Loss=4.6275, Val Loss=2.6971
Epoch [3/5]: Train Loss=3.7622, Val Loss=2.6989
Epoch [4/5]: Train Loss=3.2122, Val Loss=2.7007
Epoch [5/5]: Train Loss=2.9335, Val Loss=2.7016
BERT Test CPC Loss: 2.7013

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=347.5932, Val Loss=4.1516
Epoch [2/5]: Train Loss=19.8791, Val Loss=3.2061
Epoch [3/5]: Train Loss=14.6297, Val Loss=3.0849
Epoch [4/5]: Train Loss=11.7085, Val Loss=3.0178
Epoch [5/5]: Train Loss=9.9633, Val Loss=3.0126
GPT2 Test CPC Loss: 3.0173
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0176, Val Loss=1.5375
Epoch [2/5]: Train Loss=0.8339, Val Loss=0.6741
Epoch [3/5]: Train Loss=0.1984, Val Loss=0.1108
Epoch [4/5]: Train Loss=0.0205, Val Loss=0.0445
Epoch [5/5]: Train Loss=0.0051, Val Loss=0.0306
LSTM Test CPC Loss: 0.0459
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.9166, Val Loss=15.3827
Epoch [2/5]: Train Loss=10.3422, Val Loss=9.4650
Epoch [3/5]: Train Loss=5.5989, Val Loss=6.3010
Epoch [4/5]: Train Loss=3.2900, Val Loss=4.6440
Epoch [5/5]: Train Loss=2.0705, Val Loss=3.5995
Reservoir Test CPC Loss: 3.0394
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8541, Val Loss=2.9894
Epoch [2/5]: Train Loss=4.6904, Val Loss=2.9906
Epoch [3/5]: Train Loss=3.8435, Val Loss=2.9913
Epoch [4/5]: Train Loss=3.3427, Val Loss=2.9918
Epoch [5/5]: Train Loss=3.1557, Val Loss=2.9923
BERT Test CPC Loss: 2.9922

--- Fish 10: Run 4 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=330.6102, Val Loss=1.9931
Epoch [2/5]: Train Loss=23.3002, Val Loss=1.6724
Epoch [3/5]: Train Loss=15.4033, Val Loss=1.5015
Epoch [4/5]: Train Loss=11.0582, Val Loss=1.4459
Epoch [5/5]: Train Loss=9.0999, Val Loss=1.4282
GPT2 Test CPC Loss: 1.4414
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6957, Val Loss=0.0617
Epoch [2/5]: Train Loss=0.0142, Val Loss=0.0056
Epoch [3/5]: Train Loss=0.0013, Val Loss=0.0025
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0017
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0013
LSTM Test CPC Loss: 0.0019
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.3024, Val Loss=5.2032
Epoch [2/5]: Train Loss=3.5991, Val Loss=3.2408
Epoch [3/5]: Train Loss=2.0435, Val Loss=2.3489
Epoch [4/5]: Train Loss=1.2661, Val Loss=1.8621
Epoch [5/5]: Train Loss=0.8131, Val Loss=1.5833
Reservoir Test CPC Loss: 1.3368
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8835, Val Loss=1.5396
Epoch [2/5]: Train Loss=4.8304, Val Loss=1.5646
Epoch [3/5]: Train Loss=3.7610, Val Loss=1.6319
Epoch [4/5]: Train Loss=3.0271, Val Loss=1.6067
Epoch [5/5]: Train Loss=2.4956, Val Loss=1.5136
BERT Test CPC Loss: 1.5268

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=406.9928, Val Loss=6.3696
Epoch [2/5]: Train Loss=24.8450, Val Loss=3.9684
Epoch [3/5]: Train Loss=17.8069, Val Loss=3.1703
Epoch [4/5]: Train Loss=13.9807, Val Loss=3.0084
Epoch [5/5]: Train Loss=12.0587, Val Loss=2.8461
GPT2 Test CPC Loss: 2.7914
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5180, Val Loss=0.7714
Epoch [2/5]: Train Loss=0.3115, Val Loss=0.1363
Epoch [3/5]: Train Loss=0.0326, Val Loss=0.0463
Epoch [4/5]: Train Loss=0.0074, Val Loss=0.0367
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0165
LSTM Test CPC Loss: 0.0247
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.4454, Val Loss=14.1367
Epoch [2/5]: Train Loss=9.8379, Val Loss=8.8215
Epoch [3/5]: Train Loss=5.8557, Val Loss=6.0330
Epoch [4/5]: Train Loss=3.6737, Val Loss=4.5263
Epoch [5/5]: Train Loss=2.4316, Val Loss=3.5057
Reservoir Test CPC Loss: 3.3382
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0396, Val Loss=2.2827
Epoch [2/5]: Train Loss=4.7651, Val Loss=2.2842
Epoch [3/5]: Train Loss=3.7679, Val Loss=2.2869
Epoch [4/5]: Train Loss=3.0694, Val Loss=2.2862
Epoch [5/5]: Train Loss=2.6631, Val Loss=2.2866
BERT Test CPC Loss: 2.2856

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=598.2905, Val Loss=10.8790
Epoch [2/5]: Train Loss=36.0004, Val Loss=6.2492
Epoch [3/5]: Train Loss=25.1441, Val Loss=4.3024
Epoch [4/5]: Train Loss=19.5214, Val Loss=4.0656
Epoch [5/5]: Train Loss=15.8795, Val Loss=3.6817
GPT2 Test CPC Loss: 5.4795
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8310, Val Loss=1.1185
Epoch [2/5]: Train Loss=0.4917, Val Loss=0.3431
Epoch [3/5]: Train Loss=0.0677, Val Loss=0.1160
Epoch [4/5]: Train Loss=0.0126, Val Loss=0.0468
Epoch [5/5]: Train Loss=0.0044, Val Loss=0.0260
LSTM Test CPC Loss: 0.0667
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.2262, Val Loss=17.8255
Epoch [2/5]: Train Loss=11.1342, Val Loss=10.3053
Epoch [3/5]: Train Loss=6.1578, Val Loss=6.6393
Epoch [4/5]: Train Loss=3.6330, Val Loss=4.7066
Epoch [5/5]: Train Loss=2.2845, Val Loss=3.5155
Reservoir Test CPC Loss: 3.3203
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8374, Val Loss=2.6970
Epoch [2/5]: Train Loss=4.6712, Val Loss=2.6990
Epoch [3/5]: Train Loss=3.8178, Val Loss=2.7001
Epoch [4/5]: Train Loss=3.2642, Val Loss=2.7004
Epoch [5/5]: Train Loss=2.9699, Val Loss=2.7004
BERT Test CPC Loss: 2.7000

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=380.2791, Val Loss=5.8302
Epoch [2/5]: Train Loss=22.3846, Val Loss=4.6219
Epoch [3/5]: Train Loss=16.3868, Val Loss=5.1879
Epoch [4/5]: Train Loss=13.2095, Val Loss=3.3728
Epoch [5/5]: Train Loss=11.1458, Val Loss=3.6753
GPT2 Test CPC Loss: 3.8699
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9550, Val Loss=1.5214
Epoch [2/5]: Train Loss=0.8148, Val Loss=0.8369
Epoch [3/5]: Train Loss=0.2137, Val Loss=0.2050
Epoch [4/5]: Train Loss=0.0301, Val Loss=0.0702
Epoch [5/5]: Train Loss=0.0086, Val Loss=0.0611
LSTM Test CPC Loss: 0.0877
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.8320, Val Loss=15.4077
Epoch [2/5]: Train Loss=9.5777, Val Loss=8.7590
Epoch [3/5]: Train Loss=4.9123, Val Loss=5.6288
Epoch [4/5]: Train Loss=2.7716, Val Loss=4.0053
Epoch [5/5]: Train Loss=1.7129, Val Loss=3.0857
Reservoir Test CPC Loss: 2.5475
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7857, Val Loss=2.9907
Epoch [2/5]: Train Loss=4.6914, Val Loss=2.9914
Epoch [3/5]: Train Loss=3.9300, Val Loss=2.9921
Epoch [4/5]: Train Loss=3.4774, Val Loss=2.9921
Epoch [5/5]: Train Loss=3.2375, Val Loss=2.9922
BERT Test CPC Loss: 2.9921

--- Fish 10: Run 5 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=336.2276, Val Loss=1.6269
Epoch [2/5]: Train Loss=23.5135, Val Loss=1.5106
Epoch [3/5]: Train Loss=14.7459, Val Loss=1.4523
Epoch [4/5]: Train Loss=10.8228, Val Loss=1.4220
Epoch [5/5]: Train Loss=8.5110, Val Loss=1.4084
GPT2 Test CPC Loss: 1.4181
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7724, Val Loss=0.0990
Epoch [2/5]: Train Loss=0.0283, Val Loss=0.0148
Epoch [3/5]: Train Loss=0.0031, Val Loss=0.0042
Epoch [4/5]: Train Loss=0.0008, Val Loss=0.0030
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0023
LSTM Test CPC Loss: 0.0020
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.3529, Val Loss=6.9979
Epoch [2/5]: Train Loss=3.9127, Val Loss=4.2807
Epoch [3/5]: Train Loss=2.0596, Val Loss=3.0898
Epoch [4/5]: Train Loss=1.1942, Val Loss=2.3592
Epoch [5/5]: Train Loss=0.7348, Val Loss=2.0236
Reservoir Test CPC Loss: 1.7609
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2291, Val Loss=1.5498
Epoch [2/5]: Train Loss=4.8443, Val Loss=1.5493
Epoch [3/5]: Train Loss=3.8673, Val Loss=1.5754
Epoch [4/5]: Train Loss=3.1595, Val Loss=1.5591
Epoch [5/5]: Train Loss=2.5923, Val Loss=1.5272
BERT Test CPC Loss: 1.5451

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=383.3499, Val Loss=2.7997
Epoch [2/5]: Train Loss=26.1830, Val Loss=2.3406
Epoch [3/5]: Train Loss=17.5572, Val Loss=2.2415
Epoch [4/5]: Train Loss=13.6825, Val Loss=2.2189
Epoch [5/5]: Train Loss=10.7433, Val Loss=2.2082
GPT2 Test CPC Loss: 2.2171
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4114, Val Loss=0.6437
Epoch [2/5]: Train Loss=0.2098, Val Loss=0.0811
Epoch [3/5]: Train Loss=0.0185, Val Loss=0.0295
Epoch [4/5]: Train Loss=0.0077, Val Loss=0.0526
Epoch [5/5]: Train Loss=0.0065, Val Loss=0.0164
LSTM Test CPC Loss: 0.0468
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.0920, Val Loss=12.1631
Epoch [2/5]: Train Loss=8.7825, Val Loss=7.5416
Epoch [3/5]: Train Loss=5.0690, Val Loss=5.2416
Epoch [4/5]: Train Loss=3.0944, Val Loss=3.9493
Epoch [5/5]: Train Loss=1.9965, Val Loss=3.0043
Reservoir Test CPC Loss: 2.6768
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6940, Val Loss=2.2830
Epoch [2/5]: Train Loss=4.6544, Val Loss=2.2851
Epoch [3/5]: Train Loss=3.7007, Val Loss=2.2861
Epoch [4/5]: Train Loss=2.9826, Val Loss=2.2866
Epoch [5/5]: Train Loss=2.5745, Val Loss=2.2876
BERT Test CPC Loss: 2.2864

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=369.8347, Val Loss=9.9069
Epoch [2/5]: Train Loss=25.3500, Val Loss=3.2674
Epoch [3/5]: Train Loss=18.5190, Val Loss=2.3609
Epoch [4/5]: Train Loss=14.9108, Val Loss=2.5715
Epoch [5/5]: Train Loss=12.3579, Val Loss=2.7195
GPT2 Test CPC Loss: 2.7039
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8030, Val Loss=1.0804
Epoch [2/5]: Train Loss=0.5363, Val Loss=0.2952
Epoch [3/5]: Train Loss=0.0723, Val Loss=0.0551
Epoch [4/5]: Train Loss=0.0108, Val Loss=0.0290
Epoch [5/5]: Train Loss=0.0041, Val Loss=0.0179
LSTM Test CPC Loss: 0.0388
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.9375, Val Loss=13.5364
Epoch [2/5]: Train Loss=9.0069, Val Loss=8.5573
Epoch [3/5]: Train Loss=5.0523, Val Loss=5.7543
Epoch [4/5]: Train Loss=3.0082, Val Loss=4.2207
Epoch [5/5]: Train Loss=1.9128, Val Loss=3.3648
Reservoir Test CPC Loss: 3.1782
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7104, Val Loss=2.6974
Epoch [2/5]: Train Loss=4.6680, Val Loss=2.7000
Epoch [3/5]: Train Loss=3.7534, Val Loss=2.7009
Epoch [4/5]: Train Loss=3.1668, Val Loss=2.7013
Epoch [5/5]: Train Loss=2.9107, Val Loss=2.7022
BERT Test CPC Loss: 2.7017

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=316.5417, Val Loss=10.4436
Epoch [2/5]: Train Loss=23.2182, Val Loss=5.9183
Epoch [3/5]: Train Loss=16.4005, Val Loss=4.2830
Epoch [4/5]: Train Loss=13.0554, Val Loss=3.8587
Epoch [5/5]: Train Loss=10.8375, Val Loss=3.8142
GPT2 Test CPC Loss: 3.7429
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9906, Val Loss=1.6527
Epoch [2/5]: Train Loss=0.8613, Val Loss=0.8356
Epoch [3/5]: Train Loss=0.2518, Val Loss=0.2372
Epoch [4/5]: Train Loss=0.0393, Val Loss=0.0713
Epoch [5/5]: Train Loss=0.0100, Val Loss=0.0546
LSTM Test CPC Loss: 0.0896
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.9531, Val Loss=16.0879
Epoch [2/5]: Train Loss=10.4821, Val Loss=9.6918
Epoch [3/5]: Train Loss=5.6561, Val Loss=6.4125
Epoch [4/5]: Train Loss=3.2605, Val Loss=4.6823
Epoch [5/5]: Train Loss=2.0285, Val Loss=3.5316
Reservoir Test CPC Loss: 3.2047
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7714, Val Loss=2.9888
Epoch [2/5]: Train Loss=4.7312, Val Loss=2.9894
Epoch [3/5]: Train Loss=3.9296, Val Loss=2.9898
Epoch [4/5]: Train Loss=3.4836, Val Loss=2.9902
Epoch [5/5]: Train Loss=3.2503, Val Loss=2.9902
BERT Test CPC Loss: 2.9902

--- Fish 10: Run 6 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=324.7916, Val Loss=1.7580
Epoch [2/5]: Train Loss=24.0886, Val Loss=1.4923
Epoch [3/5]: Train Loss=14.1176, Val Loss=1.4390
Epoch [4/5]: Train Loss=10.2141, Val Loss=1.4178
Epoch [5/5]: Train Loss=8.1258, Val Loss=1.4075
GPT2 Test CPC Loss: 1.4116
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6932, Val Loss=0.0677
Epoch [2/5]: Train Loss=0.0154, Val Loss=0.0080
Epoch [3/5]: Train Loss=0.0014, Val Loss=0.0049
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0035
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0030
LSTM Test CPC Loss: 0.0023
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.5805, Val Loss=6.8515
Epoch [2/5]: Train Loss=3.8444, Val Loss=4.4406
Epoch [3/5]: Train Loss=2.1403, Val Loss=3.2383
Epoch [4/5]: Train Loss=1.2855, Val Loss=2.6836
Epoch [5/5]: Train Loss=0.8032, Val Loss=2.2486
Reservoir Test CPC Loss: 1.7828
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4558, Val Loss=1.5108
Epoch [2/5]: Train Loss=4.9441, Val Loss=1.5090
Epoch [3/5]: Train Loss=3.8899, Val Loss=1.5336
Epoch [4/5]: Train Loss=3.0927, Val Loss=1.5486
Epoch [5/5]: Train Loss=2.4761, Val Loss=1.5005
BERT Test CPC Loss: 1.5143

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=318.4255, Val Loss=2.2506
Epoch [2/5]: Train Loss=22.1474, Val Loss=2.2206
Epoch [3/5]: Train Loss=13.8579, Val Loss=2.2098
Epoch [4/5]: Train Loss=10.5681, Val Loss=2.2071
Epoch [5/5]: Train Loss=8.4621, Val Loss=2.2047
GPT2 Test CPC Loss: 2.2127
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6075, Val Loss=0.9963
Epoch [2/5]: Train Loss=0.4073, Val Loss=0.1899
Epoch [3/5]: Train Loss=0.0556, Val Loss=0.0655
Epoch [4/5]: Train Loss=0.0114, Val Loss=0.0432
Epoch [5/5]: Train Loss=0.0043, Val Loss=0.0313
LSTM Test CPC Loss: 0.0549
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.4262, Val Loss=12.3838
Epoch [2/5]: Train Loss=8.7906, Val Loss=7.9573
Epoch [3/5]: Train Loss=5.2614, Val Loss=5.6252
Epoch [4/5]: Train Loss=3.3541, Val Loss=4.3393
Epoch [5/5]: Train Loss=2.2453, Val Loss=3.4626
Reservoir Test CPC Loss: 3.2676
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1561, Val Loss=2.2835
Epoch [2/5]: Train Loss=4.6961, Val Loss=2.2859
Epoch [3/5]: Train Loss=3.7217, Val Loss=2.2869
Epoch [4/5]: Train Loss=2.9398, Val Loss=2.2891
Epoch [5/5]: Train Loss=2.5304, Val Loss=2.2896
BERT Test CPC Loss: 2.2886

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=337.2118, Val Loss=2.8559
Epoch [2/5]: Train Loss=22.9812, Val Loss=2.7722
Epoch [3/5]: Train Loss=14.5331, Val Loss=2.7073
Epoch [4/5]: Train Loss=11.0117, Val Loss=2.6837
Epoch [5/5]: Train Loss=8.9481, Val Loss=2.6701
GPT2 Test CPC Loss: 2.6862
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5720, Val Loss=0.8756
Epoch [2/5]: Train Loss=0.3519, Val Loss=0.2304
Epoch [3/5]: Train Loss=0.0487, Val Loss=0.0687
Epoch [4/5]: Train Loss=0.0127, Val Loss=0.0312
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0159
LSTM Test CPC Loss: 0.0566
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.3720, Val Loss=14.8295
Epoch [2/5]: Train Loss=10.3885, Val Loss=8.4373
Epoch [3/5]: Train Loss=5.5813, Val Loss=5.3019
Epoch [4/5]: Train Loss=3.2668, Val Loss=3.6783
Epoch [5/5]: Train Loss=2.0533, Val Loss=2.7283
Reservoir Test CPC Loss: 3.0675
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0008, Val Loss=2.6984
Epoch [2/5]: Train Loss=4.6773, Val Loss=2.6993
Epoch [3/5]: Train Loss=3.8241, Val Loss=2.7005
Epoch [4/5]: Train Loss=3.2939, Val Loss=2.7012
Epoch [5/5]: Train Loss=2.9978, Val Loss=2.7015
BERT Test CPC Loss: 2.7010

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=395.3944, Val Loss=3.3778
Epoch [2/5]: Train Loss=29.5419, Val Loss=3.0796
Epoch [3/5]: Train Loss=18.6888, Val Loss=3.0217
Epoch [4/5]: Train Loss=14.1742, Val Loss=2.9876
Epoch [5/5]: Train Loss=11.4263, Val Loss=2.9708
GPT2 Test CPC Loss: 2.9919
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8988, Val Loss=1.3969
Epoch [2/5]: Train Loss=0.7098, Val Loss=0.6875
Epoch [3/5]: Train Loss=0.1709, Val Loss=0.1983
Epoch [4/5]: Train Loss=0.0296, Val Loss=0.0824
Epoch [5/5]: Train Loss=0.0085, Val Loss=0.0655
LSTM Test CPC Loss: 0.0904
[Model: Reservoir]
Epoch [1/5]: Train Loss=26.5582, Val Loss=18.2264
Epoch [2/5]: Train Loss=11.2981, Val Loss=10.4617
Epoch [3/5]: Train Loss=6.0062, Val Loss=6.6924
Epoch [4/5]: Train Loss=3.4441, Val Loss=4.6378
Epoch [5/5]: Train Loss=2.1324, Val Loss=3.4874
Reservoir Test CPC Loss: 3.2790
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1125, Val Loss=2.9895
Epoch [2/5]: Train Loss=4.7586, Val Loss=2.9896
Epoch [3/5]: Train Loss=3.9169, Val Loss=2.9905
Epoch [4/5]: Train Loss=3.4071, Val Loss=2.9914
Epoch [5/5]: Train Loss=3.1754, Val Loss=2.9920
BERT Test CPC Loss: 2.9918

--- Fish 10: Run 7 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=298.0791, Val Loss=3.6696
Epoch [2/5]: Train Loss=19.1742, Val Loss=3.2666
Epoch [3/5]: Train Loss=13.4174, Val Loss=2.4965
Epoch [4/5]: Train Loss=10.4159, Val Loss=2.7309
Epoch [5/5]: Train Loss=8.1533, Val Loss=1.5743
GPT2 Test CPC Loss: 1.5264
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7235, Val Loss=0.0993
Epoch [2/5]: Train Loss=0.0195, Val Loss=0.0076
Epoch [3/5]: Train Loss=0.0022, Val Loss=0.0034
Epoch [4/5]: Train Loss=0.0009, Val Loss=0.0024
Epoch [5/5]: Train Loss=0.0006, Val Loss=0.0019
LSTM Test CPC Loss: 0.0062
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.8470, Val Loss=6.4534
Epoch [2/5]: Train Loss=3.6053, Val Loss=3.7287
Epoch [3/5]: Train Loss=1.9068, Val Loss=2.6770
Epoch [4/5]: Train Loss=1.1639, Val Loss=2.1194
Epoch [5/5]: Train Loss=0.7270, Val Loss=1.7578
Reservoir Test CPC Loss: 1.5356
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8652, Val Loss=1.5323
Epoch [2/5]: Train Loss=4.7212, Val Loss=1.6042
Epoch [3/5]: Train Loss=3.6729, Val Loss=1.6286
Epoch [4/5]: Train Loss=2.9718, Val Loss=1.6005
Epoch [5/5]: Train Loss=2.4402, Val Loss=1.5017
BERT Test CPC Loss: 1.5148

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=391.7995, Val Loss=2.4881
Epoch [2/5]: Train Loss=28.3535, Val Loss=2.2698
Epoch [3/5]: Train Loss=18.4610, Val Loss=2.2290
Epoch [4/5]: Train Loss=13.3259, Val Loss=2.2122
Epoch [5/5]: Train Loss=10.9440, Val Loss=2.2062
GPT2 Test CPC Loss: 2.2175
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3898, Val Loss=0.5972
Epoch [2/5]: Train Loss=0.1832, Val Loss=0.0785
Epoch [3/5]: Train Loss=0.0153, Val Loss=0.0236
Epoch [4/5]: Train Loss=0.0040, Val Loss=0.0185
Epoch [5/5]: Train Loss=0.0018, Val Loss=0.0156
LSTM Test CPC Loss: 0.0261
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.4217, Val Loss=13.9678
Epoch [2/5]: Train Loss=10.0905, Val Loss=8.4459
Epoch [3/5]: Train Loss=5.7538, Val Loss=5.7807
Epoch [4/5]: Train Loss=3.5522, Val Loss=4.2993
Epoch [5/5]: Train Loss=2.3224, Val Loss=3.4029
Reservoir Test CPC Loss: 3.2478
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3937, Val Loss=2.2839
Epoch [2/5]: Train Loss=4.8423, Val Loss=2.2829
Epoch [3/5]: Train Loss=3.8833, Val Loss=2.2831
Epoch [4/5]: Train Loss=3.1320, Val Loss=2.2848
Epoch [5/5]: Train Loss=2.6697, Val Loss=2.2867
BERT Test CPC Loss: 2.2855

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=349.0793, Val Loss=2.9730
Epoch [2/5]: Train Loss=21.8800, Val Loss=2.6644
Epoch [3/5]: Train Loss=12.9756, Val Loss=2.6338
Epoch [4/5]: Train Loss=9.5247, Val Loss=2.6330
Epoch [5/5]: Train Loss=7.4764, Val Loss=2.6340
GPT2 Test CPC Loss: 2.6653
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8521, Val Loss=1.6724
Epoch [2/5]: Train Loss=0.6556, Val Loss=0.5788
Epoch [3/5]: Train Loss=0.1427, Val Loss=0.2418
Epoch [4/5]: Train Loss=0.0231, Val Loss=0.1261
Epoch [5/5]: Train Loss=0.0075, Val Loss=0.1136
LSTM Test CPC Loss: 0.0789
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.3871, Val Loss=16.0342
Epoch [2/5]: Train Loss=10.8025, Val Loss=9.4604
Epoch [3/5]: Train Loss=5.7879, Val Loss=6.2790
Epoch [4/5]: Train Loss=3.3538, Val Loss=4.4361
Epoch [5/5]: Train Loss=2.0871, Val Loss=3.4796
Reservoir Test CPC Loss: 3.3822
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9512, Val Loss=2.6994
Epoch [2/5]: Train Loss=4.7057, Val Loss=2.7013
Epoch [3/5]: Train Loss=3.8331, Val Loss=2.7028
Epoch [4/5]: Train Loss=3.2590, Val Loss=2.7034
Epoch [5/5]: Train Loss=2.9444, Val Loss=2.7040
BERT Test CPC Loss: 2.7037

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=329.7441, Val Loss=3.0309
Epoch [2/5]: Train Loss=17.9425, Val Loss=2.9135
Epoch [3/5]: Train Loss=14.1233, Val Loss=2.9064
Epoch [4/5]: Train Loss=12.0350, Val Loss=2.9150
Epoch [5/5]: Train Loss=10.3537, Val Loss=2.9278
GPT2 Test CPC Loss: 2.9360
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1209, Val Loss=1.6110
Epoch [2/5]: Train Loss=0.8489, Val Loss=0.6558
Epoch [3/5]: Train Loss=0.2133, Val Loss=0.1366
Epoch [4/5]: Train Loss=0.0322, Val Loss=0.0492
Epoch [5/5]: Train Loss=0.0099, Val Loss=0.0281
LSTM Test CPC Loss: 0.0758
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.1141, Val Loss=16.8722
Epoch [2/5]: Train Loss=10.7017, Val Loss=9.9954
Epoch [3/5]: Train Loss=5.6620, Val Loss=6.5621
Epoch [4/5]: Train Loss=3.2218, Val Loss=4.6195
Epoch [5/5]: Train Loss=1.9701, Val Loss=3.5198
Reservoir Test CPC Loss: 2.9388
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8201, Val Loss=2.9867
Epoch [2/5]: Train Loss=4.6893, Val Loss=2.9875
Epoch [3/5]: Train Loss=3.9060, Val Loss=2.9879
Epoch [4/5]: Train Loss=3.4423, Val Loss=2.9888
Epoch [5/5]: Train Loss=3.2078, Val Loss=2.9898
BERT Test CPC Loss: 2.9895

--- Fish 10: Run 8 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=379.8645, Val Loss=1.9318
Epoch [2/5]: Train Loss=30.4578, Val Loss=1.4733
Epoch [3/5]: Train Loss=19.2470, Val Loss=1.4622
Epoch [4/5]: Train Loss=13.7063, Val Loss=1.4521
Epoch [5/5]: Train Loss=10.8557, Val Loss=1.4228
GPT2 Test CPC Loss: 1.4383
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6666, Val Loss=0.0748
Epoch [2/5]: Train Loss=0.0159, Val Loss=0.0173
Epoch [3/5]: Train Loss=0.0019, Val Loss=0.0094
Epoch [4/5]: Train Loss=0.0041, Val Loss=0.0085
Epoch [5/5]: Train Loss=0.0012, Val Loss=0.0013
LSTM Test CPC Loss: 0.0020
[Model: Reservoir]
Epoch [1/5]: Train Loss=11.0417, Val Loss=5.4380
Epoch [2/5]: Train Loss=3.8388, Val Loss=3.2466
Epoch [3/5]: Train Loss=2.1474, Val Loss=2.4220
Epoch [4/5]: Train Loss=1.3492, Val Loss=1.8966
Epoch [5/5]: Train Loss=0.8651, Val Loss=1.5838
Reservoir Test CPC Loss: 1.5436
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1958, Val Loss=1.5481
Epoch [2/5]: Train Loss=4.7964, Val Loss=1.5880
Epoch [3/5]: Train Loss=3.6747, Val Loss=1.5994
Epoch [4/5]: Train Loss=2.6844, Val Loss=1.5245
Epoch [5/5]: Train Loss=2.0487, Val Loss=1.4988
BERT Test CPC Loss: 1.4979

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=394.2699, Val Loss=4.2183
Epoch [2/5]: Train Loss=28.5591, Val Loss=3.3059
Epoch [3/5]: Train Loss=19.2895, Val Loss=3.6132
Epoch [4/5]: Train Loss=15.4228, Val Loss=3.4672
Epoch [5/5]: Train Loss=12.3663, Val Loss=3.1311
GPT2 Test CPC Loss: 3.1106
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2706, Val Loss=0.5638
Epoch [2/5]: Train Loss=0.1831, Val Loss=0.0866
Epoch [3/5]: Train Loss=0.0161, Val Loss=0.0330
Epoch [4/5]: Train Loss=0.0042, Val Loss=0.0222
Epoch [5/5]: Train Loss=0.0022, Val Loss=0.0168
LSTM Test CPC Loss: 0.0465
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.0062, Val Loss=13.4031
Epoch [2/5]: Train Loss=9.4574, Val Loss=8.2029
Epoch [3/5]: Train Loss=5.2623, Val Loss=5.6330
Epoch [4/5]: Train Loss=3.1799, Val Loss=4.1598
Epoch [5/5]: Train Loss=2.0338, Val Loss=3.3337
Reservoir Test CPC Loss: 3.0958
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.6178, Val Loss=2.2890
Epoch [2/5]: Train Loss=4.8815, Val Loss=2.2857
Epoch [3/5]: Train Loss=3.8997, Val Loss=2.2853
Epoch [4/5]: Train Loss=3.1523, Val Loss=2.2874
Epoch [5/5]: Train Loss=2.6618, Val Loss=2.2885
BERT Test CPC Loss: 2.2876

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=543.2769, Val Loss=8.9880
Epoch [2/5]: Train Loss=44.8694, Val Loss=3.1578
Epoch [3/5]: Train Loss=26.8743, Val Loss=2.7474
Epoch [4/5]: Train Loss=19.0040, Val Loss=2.6667
Epoch [5/5]: Train Loss=15.0630, Val Loss=2.6030
GPT2 Test CPC Loss: 2.6322
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5434, Val Loss=0.9957
Epoch [2/5]: Train Loss=0.4042, Val Loss=0.2693
Epoch [3/5]: Train Loss=0.0587, Val Loss=0.0955
Epoch [4/5]: Train Loss=0.0102, Val Loss=0.0633
Epoch [5/5]: Train Loss=0.0040, Val Loss=0.0443
LSTM Test CPC Loss: 0.0610
[Model: Reservoir]
Epoch [1/5]: Train Loss=26.4384, Val Loss=16.4786
Epoch [2/5]: Train Loss=11.3007, Val Loss=9.3398
Epoch [3/5]: Train Loss=6.1607, Val Loss=5.8243
Epoch [4/5]: Train Loss=3.6104, Val Loss=4.0018
Epoch [5/5]: Train Loss=2.2752, Val Loss=2.9635
Reservoir Test CPC Loss: 3.5111
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7923, Val Loss=2.6959
Epoch [2/5]: Train Loss=4.6428, Val Loss=2.6969
Epoch [3/5]: Train Loss=3.7908, Val Loss=2.6969
Epoch [4/5]: Train Loss=3.2516, Val Loss=2.6977
Epoch [5/5]: Train Loss=2.9718, Val Loss=2.6981
BERT Test CPC Loss: 2.6972

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=295.6152, Val Loss=2.8878
Epoch [2/5]: Train Loss=20.7155, Val Loss=2.9159
Epoch [3/5]: Train Loss=14.8234, Val Loss=2.9368
Epoch [4/5]: Train Loss=11.8817, Val Loss=2.9363
Epoch [5/5]: Train Loss=9.9682, Val Loss=2.9442
GPT2 Test CPC Loss: 2.9500
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9246, Val Loss=1.4421
Epoch [2/5]: Train Loss=0.7509, Val Loss=0.6216
Epoch [3/5]: Train Loss=0.1611, Val Loss=0.2514
Epoch [4/5]: Train Loss=0.0223, Val Loss=0.1214
Epoch [5/5]: Train Loss=0.0068, Val Loss=0.0837
LSTM Test CPC Loss: 0.1004
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.1365, Val Loss=13.2786
Epoch [2/5]: Train Loss=10.1738, Val Loss=8.0206
Epoch [3/5]: Train Loss=5.6684, Val Loss=5.2688
Epoch [4/5]: Train Loss=3.3654, Val Loss=3.7288
Epoch [5/5]: Train Loss=2.1334, Val Loss=2.8630
Reservoir Test CPC Loss: 3.1039
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8556, Val Loss=2.9889
Epoch [2/5]: Train Loss=4.7382, Val Loss=2.9903
Epoch [3/5]: Train Loss=3.9309, Val Loss=2.9910
Epoch [4/5]: Train Loss=3.4493, Val Loss=2.9914
Epoch [5/5]: Train Loss=3.2052, Val Loss=2.9922
BERT Test CPC Loss: 2.9922

--- Fish 10: Run 9 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=515.1297, Val Loss=4.1620
Epoch [2/5]: Train Loss=35.0525, Val Loss=3.5192
Epoch [3/5]: Train Loss=21.4236, Val Loss=2.0967
Epoch [4/5]: Train Loss=15.9517, Val Loss=2.1686
Epoch [5/5]: Train Loss=12.0099, Val Loss=1.8371
GPT2 Test CPC Loss: 1.7812
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7535, Val Loss=0.1082
Epoch [2/5]: Train Loss=0.0200, Val Loss=0.0108
Epoch [3/5]: Train Loss=0.0074, Val Loss=0.0061
Epoch [4/5]: Train Loss=0.0010, Val Loss=0.0029
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0019
LSTM Test CPC Loss: 0.0029
[Model: Reservoir]
Epoch [1/5]: Train Loss=12.8883, Val Loss=7.5037
Epoch [2/5]: Train Loss=4.6850, Val Loss=4.0780
Epoch [3/5]: Train Loss=2.5456, Val Loss=2.8483
Epoch [4/5]: Train Loss=1.5380, Val Loss=2.1202
Epoch [5/5]: Train Loss=0.9715, Val Loss=1.7305
Reservoir Test CPC Loss: 2.2456
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0707, Val Loss=1.5339
Epoch [2/5]: Train Loss=4.8367, Val Loss=1.5583
Epoch [3/5]: Train Loss=3.7574, Val Loss=1.5871
Epoch [4/5]: Train Loss=3.0013, Val Loss=1.5776
Epoch [5/5]: Train Loss=2.4302, Val Loss=1.5030
BERT Test CPC Loss: 1.5165

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=381.8382, Val Loss=2.9839
Epoch [2/5]: Train Loss=26.7575, Val Loss=2.3707
Epoch [3/5]: Train Loss=16.6633, Val Loss=2.2612
Epoch [4/5]: Train Loss=12.3069, Val Loss=2.2309
Epoch [5/5]: Train Loss=9.9485, Val Loss=2.2240
GPT2 Test CPC Loss: 2.2406
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4502, Val Loss=0.7590
Epoch [2/5]: Train Loss=0.2730, Val Loss=0.2611
Epoch [3/5]: Train Loss=0.0296, Val Loss=0.1052
Epoch [4/5]: Train Loss=0.0080, Val Loss=0.1185
Epoch [5/5]: Train Loss=0.0035, Val Loss=0.0814
LSTM Test CPC Loss: 0.0673
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.8403, Val Loss=12.1621
Epoch [2/5]: Train Loss=8.9953, Val Loss=7.9411
Epoch [3/5]: Train Loss=5.3625, Val Loss=5.7152
Epoch [4/5]: Train Loss=3.3787, Val Loss=4.2825
Epoch [5/5]: Train Loss=2.2184, Val Loss=3.3965
Reservoir Test CPC Loss: 3.7114
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2591, Val Loss=2.2810
Epoch [2/5]: Train Loss=4.7531, Val Loss=2.2810
Epoch [3/5]: Train Loss=3.7414, Val Loss=2.2833
Epoch [4/5]: Train Loss=2.9619, Val Loss=2.2862
Epoch [5/5]: Train Loss=2.5701, Val Loss=2.2886
BERT Test CPC Loss: 2.2877

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=409.4475, Val Loss=2.7161
Epoch [2/5]: Train Loss=25.0632, Val Loss=2.6339
Epoch [3/5]: Train Loss=15.1418, Val Loss=2.6299
Epoch [4/5]: Train Loss=10.9402, Val Loss=2.6309
Epoch [5/5]: Train Loss=8.7553, Val Loss=2.6333
GPT2 Test CPC Loss: 2.6414
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7820, Val Loss=1.1032
Epoch [2/5]: Train Loss=0.5060, Val Loss=0.2910
Epoch [3/5]: Train Loss=0.0676, Val Loss=0.1067
Epoch [4/5]: Train Loss=0.0120, Val Loss=0.0523
Epoch [5/5]: Train Loss=0.0043, Val Loss=0.0257
LSTM Test CPC Loss: 0.0406
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.9584, Val Loss=15.6246
Epoch [2/5]: Train Loss=10.0378, Val Loss=9.3353
Epoch [3/5]: Train Loss=5.5697, Val Loss=6.1101
Epoch [4/5]: Train Loss=3.3355, Val Loss=4.3808
Epoch [5/5]: Train Loss=2.1128, Val Loss=3.3867
Reservoir Test CPC Loss: 3.0894
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0449, Val Loss=2.6979
Epoch [2/5]: Train Loss=4.6556, Val Loss=2.6991
Epoch [3/5]: Train Loss=3.7972, Val Loss=2.7007
Epoch [4/5]: Train Loss=3.1996, Val Loss=2.7018
Epoch [5/5]: Train Loss=2.9030, Val Loss=2.7026
BERT Test CPC Loss: 2.7022

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=433.6262, Val Loss=3.3788
Epoch [2/5]: Train Loss=23.5528, Val Loss=2.9114
Epoch [3/5]: Train Loss=16.8767, Val Loss=3.0174
Epoch [4/5]: Train Loss=13.7261, Val Loss=2.9453
Epoch [5/5]: Train Loss=11.7501, Val Loss=2.9767
GPT2 Test CPC Loss: 2.9912
[Model: LSTM]
Epoch [1/5]: Train Loss=2.2998, Val Loss=1.7584
Epoch [2/5]: Train Loss=1.0982, Val Loss=1.0688
Epoch [3/5]: Train Loss=0.4115, Val Loss=0.4168
Epoch [4/5]: Train Loss=0.0710, Val Loss=0.1231
Epoch [5/5]: Train Loss=0.0124, Val Loss=0.0620
LSTM Test CPC Loss: 0.0692
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.9675, Val Loss=16.6752
Epoch [2/5]: Train Loss=10.6308, Val Loss=9.6750
Epoch [3/5]: Train Loss=5.6890, Val Loss=6.1868
Epoch [4/5]: Train Loss=3.2723, Val Loss=4.2831
Epoch [5/5]: Train Loss=2.0349, Val Loss=3.1800
Reservoir Test CPC Loss: 2.9479
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0780, Val Loss=2.9878
Epoch [2/5]: Train Loss=4.7423, Val Loss=2.9891
Epoch [3/5]: Train Loss=3.9810, Val Loss=2.9896
Epoch [4/5]: Train Loss=3.5303, Val Loss=2.9899
Epoch [5/5]: Train Loss=3.2657, Val Loss=2.9905
BERT Test CPC Loss: 2.9903

--- Fish 10: Run 10 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=369.0958, Val Loss=3.9628
Epoch [2/5]: Train Loss=27.3258, Val Loss=3.5077
Epoch [3/5]: Train Loss=18.1922, Val Loss=2.9230
Epoch [4/5]: Train Loss=13.5478, Val Loss=2.2469
Epoch [5/5]: Train Loss=10.9821, Val Loss=2.2587
GPT2 Test CPC Loss: 2.1354
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7226, Val Loss=0.0924
Epoch [2/5]: Train Loss=0.0178, Val Loss=0.0067
Epoch [3/5]: Train Loss=0.0012, Val Loss=0.0035
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0021
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0015
LSTM Test CPC Loss: 0.0033
[Model: Reservoir]
Epoch [1/5]: Train Loss=12.9995, Val Loss=6.4019
Epoch [2/5]: Train Loss=3.9493, Val Loss=3.3333
Epoch [3/5]: Train Loss=2.0571, Val Loss=2.2588
Epoch [4/5]: Train Loss=1.2198, Val Loss=1.7470
Epoch [5/5]: Train Loss=0.7539, Val Loss=1.4561
Reservoir Test CPC Loss: 1.4940
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2745, Val Loss=1.5114
Epoch [2/5]: Train Loss=4.9152, Val Loss=1.5202
Epoch [3/5]: Train Loss=3.8859, Val Loss=1.5842
Epoch [4/5]: Train Loss=3.0912, Val Loss=1.5585
Epoch [5/5]: Train Loss=2.4608, Val Loss=1.5076
BERT Test CPC Loss: 1.5239

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=532.9939, Val Loss=2.3342
Epoch [2/5]: Train Loss=31.1364, Val Loss=2.3196
Epoch [3/5]: Train Loss=21.9431, Val Loss=2.3308
Epoch [4/5]: Train Loss=17.0518, Val Loss=2.3673
Epoch [5/5]: Train Loss=14.1185, Val Loss=2.3389
GPT2 Test CPC Loss: 2.3503
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1189, Val Loss=0.4071
Epoch [2/5]: Train Loss=0.1218, Val Loss=0.1068
Epoch [3/5]: Train Loss=0.0133, Val Loss=0.0320
Epoch [4/5]: Train Loss=0.0032, Val Loss=0.0175
Epoch [5/5]: Train Loss=0.0016, Val Loss=0.0166
LSTM Test CPC Loss: 0.0343
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.5649, Val Loss=11.2657
Epoch [2/5]: Train Loss=8.5146, Val Loss=6.8788
Epoch [3/5]: Train Loss=4.9042, Val Loss=4.5708
Epoch [4/5]: Train Loss=3.0127, Val Loss=3.3918
Epoch [5/5]: Train Loss=1.9414, Val Loss=2.6394
Reservoir Test CPC Loss: 2.8154
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0782, Val Loss=2.2750
Epoch [2/5]: Train Loss=4.7265, Val Loss=2.2759
Epoch [3/5]: Train Loss=3.7467, Val Loss=2.2775
Epoch [4/5]: Train Loss=3.0234, Val Loss=2.2792
Epoch [5/5]: Train Loss=2.6122, Val Loss=2.2804
BERT Test CPC Loss: 2.2787

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=439.9802, Val Loss=3.7101
Epoch [2/5]: Train Loss=28.8047, Val Loss=2.8550
Epoch [3/5]: Train Loss=20.3294, Val Loss=2.9539
Epoch [4/5]: Train Loss=15.9984, Val Loss=3.0001
Epoch [5/5]: Train Loss=13.0028, Val Loss=3.0140
GPT2 Test CPC Loss: 3.1176
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4802, Val Loss=0.8592
Epoch [2/5]: Train Loss=0.3775, Val Loss=0.3095
Epoch [3/5]: Train Loss=0.0639, Val Loss=0.0945
Epoch [4/5]: Train Loss=0.0119, Val Loss=0.0598
Epoch [5/5]: Train Loss=0.0046, Val Loss=0.0469
LSTM Test CPC Loss: 0.1005
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.1312, Val Loss=15.6123
Epoch [2/5]: Train Loss=10.7025, Val Loss=9.2569
Epoch [3/5]: Train Loss=5.8126, Val Loss=6.1116
Epoch [4/5]: Train Loss=3.3820, Val Loss=4.4064
Epoch [5/5]: Train Loss=2.1168, Val Loss=3.3797
Reservoir Test CPC Loss: 3.0461
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2069, Val Loss=2.6987
Epoch [2/5]: Train Loss=4.7130, Val Loss=2.7005
Epoch [3/5]: Train Loss=3.8497, Val Loss=2.7009
Epoch [4/5]: Train Loss=3.2606, Val Loss=2.7023
Epoch [5/5]: Train Loss=2.9516, Val Loss=2.7030
BERT Test CPC Loss: 2.7026

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=393.8362, Val Loss=4.6806
Epoch [2/5]: Train Loss=29.1990, Val Loss=3.3871
Epoch [3/5]: Train Loss=20.2058, Val Loss=3.0300
Epoch [4/5]: Train Loss=15.6232, Val Loss=2.9395
Epoch [5/5]: Train Loss=12.8029, Val Loss=2.9342
GPT2 Test CPC Loss: 2.9699
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8544, Val Loss=1.2570
Epoch [2/5]: Train Loss=0.6729, Val Loss=0.5887
Epoch [3/5]: Train Loss=0.1545, Val Loss=0.1536
Epoch [4/5]: Train Loss=0.0272, Val Loss=0.0834
Epoch [5/5]: Train Loss=0.0077, Val Loss=0.0554
LSTM Test CPC Loss: 0.1010
[Model: Reservoir]
Epoch [1/5]: Train Loss=27.9338, Val Loss=16.5409
Epoch [2/5]: Train Loss=11.9134, Val Loss=9.9097
Epoch [3/5]: Train Loss=6.5697, Val Loss=6.4946
Epoch [4/5]: Train Loss=3.8649, Val Loss=4.5407
Epoch [5/5]: Train Loss=2.4140, Val Loss=3.3915
Reservoir Test CPC Loss: 3.2490
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9269, Val Loss=2.9886
Epoch [2/5]: Train Loss=4.7360, Val Loss=2.9891
Epoch [3/5]: Train Loss=3.9452, Val Loss=2.9898
Epoch [4/5]: Train Loss=3.4634, Val Loss=2.9903
Epoch [5/5]: Train Loss=3.2243, Val Loss=2.9912
BERT Test CPC Loss: 2.9910

========== Processing Fish 11 ==========
Fish 11: Neural data shape: (2798, 14015)

--- Fish 11: Run 1 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=448.4140, Val Loss=17.5241
Epoch [2/5]: Train Loss=32.8902, Val Loss=6.3686
Epoch [3/5]: Train Loss=19.1219, Val Loss=10.8581
Epoch [4/5]: Train Loss=12.9075, Val Loss=9.6990
Epoch [5/5]: Train Loss=9.8382, Val Loss=7.3049
GPT2 Test CPC Loss: 8.2289
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7024, Val Loss=0.1064
Epoch [2/5]: Train Loss=0.0188, Val Loss=0.0085
Epoch [3/5]: Train Loss=0.0036, Val Loss=0.0050
Epoch [4/5]: Train Loss=0.0038, Val Loss=0.0021
Epoch [5/5]: Train Loss=0.0020, Val Loss=0.0007
LSTM Test CPC Loss: 0.0016
[Model: Reservoir]
Epoch [1/5]: Train Loss=6.8486, Val Loss=2.4591
Epoch [2/5]: Train Loss=1.5452, Val Loss=1.3038
Epoch [3/5]: Train Loss=0.7524, Val Loss=0.8366
Epoch [4/5]: Train Loss=0.4280, Val Loss=0.6597
Epoch [5/5]: Train Loss=0.2548, Val Loss=0.5938
Reservoir Test CPC Loss: 0.9222
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7885, Val Loss=1.5104
Epoch [2/5]: Train Loss=4.8776, Val Loss=1.5278
Epoch [3/5]: Train Loss=3.8406, Val Loss=1.5425
Epoch [4/5]: Train Loss=3.0164, Val Loss=1.5290
Epoch [5/5]: Train Loss=2.3343, Val Loss=1.4939
BERT Test CPC Loss: 1.4972

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=385.3653, Val Loss=2.2918
Epoch [2/5]: Train Loss=29.4347, Val Loss=2.2075
Epoch [3/5]: Train Loss=19.4462, Val Loss=2.2011
Epoch [4/5]: Train Loss=14.1255, Val Loss=2.1948
Epoch [5/5]: Train Loss=11.0062, Val Loss=2.1961
GPT2 Test CPC Loss: 2.1905
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1183, Val Loss=0.2576
Epoch [2/5]: Train Loss=0.0727, Val Loss=0.0291
Epoch [3/5]: Train Loss=0.0076, Val Loss=0.0095
Epoch [4/5]: Train Loss=0.0038, Val Loss=0.0053
Epoch [5/5]: Train Loss=0.0035, Val Loss=0.0146
LSTM Test CPC Loss: 0.0266
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.2828, Val Loss=9.5441
Epoch [2/5]: Train Loss=7.0526, Val Loss=5.8599
Epoch [3/5]: Train Loss=4.2794, Val Loss=4.0562
Epoch [4/5]: Train Loss=2.7899, Val Loss=3.0190
Epoch [5/5]: Train Loss=1.9040, Val Loss=2.3875
Reservoir Test CPC Loss: 2.9483
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6297, Val Loss=2.2802
Epoch [2/5]: Train Loss=4.6859, Val Loss=2.2822
Epoch [3/5]: Train Loss=3.7486, Val Loss=2.2840
Epoch [4/5]: Train Loss=3.0376, Val Loss=2.2852
Epoch [5/5]: Train Loss=2.6082, Val Loss=2.2876
BERT Test CPC Loss: 2.2870

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=441.2807, Val Loss=2.5833
Epoch [2/5]: Train Loss=30.9024, Val Loss=2.6268
Epoch [3/5]: Train Loss=19.8176, Val Loss=2.6530
Epoch [4/5]: Train Loss=14.7689, Val Loss=2.6589
Epoch [5/5]: Train Loss=11.9298, Val Loss=2.6589
GPT2 Test CPC Loss: 2.6506
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4656, Val Loss=0.6286
Epoch [2/5]: Train Loss=0.2619, Val Loss=0.1414
Epoch [3/5]: Train Loss=0.0453, Val Loss=0.0265
Epoch [4/5]: Train Loss=0.0069, Val Loss=0.0177
Epoch [5/5]: Train Loss=0.0033, Val Loss=0.0117
LSTM Test CPC Loss: 0.0439
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.9354, Val Loss=12.0394
Epoch [2/5]: Train Loss=8.3324, Val Loss=6.5489
Epoch [3/5]: Train Loss=4.5020, Val Loss=4.0185
Epoch [4/5]: Train Loss=2.6979, Val Loss=2.7191
Epoch [5/5]: Train Loss=1.7493, Val Loss=2.0143
Reservoir Test CPC Loss: 2.5705
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7741, Val Loss=2.6967
Epoch [2/5]: Train Loss=4.7317, Val Loss=2.6973
Epoch [3/5]: Train Loss=3.8606, Val Loss=2.6978
Epoch [4/5]: Train Loss=3.3013, Val Loss=2.6978
Epoch [5/5]: Train Loss=3.0056, Val Loss=2.6986
BERT Test CPC Loss: 2.6981

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=518.6063, Val Loss=5.8335
Epoch [2/5]: Train Loss=26.5942, Val Loss=5.0875
Epoch [3/5]: Train Loss=18.5669, Val Loss=4.1615
Epoch [4/5]: Train Loss=14.4695, Val Loss=3.7114
Epoch [5/5]: Train Loss=12.2505, Val Loss=4.5107
GPT2 Test CPC Loss: 5.2805
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7595, Val Loss=1.0776
Epoch [2/5]: Train Loss=0.5601, Val Loss=0.3025
Epoch [3/5]: Train Loss=0.0949, Val Loss=0.0590
Epoch [4/5]: Train Loss=0.0147, Val Loss=0.0244
Epoch [5/5]: Train Loss=0.0044, Val Loss=0.0259
LSTM Test CPC Loss: 0.1332
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.9540, Val Loss=13.7800
Epoch [2/5]: Train Loss=9.0179, Val Loss=7.0272
Epoch [3/5]: Train Loss=4.6326, Val Loss=4.3436
Epoch [4/5]: Train Loss=2.7029, Val Loss=3.0238
Epoch [5/5]: Train Loss=1.7279, Val Loss=2.2700
Reservoir Test CPC Loss: 2.5838
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.1991, Val Loss=2.9912
Epoch [2/5]: Train Loss=4.6483, Val Loss=2.9914
Epoch [3/5]: Train Loss=3.8915, Val Loss=2.9918
Epoch [4/5]: Train Loss=3.4573, Val Loss=2.9921
Epoch [5/5]: Train Loss=3.2278, Val Loss=2.9921
BERT Test CPC Loss: 2.9920

--- Fish 11: Run 2 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=824.8351, Val Loss=9.0935
Epoch [2/5]: Train Loss=53.9070, Val Loss=2.0672
Epoch [3/5]: Train Loss=30.9146, Val Loss=1.4980
Epoch [4/5]: Train Loss=21.5418, Val Loss=1.4550
Epoch [5/5]: Train Loss=16.4076, Val Loss=1.4903
GPT2 Test CPC Loss: 1.4824
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6015, Val Loss=0.0101
Epoch [2/5]: Train Loss=0.0093, Val Loss=0.0012
Epoch [3/5]: Train Loss=0.0017, Val Loss=0.0003
Epoch [4/5]: Train Loss=0.0040, Val Loss=0.0071
Epoch [5/5]: Train Loss=0.0012, Val Loss=0.0020
LSTM Test CPC Loss: 0.0054
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.8542, Val Loss=2.8427
Epoch [2/5]: Train Loss=1.8886, Val Loss=1.2572
Epoch [3/5]: Train Loss=0.9052, Val Loss=0.8488
Epoch [4/5]: Train Loss=0.5197, Val Loss=0.6896
Epoch [5/5]: Train Loss=0.3280, Val Loss=0.5500
Reservoir Test CPC Loss: 1.0516
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6951, Val Loss=1.5326
Epoch [2/5]: Train Loss=4.8848, Val Loss=1.5476
Epoch [3/5]: Train Loss=3.8648, Val Loss=1.5567
Epoch [4/5]: Train Loss=3.1076, Val Loss=1.5446
Epoch [5/5]: Train Loss=2.4685, Val Loss=1.5105
BERT Test CPC Loss: 1.5156

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=519.1964, Val Loss=2.3443
Epoch [2/5]: Train Loss=23.4109, Val Loss=2.2232
Epoch [3/5]: Train Loss=16.2581, Val Loss=2.2382
Epoch [4/5]: Train Loss=12.9410, Val Loss=2.2744
Epoch [5/5]: Train Loss=10.9515, Val Loss=2.2360
GPT2 Test CPC Loss: 2.2347
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2014, Val Loss=0.3537
Epoch [2/5]: Train Loss=0.1214, Val Loss=0.0902
Epoch [3/5]: Train Loss=0.0151, Val Loss=0.0190
Epoch [4/5]: Train Loss=0.0058, Val Loss=0.0125
Epoch [5/5]: Train Loss=0.0050, Val Loss=0.0200
LSTM Test CPC Loss: 0.0459
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.1604, Val Loss=11.3674
Epoch [2/5]: Train Loss=7.4044, Val Loss=6.5051
Epoch [3/5]: Train Loss=4.1418, Val Loss=4.2334
Epoch [4/5]: Train Loss=2.5474, Val Loss=3.1572
Epoch [5/5]: Train Loss=1.6793, Val Loss=2.4935
Reservoir Test CPC Loss: 2.8408
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6653, Val Loss=2.2817
Epoch [2/5]: Train Loss=4.6898, Val Loss=2.2853
Epoch [3/5]: Train Loss=3.7505, Val Loss=2.2867
Epoch [4/5]: Train Loss=3.0457, Val Loss=2.2878
Epoch [5/5]: Train Loss=2.6410, Val Loss=2.2892
BERT Test CPC Loss: 2.2887

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=462.8688, Val Loss=2.7365
Epoch [2/5]: Train Loss=30.8995, Val Loss=2.5960
Epoch [3/5]: Train Loss=19.8804, Val Loss=2.6102
Epoch [4/5]: Train Loss=14.6451, Val Loss=2.6196
Epoch [5/5]: Train Loss=11.8967, Val Loss=2.6255
GPT2 Test CPC Loss: 2.6168
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5478, Val Loss=0.7874
Epoch [2/5]: Train Loss=0.3155, Val Loss=0.2027
Epoch [3/5]: Train Loss=0.0416, Val Loss=0.0289
Epoch [4/5]: Train Loss=0.0096, Val Loss=0.0100
Epoch [5/5]: Train Loss=0.0045, Val Loss=0.0052
LSTM Test CPC Loss: 0.0283
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.9851, Val Loss=12.6839
Epoch [2/5]: Train Loss=8.6040, Val Loss=7.2714
Epoch [3/5]: Train Loss=4.6411, Val Loss=4.7524
Epoch [4/5]: Train Loss=2.7887, Val Loss=3.2873
Epoch [5/5]: Train Loss=1.8101, Val Loss=2.4934
Reservoir Test CPC Loss: 2.8549
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7698, Val Loss=2.6987
Epoch [2/5]: Train Loss=4.6925, Val Loss=2.6995
Epoch [3/5]: Train Loss=3.8147, Val Loss=2.6998
Epoch [4/5]: Train Loss=3.1717, Val Loss=2.7008
Epoch [5/5]: Train Loss=2.8980, Val Loss=2.7021
BERT Test CPC Loss: 2.7018

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=618.5119, Val Loss=3.1978
Epoch [2/5]: Train Loss=34.0636, Val Loss=2.9186
Epoch [3/5]: Train Loss=20.0094, Val Loss=2.8883
Epoch [4/5]: Train Loss=14.4001, Val Loss=2.8848
Epoch [5/5]: Train Loss=11.4847, Val Loss=2.8966
GPT2 Test CPC Loss: 2.8724
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0557, Val Loss=1.2134
Epoch [2/5]: Train Loss=0.7436, Val Loss=0.4390
Epoch [3/5]: Train Loss=0.2092, Val Loss=0.1215
Epoch [4/5]: Train Loss=0.0311, Val Loss=0.0325
Epoch [5/5]: Train Loss=0.0093, Val Loss=0.0264
LSTM Test CPC Loss: 0.0827
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.9319, Val Loss=11.4341
Epoch [2/5]: Train Loss=9.3596, Val Loss=7.0762
Epoch [3/5]: Train Loss=5.5033, Val Loss=4.7429
Epoch [4/5]: Train Loss=3.4703, Val Loss=3.4430
Epoch [5/5]: Train Loss=2.3275, Val Loss=2.6198
Reservoir Test CPC Loss: 3.1585
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2249, Val Loss=2.9868
Epoch [2/5]: Train Loss=4.8305, Val Loss=2.9880
Epoch [3/5]: Train Loss=3.9941, Val Loss=2.9898
Epoch [4/5]: Train Loss=3.4265, Val Loss=2.9916
Epoch [5/5]: Train Loss=3.1744, Val Loss=2.9925
BERT Test CPC Loss: 2.9924

--- Fish 11: Run 3 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=361.9649, Val Loss=1.8166
Epoch [2/5]: Train Loss=28.6143, Val Loss=1.4717
Epoch [3/5]: Train Loss=18.3736, Val Loss=1.4581
Epoch [4/5]: Train Loss=12.9610, Val Loss=1.4275
Epoch [5/5]: Train Loss=10.1387, Val Loss=1.4224
GPT2 Test CPC Loss: 1.4247
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6183, Val Loss=0.0824
Epoch [2/5]: Train Loss=0.0217, Val Loss=0.0080
Epoch [3/5]: Train Loss=0.0146, Val Loss=0.0032
Epoch [4/5]: Train Loss=0.0019, Val Loss=0.0011
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0009
LSTM Test CPC Loss: 0.0008
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.4622, Val Loss=3.3084
Epoch [2/5]: Train Loss=1.5190, Val Loss=1.9309
Epoch [3/5]: Train Loss=0.7236, Val Loss=1.4490
Epoch [4/5]: Train Loss=0.4417, Val Loss=1.1877
Epoch [5/5]: Train Loss=0.2585, Val Loss=1.0662
Reservoir Test CPC Loss: 1.1274
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8657, Val Loss=1.4968
Epoch [2/5]: Train Loss=4.9155, Val Loss=1.5130
Epoch [3/5]: Train Loss=3.9332, Val Loss=1.5564
Epoch [4/5]: Train Loss=3.2551, Val Loss=1.5484
Epoch [5/5]: Train Loss=2.6832, Val Loss=1.5052
BERT Test CPC Loss: 1.5133

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=454.7435, Val Loss=12.8210
Epoch [2/5]: Train Loss=29.8745, Val Loss=8.0155
Epoch [3/5]: Train Loss=21.7300, Val Loss=4.1852
Epoch [4/5]: Train Loss=16.0593, Val Loss=3.5320
Epoch [5/5]: Train Loss=13.1614, Val Loss=2.7369
GPT2 Test CPC Loss: 3.6774
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2867, Val Loss=0.4837
Epoch [2/5]: Train Loss=0.1839, Val Loss=0.1413
Epoch [3/5]: Train Loss=0.0212, Val Loss=0.0260
Epoch [4/5]: Train Loss=0.0074, Val Loss=0.0167
Epoch [5/5]: Train Loss=0.0087, Val Loss=0.0134
LSTM Test CPC Loss: 0.0214
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.6551, Val Loss=8.7480
Epoch [2/5]: Train Loss=6.7265, Val Loss=5.2396
Epoch [3/5]: Train Loss=3.9122, Val Loss=3.6475
Epoch [4/5]: Train Loss=2.4938, Val Loss=2.7214
Epoch [5/5]: Train Loss=1.6853, Val Loss=2.0847
Reservoir Test CPC Loss: 2.6308
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4266, Val Loss=2.2798
Epoch [2/5]: Train Loss=4.6480, Val Loss=2.2813
Epoch [3/5]: Train Loss=3.6795, Val Loss=2.2822
Epoch [4/5]: Train Loss=2.9759, Val Loss=2.2832
Epoch [5/5]: Train Loss=2.6214, Val Loss=2.2856
BERT Test CPC Loss: 2.2852

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=329.6567, Val Loss=2.8094
Epoch [2/5]: Train Loss=19.9035, Val Loss=2.9342
Epoch [3/5]: Train Loss=14.6533, Val Loss=2.8576
Epoch [4/5]: Train Loss=11.7408, Val Loss=2.7897
Epoch [5/5]: Train Loss=9.9064, Val Loss=2.7728
GPT2 Test CPC Loss: 2.7614
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6056, Val Loss=0.8826
Epoch [2/5]: Train Loss=0.3561, Val Loss=0.1187
Epoch [3/5]: Train Loss=0.0417, Val Loss=0.0416
Epoch [4/5]: Train Loss=0.0084, Val Loss=0.0143
Epoch [5/5]: Train Loss=0.0052, Val Loss=0.0097
LSTM Test CPC Loss: 0.0670
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.8179, Val Loss=11.7914
Epoch [2/5]: Train Loss=8.0783, Val Loss=6.5371
Epoch [3/5]: Train Loss=4.1339, Val Loss=4.1797
Epoch [4/5]: Train Loss=2.3999, Val Loss=3.0015
Epoch [5/5]: Train Loss=1.5214, Val Loss=2.2847
Reservoir Test CPC Loss: 2.3089
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7955, Val Loss=2.7015
Epoch [2/5]: Train Loss=4.7121, Val Loss=2.7023
Epoch [3/5]: Train Loss=3.8614, Val Loss=2.7028
Epoch [4/5]: Train Loss=3.3169, Val Loss=2.7036
Epoch [5/5]: Train Loss=2.9949, Val Loss=2.7039
BERT Test CPC Loss: 2.7037

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=309.5782, Val Loss=2.9694
Epoch [2/5]: Train Loss=16.5628, Val Loss=2.9282
Epoch [3/5]: Train Loss=12.3071, Val Loss=2.9275
Epoch [4/5]: Train Loss=9.8755, Val Loss=2.9307
Epoch [5/5]: Train Loss=8.3819, Val Loss=2.9355
GPT2 Test CPC Loss: 2.9184
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9750, Val Loss=1.1689
Epoch [2/5]: Train Loss=0.6669, Val Loss=0.3243
Epoch [3/5]: Train Loss=0.1172, Val Loss=0.0701
Epoch [4/5]: Train Loss=0.0150, Val Loss=0.0323
Epoch [5/5]: Train Loss=0.0044, Val Loss=0.0164
LSTM Test CPC Loss: 0.0433
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.7676, Val Loss=12.0806
Epoch [2/5]: Train Loss=8.4291, Val Loss=6.6627
Epoch [3/5]: Train Loss=4.4678, Val Loss=4.1189
Epoch [4/5]: Train Loss=2.6277, Val Loss=2.9206
Epoch [5/5]: Train Loss=1.6786, Val Loss=2.1548
Reservoir Test CPC Loss: 2.4385
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4708, Val Loss=2.9904
Epoch [2/5]: Train Loss=4.6914, Val Loss=2.9913
Epoch [3/5]: Train Loss=3.8930, Val Loss=2.9922
Epoch [4/5]: Train Loss=3.4029, Val Loss=2.9924
Epoch [5/5]: Train Loss=3.1776, Val Loss=2.9926
BERT Test CPC Loss: 2.9926

--- Fish 11: Run 4 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=433.6901, Val Loss=1.7121
Epoch [2/5]: Train Loss=28.2804, Val Loss=1.6965
Epoch [3/5]: Train Loss=18.8849, Val Loss=1.7240
Epoch [4/5]: Train Loss=14.6792, Val Loss=1.7227
Epoch [5/5]: Train Loss=11.8486, Val Loss=1.7067
GPT2 Test CPC Loss: 1.7331
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7173, Val Loss=0.1319
Epoch [2/5]: Train Loss=0.0186, Val Loss=0.0067
Epoch [3/5]: Train Loss=0.0065, Val Loss=0.0059
Epoch [4/5]: Train Loss=0.0023, Val Loss=0.0009
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0006
LSTM Test CPC Loss: 0.0007
[Model: Reservoir]
Epoch [1/5]: Train Loss=6.0528, Val Loss=2.7105
Epoch [2/5]: Train Loss=1.3392, Val Loss=1.5521
Epoch [3/5]: Train Loss=0.6402, Val Loss=1.1407
Epoch [4/5]: Train Loss=0.3455, Val Loss=0.9320
Epoch [5/5]: Train Loss=0.1962, Val Loss=0.7933
Reservoir Test CPC Loss: 0.8862
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9606, Val Loss=1.5009
Epoch [2/5]: Train Loss=4.9915, Val Loss=1.5217
Epoch [3/5]: Train Loss=3.9784, Val Loss=1.5445
Epoch [4/5]: Train Loss=3.2291, Val Loss=1.5503
Epoch [5/5]: Train Loss=2.6187, Val Loss=1.5027
BERT Test CPC Loss: 1.5092

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=499.3311, Val Loss=2.7099
Epoch [2/5]: Train Loss=25.7074, Val Loss=2.3444
Epoch [3/5]: Train Loss=18.7883, Val Loss=2.3181
Epoch [4/5]: Train Loss=14.9987, Val Loss=2.2948
Epoch [5/5]: Train Loss=12.6652, Val Loss=2.2742
GPT2 Test CPC Loss: 2.2876
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2912, Val Loss=0.3960
Epoch [2/5]: Train Loss=0.1601, Val Loss=0.0492
Epoch [3/5]: Train Loss=0.0130, Val Loss=0.0206
Epoch [4/5]: Train Loss=0.0034, Val Loss=0.0120
Epoch [5/5]: Train Loss=0.0043, Val Loss=0.0121
LSTM Test CPC Loss: 0.0515
[Model: Reservoir]
Epoch [1/5]: Train Loss=14.6863, Val Loss=8.2670
Epoch [2/5]: Train Loss=5.8984, Val Loss=5.0053
Epoch [3/5]: Train Loss=3.3876, Val Loss=3.4179
Epoch [4/5]: Train Loss=2.1207, Val Loss=2.5600
Epoch [5/5]: Train Loss=1.4099, Val Loss=1.9840
Reservoir Test CPC Loss: 2.3363
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6448, Val Loss=2.2791
Epoch [2/5]: Train Loss=4.7177, Val Loss=2.2803
Epoch [3/5]: Train Loss=3.7533, Val Loss=2.2827
Epoch [4/5]: Train Loss=3.0273, Val Loss=2.2837
Epoch [5/5]: Train Loss=2.6158, Val Loss=2.2859
BERT Test CPC Loss: 2.2852

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=505.0214, Val Loss=2.6214
Epoch [2/5]: Train Loss=22.4939, Val Loss=2.6397
Epoch [3/5]: Train Loss=16.2372, Val Loss=2.6578
Epoch [4/5]: Train Loss=13.0342, Val Loss=2.6557
Epoch [5/5]: Train Loss=11.1277, Val Loss=2.6528
GPT2 Test CPC Loss: 2.6486
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5186, Val Loss=0.6650
Epoch [2/5]: Train Loss=0.2671, Val Loss=0.1066
Epoch [3/5]: Train Loss=0.0292, Val Loss=0.0247
Epoch [4/5]: Train Loss=0.0080, Val Loss=0.0120
Epoch [5/5]: Train Loss=0.0048, Val Loss=0.0140
LSTM Test CPC Loss: 0.0762
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.0953, Val Loss=11.9830
Epoch [2/5]: Train Loss=8.2537, Val Loss=6.6980
Epoch [3/5]: Train Loss=4.6833, Val Loss=4.3588
Epoch [4/5]: Train Loss=2.9248, Val Loss=3.0761
Epoch [5/5]: Train Loss=1.9588, Val Loss=2.2679
Reservoir Test CPC Loss: 2.7241
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5281, Val Loss=2.6973
Epoch [2/5]: Train Loss=4.6900, Val Loss=2.6980
Epoch [3/5]: Train Loss=3.8513, Val Loss=2.6991
Epoch [4/5]: Train Loss=3.3404, Val Loss=2.6997
Epoch [5/5]: Train Loss=3.0458, Val Loss=2.7007
BERT Test CPC Loss: 2.7004

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=610.0727, Val Loss=3.1781
Epoch [2/5]: Train Loss=40.1964, Val Loss=2.9378
Epoch [3/5]: Train Loss=25.3687, Val Loss=2.8872
Epoch [4/5]: Train Loss=19.0324, Val Loss=2.8900
Epoch [5/5]: Train Loss=15.0653, Val Loss=2.9044
GPT2 Test CPC Loss: 2.8844
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7809, Val Loss=0.9096
Epoch [2/5]: Train Loss=0.4085, Val Loss=0.1902
Epoch [3/5]: Train Loss=0.0433, Val Loss=0.0530
Epoch [4/5]: Train Loss=0.0091, Val Loss=0.0211
Epoch [5/5]: Train Loss=0.0037, Val Loss=0.0173
LSTM Test CPC Loss: 0.0911
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.8454, Val Loss=11.9794
Epoch [2/5]: Train Loss=8.9076, Val Loss=6.7244
Epoch [3/5]: Train Loss=4.8778, Val Loss=4.2163
Epoch [4/5]: Train Loss=2.9182, Val Loss=2.9756
Epoch [5/5]: Train Loss=1.8802, Val Loss=2.2125
Reservoir Test CPC Loss: 2.9447
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0166, Val Loss=2.9886
Epoch [2/5]: Train Loss=4.7486, Val Loss=2.9897
Epoch [3/5]: Train Loss=3.9445, Val Loss=2.9908
Epoch [4/5]: Train Loss=3.4414, Val Loss=2.9917
Epoch [5/5]: Train Loss=3.1923, Val Loss=2.9924
BERT Test CPC Loss: 2.9923

--- Fish 11: Run 5 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=502.6796, Val Loss=2.6793
Epoch [2/5]: Train Loss=43.1695, Val Loss=1.5859
Epoch [3/5]: Train Loss=29.1706, Val Loss=1.4075
Epoch [4/5]: Train Loss=20.9188, Val Loss=1.4010
Epoch [5/5]: Train Loss=17.1824, Val Loss=1.4176
GPT2 Test CPC Loss: 1.4131
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7148, Val Loss=0.0714
Epoch [2/5]: Train Loss=0.0134, Val Loss=0.0117
Epoch [3/5]: Train Loss=0.0016, Val Loss=0.0007
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0005
Epoch [5/5]: Train Loss=0.0086, Val Loss=0.0145
LSTM Test CPC Loss: 0.0153
[Model: Reservoir]
Epoch [1/5]: Train Loss=5.9656, Val Loss=2.5271
Epoch [2/5]: Train Loss=1.3140, Val Loss=1.4347
Epoch [3/5]: Train Loss=0.6858, Val Loss=1.0994
Epoch [4/5]: Train Loss=0.4034, Val Loss=0.8580
Epoch [5/5]: Train Loss=0.2498, Val Loss=0.7147
Reservoir Test CPC Loss: 1.0430
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0497, Val Loss=1.5012
Epoch [2/5]: Train Loss=4.9224, Val Loss=1.5182
Epoch [3/5]: Train Loss=3.9584, Val Loss=1.5247
Epoch [4/5]: Train Loss=3.3004, Val Loss=1.5368
Epoch [5/5]: Train Loss=2.7392, Val Loss=1.5157
BERT Test CPC Loss: 1.5242

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=343.8321, Val Loss=2.7692
Epoch [2/5]: Train Loss=25.3009, Val Loss=2.3076
Epoch [3/5]: Train Loss=18.8751, Val Loss=2.2564
Epoch [4/5]: Train Loss=15.0316, Val Loss=2.2820
Epoch [5/5]: Train Loss=12.6739, Val Loss=2.2345
GPT2 Test CPC Loss: 2.2444
[Model: LSTM]
Epoch [1/5]: Train Loss=1.0612, Val Loss=0.2636
Epoch [2/5]: Train Loss=0.0738, Val Loss=0.0364
Epoch [3/5]: Train Loss=0.0118, Val Loss=0.0134
Epoch [4/5]: Train Loss=0.0253, Val Loss=0.0267
Epoch [5/5]: Train Loss=0.0049, Val Loss=0.0045
LSTM Test CPC Loss: 0.0067
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.9641, Val Loss=8.8797
Epoch [2/5]: Train Loss=6.4512, Val Loss=5.2501
Epoch [3/5]: Train Loss=3.6810, Val Loss=3.6572
Epoch [4/5]: Train Loss=2.3342, Val Loss=2.6876
Epoch [5/5]: Train Loss=1.5757, Val Loss=2.1051
Reservoir Test CPC Loss: 2.3188
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7795, Val Loss=2.2767
Epoch [2/5]: Train Loss=4.7338, Val Loss=2.2750
Epoch [3/5]: Train Loss=3.7341, Val Loss=2.2764
Epoch [4/5]: Train Loss=2.9903, Val Loss=2.2775
Epoch [5/5]: Train Loss=2.5975, Val Loss=2.2812
BERT Test CPC Loss: 2.2804

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=493.1782, Val Loss=7.0325
Epoch [2/5]: Train Loss=43.5938, Val Loss=4.2984
Epoch [3/5]: Train Loss=28.3816, Val Loss=2.9967
Epoch [4/5]: Train Loss=20.6370, Val Loss=2.7612
Epoch [5/5]: Train Loss=16.5891, Val Loss=2.6578
GPT2 Test CPC Loss: 2.6515
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7106, Val Loss=0.8672
Epoch [2/5]: Train Loss=0.3853, Val Loss=0.2013
Epoch [3/5]: Train Loss=0.0453, Val Loss=0.0527
Epoch [4/5]: Train Loss=0.0086, Val Loss=0.0321
Epoch [5/5]: Train Loss=0.0084, Val Loss=0.0233
LSTM Test CPC Loss: 0.0400
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.7636, Val Loss=11.5214
Epoch [2/5]: Train Loss=8.3763, Val Loss=6.6806
Epoch [3/5]: Train Loss=4.6848, Val Loss=4.4881
Epoch [4/5]: Train Loss=2.8989, Val Loss=3.2678
Epoch [5/5]: Train Loss=1.9162, Val Loss=2.4694
Reservoir Test CPC Loss: 2.4492
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1516, Val Loss=2.6979
Epoch [2/5]: Train Loss=4.7859, Val Loss=2.6975
Epoch [3/5]: Train Loss=3.9171, Val Loss=2.6989
Epoch [4/5]: Train Loss=3.3262, Val Loss=2.7001
Epoch [5/5]: Train Loss=2.9768, Val Loss=2.7016
BERT Test CPC Loss: 2.7013

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=410.5272, Val Loss=3.0629
Epoch [2/5]: Train Loss=20.4397, Val Loss=2.9705
Epoch [3/5]: Train Loss=15.2977, Val Loss=2.9605
Epoch [4/5]: Train Loss=12.4833, Val Loss=2.9361
Epoch [5/5]: Train Loss=10.5789, Val Loss=2.9456
GPT2 Test CPC Loss: 2.9387
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7998, Val Loss=1.0537
Epoch [2/5]: Train Loss=0.5846, Val Loss=0.3397
Epoch [3/5]: Train Loss=0.1032, Val Loss=0.1120
Epoch [4/5]: Train Loss=0.0166, Val Loss=0.0467
Epoch [5/5]: Train Loss=0.0060, Val Loss=0.0194
LSTM Test CPC Loss: 0.0704
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.6553, Val Loss=14.1393
Epoch [2/5]: Train Loss=10.0482, Val Loss=7.6950
Epoch [3/5]: Train Loss=5.2863, Val Loss=4.8462
Epoch [4/5]: Train Loss=3.1021, Val Loss=3.2871
Epoch [5/5]: Train Loss=1.9771, Val Loss=2.4456
Reservoir Test CPC Loss: 2.9608
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4652, Val Loss=2.9884
Epoch [2/5]: Train Loss=4.7143, Val Loss=2.9893
Epoch [3/5]: Train Loss=3.9343, Val Loss=2.9908
Epoch [4/5]: Train Loss=3.4675, Val Loss=2.9913
Epoch [5/5]: Train Loss=3.2191, Val Loss=2.9917
BERT Test CPC Loss: 2.9916

--- Fish 11: Run 6 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=304.4408, Val Loss=1.6670
Epoch [2/5]: Train Loss=18.8268, Val Loss=1.4675
Epoch [3/5]: Train Loss=11.5522, Val Loss=1.4297
Epoch [4/5]: Train Loss=8.5922, Val Loss=1.4098
Epoch [5/5]: Train Loss=6.8005, Val Loss=1.4024
GPT2 Test CPC Loss: 1.4030
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6587, Val Loss=0.0481
Epoch [2/5]: Train Loss=0.0107, Val Loss=0.0031
Epoch [3/5]: Train Loss=0.0014, Val Loss=0.0018
Epoch [4/5]: Train Loss=0.0044, Val Loss=0.0052
Epoch [5/5]: Train Loss=0.0040, Val Loss=0.0127
LSTM Test CPC Loss: 0.0253
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.9579, Val Loss=3.2079
Epoch [2/5]: Train Loss=1.9563, Val Loss=1.8892
Epoch [3/5]: Train Loss=1.0402, Val Loss=1.3883
Epoch [4/5]: Train Loss=0.6194, Val Loss=1.0961
Epoch [5/5]: Train Loss=0.4259, Val Loss=0.9605
Reservoir Test CPC Loss: 1.1979
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7081, Val Loss=1.5108
Epoch [2/5]: Train Loss=4.8349, Val Loss=1.5460
Epoch [3/5]: Train Loss=3.8412, Val Loss=1.5940
Epoch [4/5]: Train Loss=3.1342, Val Loss=1.5746
Epoch [5/5]: Train Loss=2.5971, Val Loss=1.5217
BERT Test CPC Loss: 1.5317

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=390.8474, Val Loss=4.4187
Epoch [2/5]: Train Loss=30.5944, Val Loss=2.3964
Epoch [3/5]: Train Loss=19.0383, Val Loss=2.2692
Epoch [4/5]: Train Loss=13.8197, Val Loss=2.2204
Epoch [5/5]: Train Loss=10.7680, Val Loss=2.2014
GPT2 Test CPC Loss: 2.1977
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2838, Val Loss=0.4980
Epoch [2/5]: Train Loss=0.1403, Val Loss=0.0614
Epoch [3/5]: Train Loss=0.0139, Val Loss=0.0356
Epoch [4/5]: Train Loss=0.0053, Val Loss=0.0063
Epoch [5/5]: Train Loss=0.0040, Val Loss=0.0058
LSTM Test CPC Loss: 0.0225
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.2452, Val Loss=9.8683
Epoch [2/5]: Train Loss=6.2967, Val Loss=5.8910
Epoch [3/5]: Train Loss=3.5758, Val Loss=3.9617
Epoch [4/5]: Train Loss=2.2188, Val Loss=2.9727
Epoch [5/5]: Train Loss=1.4655, Val Loss=2.3690
Reservoir Test CPC Loss: 2.6053
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9670, Val Loss=2.2867
Epoch [2/5]: Train Loss=4.7586, Val Loss=2.2882
Epoch [3/5]: Train Loss=3.8062, Val Loss=2.2880
Epoch [4/5]: Train Loss=3.0931, Val Loss=2.2894
Epoch [5/5]: Train Loss=2.6713, Val Loss=2.2905
BERT Test CPC Loss: 2.2901

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=376.7844, Val Loss=2.8349
Epoch [2/5]: Train Loss=23.7768, Val Loss=2.6607
Epoch [3/5]: Train Loss=17.0878, Val Loss=2.6564
Epoch [4/5]: Train Loss=13.6610, Val Loss=2.6570
Epoch [5/5]: Train Loss=11.4667, Val Loss=2.6624
GPT2 Test CPC Loss: 2.6641
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4579, Val Loss=0.6735
Epoch [2/5]: Train Loss=0.3124, Val Loss=0.1969
Epoch [3/5]: Train Loss=0.0451, Val Loss=0.0575
Epoch [4/5]: Train Loss=0.0107, Val Loss=0.0386
Epoch [5/5]: Train Loss=0.0062, Val Loss=0.0301
LSTM Test CPC Loss: 0.0872
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.5652, Val Loss=11.3560
Epoch [2/5]: Train Loss=7.9881, Val Loss=6.5027
Epoch [3/5]: Train Loss=4.4447, Val Loss=4.1894
Epoch [4/5]: Train Loss=2.7377, Val Loss=2.9652
Epoch [5/5]: Train Loss=1.8098, Val Loss=2.2536
Reservoir Test CPC Loss: 2.6880
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6348, Val Loss=2.6949
Epoch [2/5]: Train Loss=4.7425, Val Loss=2.6969
Epoch [3/5]: Train Loss=3.8783, Val Loss=2.6988
Epoch [4/5]: Train Loss=3.3096, Val Loss=2.7004
Epoch [5/5]: Train Loss=2.9857, Val Loss=2.7018
BERT Test CPC Loss: 2.7016

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=487.0512, Val Loss=2.8942
Epoch [2/5]: Train Loss=26.5590, Val Loss=2.9097
Epoch [3/5]: Train Loss=16.9811, Val Loss=2.9071
Epoch [4/5]: Train Loss=12.7834, Val Loss=2.9193
Epoch [5/5]: Train Loss=10.2887, Val Loss=2.9271
GPT2 Test CPC Loss: 2.9139
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0018, Val Loss=1.2422
Epoch [2/5]: Train Loss=0.7006, Val Loss=0.3928
Epoch [3/5]: Train Loss=0.1418, Val Loss=0.0624
Epoch [4/5]: Train Loss=0.0181, Val Loss=0.0216
Epoch [5/5]: Train Loss=0.0046, Val Loss=0.0138
LSTM Test CPC Loss: 0.0406
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.6959, Val Loss=13.8943
Epoch [2/5]: Train Loss=9.7215, Val Loss=7.9590
Epoch [3/5]: Train Loss=5.4252, Val Loss=5.0927
Epoch [4/5]: Train Loss=3.2858, Val Loss=3.5301
Epoch [5/5]: Train Loss=2.1257, Val Loss=2.6568
Reservoir Test CPC Loss: 2.9912
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1059, Val Loss=2.9896
Epoch [2/5]: Train Loss=4.7910, Val Loss=2.9911
Epoch [3/5]: Train Loss=3.9658, Val Loss=2.9921
Epoch [4/5]: Train Loss=3.4234, Val Loss=2.9930
Epoch [5/5]: Train Loss=3.1765, Val Loss=2.9934
BERT Test CPC Loss: 2.9933

--- Fish 11: Run 7 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=343.7381, Val Loss=2.2010
Epoch [2/5]: Train Loss=25.6755, Val Loss=1.5701
Epoch [3/5]: Train Loss=18.1460, Val Loss=1.5110
Epoch [4/5]: Train Loss=14.2940, Val Loss=1.4914
Epoch [5/5]: Train Loss=11.5999, Val Loss=1.4903
GPT2 Test CPC Loss: 1.4986
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5864, Val Loss=0.0447
Epoch [2/5]: Train Loss=0.0145, Val Loss=0.0043
Epoch [3/5]: Train Loss=0.0018, Val Loss=0.0049
Epoch [4/5]: Train Loss=0.0039, Val Loss=0.0023
Epoch [5/5]: Train Loss=0.0028, Val Loss=0.0003
LSTM Test CPC Loss: 0.0021
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.7364, Val Loss=2.2764
Epoch [2/5]: Train Loss=1.2702, Val Loss=1.3083
Epoch [3/5]: Train Loss=0.6067, Val Loss=0.9692
Epoch [4/5]: Train Loss=0.3351, Val Loss=0.7613
Epoch [5/5]: Train Loss=0.1963, Val Loss=0.6683
Reservoir Test CPC Loss: 0.9077
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7689, Val Loss=1.5445
Epoch [2/5]: Train Loss=4.8982, Val Loss=1.6076
Epoch [3/5]: Train Loss=3.8624, Val Loss=1.6502
Epoch [4/5]: Train Loss=3.1721, Val Loss=1.5820
Epoch [5/5]: Train Loss=2.6109, Val Loss=1.5282
BERT Test CPC Loss: 1.5395

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=372.7078, Val Loss=2.4888
Epoch [2/5]: Train Loss=30.0173, Val Loss=2.2511
Epoch [3/5]: Train Loss=19.4589, Val Loss=2.2234
Epoch [4/5]: Train Loss=14.8626, Val Loss=2.2148
Epoch [5/5]: Train Loss=11.5732, Val Loss=2.2103
GPT2 Test CPC Loss: 2.2054
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2791, Val Loss=0.4438
Epoch [2/5]: Train Loss=0.1359, Val Loss=0.0505
Epoch [3/5]: Train Loss=0.0134, Val Loss=0.0253
Epoch [4/5]: Train Loss=0.0055, Val Loss=0.0067
Epoch [5/5]: Train Loss=0.0055, Val Loss=0.0087
LSTM Test CPC Loss: 0.0264
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.7963, Val Loss=9.8221
Epoch [2/5]: Train Loss=6.3310, Val Loss=5.7920
Epoch [3/5]: Train Loss=3.4597, Val Loss=3.9730
Epoch [4/5]: Train Loss=2.1172, Val Loss=2.9693
Epoch [5/5]: Train Loss=1.3960, Val Loss=2.3680
Reservoir Test CPC Loss: 2.3294
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0840, Val Loss=2.2866
Epoch [2/5]: Train Loss=4.8100, Val Loss=2.2863
Epoch [3/5]: Train Loss=3.8827, Val Loss=2.2875
Epoch [4/5]: Train Loss=3.2014, Val Loss=2.2881
Epoch [5/5]: Train Loss=2.7619, Val Loss=2.2892
BERT Test CPC Loss: 2.2887

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=555.8995, Val Loss=2.9870
Epoch [2/5]: Train Loss=39.8471, Val Loss=2.5973
Epoch [3/5]: Train Loss=26.4441, Val Loss=2.5993
Epoch [4/5]: Train Loss=20.0401, Val Loss=2.6058
Epoch [5/5]: Train Loss=16.2271, Val Loss=2.6168
GPT2 Test CPC Loss: 2.6037
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6718, Val Loss=0.9243
Epoch [2/5]: Train Loss=0.3294, Val Loss=0.2195
Epoch [3/5]: Train Loss=0.0402, Val Loss=0.0638
Epoch [4/5]: Train Loss=0.0078, Val Loss=0.0363
Epoch [5/5]: Train Loss=0.0043, Val Loss=0.0270
LSTM Test CPC Loss: 0.0449
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.5803, Val Loss=10.4754
Epoch [2/5]: Train Loss=7.5178, Val Loss=6.0228
Epoch [3/5]: Train Loss=4.3614, Val Loss=3.9791
Epoch [4/5]: Train Loss=2.7648, Val Loss=2.7943
Epoch [5/5]: Train Loss=1.8560, Val Loss=2.1387
Reservoir Test CPC Loss: 2.7372
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0724, Val Loss=2.6952
Epoch [2/5]: Train Loss=4.7708, Val Loss=2.6967
Epoch [3/5]: Train Loss=3.9424, Val Loss=2.6984
Epoch [4/5]: Train Loss=3.3935, Val Loss=2.6985
Epoch [5/5]: Train Loss=3.0671, Val Loss=2.6990
BERT Test CPC Loss: 2.6987

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=446.0054, Val Loss=4.7461
Epoch [2/5]: Train Loss=23.4194, Val Loss=3.8987
Epoch [3/5]: Train Loss=16.7590, Val Loss=3.1759
Epoch [4/5]: Train Loss=13.2653, Val Loss=2.9763
Epoch [5/5]: Train Loss=11.0111, Val Loss=2.9422
GPT2 Test CPC Loss: 2.9282
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9990, Val Loss=1.2782
Epoch [2/5]: Train Loss=0.8206, Val Loss=0.6951
Epoch [3/5]: Train Loss=0.2258, Val Loss=0.1355
Epoch [4/5]: Train Loss=0.0353, Val Loss=0.0467
Epoch [5/5]: Train Loss=0.0099, Val Loss=0.0277
LSTM Test CPC Loss: 0.0853
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.9719, Val Loss=12.4641
Epoch [2/5]: Train Loss=9.3411, Val Loss=7.0325
Epoch [3/5]: Train Loss=5.3199, Val Loss=4.4862
Epoch [4/5]: Train Loss=3.2767, Val Loss=3.1074
Epoch [5/5]: Train Loss=2.1360, Val Loss=2.3105
Reservoir Test CPC Loss: 3.0901
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5762, Val Loss=2.9886
Epoch [2/5]: Train Loss=4.7681, Val Loss=2.9887
Epoch [3/5]: Train Loss=3.9932, Val Loss=2.9894
Epoch [4/5]: Train Loss=3.5067, Val Loss=2.9901
Epoch [5/5]: Train Loss=3.2413, Val Loss=2.9912
BERT Test CPC Loss: 2.9910

--- Fish 11: Run 8 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=435.4201, Val Loss=1.5045
Epoch [2/5]: Train Loss=31.4886, Val Loss=1.5449
Epoch [3/5]: Train Loss=22.3489, Val Loss=1.5675
Epoch [4/5]: Train Loss=17.2110, Val Loss=1.5835
Epoch [5/5]: Train Loss=13.9880, Val Loss=1.6107
GPT2 Test CPC Loss: 1.6166
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6083, Val Loss=0.1583
Epoch [2/5]: Train Loss=0.0158, Val Loss=0.0030
Epoch [3/5]: Train Loss=0.0061, Val Loss=0.0109
Epoch [4/5]: Train Loss=0.0027, Val Loss=0.0012
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0006
LSTM Test CPC Loss: 0.0008
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.5271, Val Loss=2.1495
Epoch [2/5]: Train Loss=1.6543, Val Loss=1.0884
Epoch [3/5]: Train Loss=0.8685, Val Loss=0.7497
Epoch [4/5]: Train Loss=0.5022, Val Loss=0.6376
Epoch [5/5]: Train Loss=0.3119, Val Loss=0.5686
Reservoir Test CPC Loss: 1.0258
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1070, Val Loss=1.5076
Epoch [2/5]: Train Loss=4.9787, Val Loss=1.5000
Epoch [3/5]: Train Loss=3.9996, Val Loss=1.5059
Epoch [4/5]: Train Loss=3.2240, Val Loss=1.5011
Epoch [5/5]: Train Loss=2.5684, Val Loss=1.4913
BERT Test CPC Loss: 1.4951

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=567.0127, Val Loss=3.6585
Epoch [2/5]: Train Loss=46.1466, Val Loss=2.2795
Epoch [3/5]: Train Loss=30.6743, Val Loss=2.3411
Epoch [4/5]: Train Loss=22.6709, Val Loss=2.2968
Epoch [5/5]: Train Loss=18.2914, Val Loss=2.2731
GPT2 Test CPC Loss: 2.2654
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3186, Val Loss=0.4773
Epoch [2/5]: Train Loss=0.1724, Val Loss=0.0497
Epoch [3/5]: Train Loss=0.0163, Val Loss=0.0081
Epoch [4/5]: Train Loss=0.0048, Val Loss=0.0080
Epoch [5/5]: Train Loss=0.0062, Val Loss=0.0159
LSTM Test CPC Loss: 0.0420
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.3405, Val Loss=10.8887
Epoch [2/5]: Train Loss=7.0070, Val Loss=6.4688
Epoch [3/5]: Train Loss=3.9335, Val Loss=4.4726
Epoch [4/5]: Train Loss=2.4282, Val Loss=3.3854
Epoch [5/5]: Train Loss=1.5967, Val Loss=2.6541
Reservoir Test CPC Loss: 3.1919
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8356, Val Loss=2.2812
Epoch [2/5]: Train Loss=4.7654, Val Loss=2.2812
Epoch [3/5]: Train Loss=3.8401, Val Loss=2.2833
Epoch [4/5]: Train Loss=3.1477, Val Loss=2.2834
Epoch [5/5]: Train Loss=2.7068, Val Loss=2.2846
BERT Test CPC Loss: 2.2839

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=382.4757, Val Loss=4.0502
Epoch [2/5]: Train Loss=35.4730, Val Loss=2.8396
Epoch [3/5]: Train Loss=22.7067, Val Loss=2.7353
Epoch [4/5]: Train Loss=16.8663, Val Loss=2.6917
Epoch [5/5]: Train Loss=13.5827, Val Loss=2.6664
GPT2 Test CPC Loss: 2.6591
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4344, Val Loss=0.6978
Epoch [2/5]: Train Loss=0.3039, Val Loss=0.1536
Epoch [3/5]: Train Loss=0.0374, Val Loss=0.0645
Epoch [4/5]: Train Loss=0.0075, Val Loss=0.0272
Epoch [5/5]: Train Loss=0.0042, Val Loss=0.0290
LSTM Test CPC Loss: 0.0430
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.9598, Val Loss=12.6429
Epoch [2/5]: Train Loss=9.0525, Val Loss=6.9684
Epoch [3/5]: Train Loss=4.9566, Val Loss=4.4435
Epoch [4/5]: Train Loss=2.9874, Val Loss=3.0498
Epoch [5/5]: Train Loss=1.9459, Val Loss=2.2834
Reservoir Test CPC Loss: 2.5977
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6860, Val Loss=2.6986
Epoch [2/5]: Train Loss=4.6807, Val Loss=2.7003
Epoch [3/5]: Train Loss=3.8108, Val Loss=2.7010
Epoch [4/5]: Train Loss=3.2609, Val Loss=2.7016
Epoch [5/5]: Train Loss=2.9679, Val Loss=2.7021
BERT Test CPC Loss: 2.7019

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=513.9791, Val Loss=6.9553
Epoch [2/5]: Train Loss=39.8701, Val Loss=4.1428
Epoch [3/5]: Train Loss=26.0311, Val Loss=3.4698
Epoch [4/5]: Train Loss=19.3407, Val Loss=3.2375
Epoch [5/5]: Train Loss=15.5042, Val Loss=3.0272
GPT2 Test CPC Loss: 3.0110
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9439, Val Loss=1.3029
Epoch [2/5]: Train Loss=0.7147, Val Loss=0.3796
Epoch [3/5]: Train Loss=0.1480, Val Loss=0.0762
Epoch [4/5]: Train Loss=0.0221, Val Loss=0.0250
Epoch [5/5]: Train Loss=0.0065, Val Loss=0.0114
LSTM Test CPC Loss: 0.0562
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.7288, Val Loss=10.9263
Epoch [2/5]: Train Loss=8.3309, Val Loss=5.8078
Epoch [3/5]: Train Loss=4.2090, Val Loss=3.5862
Epoch [4/5]: Train Loss=2.4188, Val Loss=2.4649
Epoch [5/5]: Train Loss=1.5411, Val Loss=1.8055
Reservoir Test CPC Loss: 2.1755
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5915, Val Loss=2.9906
Epoch [2/5]: Train Loss=4.7638, Val Loss=2.9915
Epoch [3/5]: Train Loss=3.9714, Val Loss=2.9920
Epoch [4/5]: Train Loss=3.4819, Val Loss=2.9924
Epoch [5/5]: Train Loss=3.2271, Val Loss=2.9929
BERT Test CPC Loss: 2.9928

--- Fish 11: Run 9 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=410.3002, Val Loss=1.4513
Epoch [2/5]: Train Loss=23.4425, Val Loss=1.4542
Epoch [3/5]: Train Loss=16.9973, Val Loss=1.4618
Epoch [4/5]: Train Loss=12.9266, Val Loss=1.4937
Epoch [5/5]: Train Loss=10.5674, Val Loss=1.5091
GPT2 Test CPC Loss: 1.5114
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5607, Val Loss=0.0398
Epoch [2/5]: Train Loss=0.0092, Val Loss=0.0010
Epoch [3/5]: Train Loss=0.0035, Val Loss=0.0272
Epoch [4/5]: Train Loss=0.0046, Val Loss=0.0011
Epoch [5/5]: Train Loss=0.0024, Val Loss=0.0022
LSTM Test CPC Loss: 0.0025
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.0276, Val Loss=2.7227
Epoch [2/5]: Train Loss=1.5724, Val Loss=1.5710
Epoch [3/5]: Train Loss=0.8434, Val Loss=1.1524
Epoch [4/5]: Train Loss=0.4881, Val Loss=0.8897
Epoch [5/5]: Train Loss=0.3040, Val Loss=0.7722
Reservoir Test CPC Loss: 0.9594
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.5067, Val Loss=1.5190
Epoch [2/5]: Train Loss=5.0870, Val Loss=1.5213
Epoch [3/5]: Train Loss=4.1125, Val Loss=1.5256
Epoch [4/5]: Train Loss=3.3826, Val Loss=1.5240
Epoch [5/5]: Train Loss=2.7708, Val Loss=1.5146
BERT Test CPC Loss: 1.5192

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=438.5647, Val Loss=2.5221
Epoch [2/5]: Train Loss=39.0833, Val Loss=2.2952
Epoch [3/5]: Train Loss=25.7548, Val Loss=2.1837
Epoch [4/5]: Train Loss=19.1339, Val Loss=2.1794
Epoch [5/5]: Train Loss=15.5711, Val Loss=2.1882
GPT2 Test CPC Loss: 2.1823
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2842, Val Loss=0.4096
Epoch [2/5]: Train Loss=0.1537, Val Loss=0.0491
Epoch [3/5]: Train Loss=0.0183, Val Loss=0.0131
Epoch [4/5]: Train Loss=0.0048, Val Loss=0.0146
Epoch [5/5]: Train Loss=0.0083, Val Loss=0.0088
LSTM Test CPC Loss: 0.0291
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.6262, Val Loss=8.5856
Epoch [2/5]: Train Loss=6.1117, Val Loss=4.7937
Epoch [3/5]: Train Loss=3.4490, Val Loss=3.1730
Epoch [4/5]: Train Loss=2.1666, Val Loss=2.2968
Epoch [5/5]: Train Loss=1.4496, Val Loss=1.7926
Reservoir Test CPC Loss: 2.6055
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9386, Val Loss=2.2735
Epoch [2/5]: Train Loss=4.7986, Val Loss=2.2768
Epoch [3/5]: Train Loss=3.8477, Val Loss=2.2782
Epoch [4/5]: Train Loss=3.1811, Val Loss=2.2802
Epoch [5/5]: Train Loss=2.7532, Val Loss=2.2821
BERT Test CPC Loss: 2.2815

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=453.5915, Val Loss=2.8248
Epoch [2/5]: Train Loss=30.8889, Val Loss=2.6678
Epoch [3/5]: Train Loss=19.0790, Val Loss=2.6291
Epoch [4/5]: Train Loss=13.9458, Val Loss=2.6225
Epoch [5/5]: Train Loss=11.1637, Val Loss=2.6268
GPT2 Test CPC Loss: 2.6169
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6185, Val Loss=0.8194
Epoch [2/5]: Train Loss=0.3546, Val Loss=0.1592
Epoch [3/5]: Train Loss=0.0680, Val Loss=0.0545
Epoch [4/5]: Train Loss=0.0135, Val Loss=0.0279
Epoch [5/5]: Train Loss=0.0089, Val Loss=0.0137
LSTM Test CPC Loss: 0.0597
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.9284, Val Loss=12.0576
Epoch [2/5]: Train Loss=7.9257, Val Loss=6.3581
Epoch [3/5]: Train Loss=4.1632, Val Loss=3.8756
Epoch [4/5]: Train Loss=2.4732, Val Loss=2.6624
Epoch [5/5]: Train Loss=1.6107, Val Loss=1.9558
Reservoir Test CPC Loss: 2.6529
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1490, Val Loss=2.6964
Epoch [2/5]: Train Loss=4.8555, Val Loss=2.6980
Epoch [3/5]: Train Loss=3.9804, Val Loss=2.6984
Epoch [4/5]: Train Loss=3.3750, Val Loss=2.6998
Epoch [5/5]: Train Loss=3.0168, Val Loss=2.7008
BERT Test CPC Loss: 2.7004

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=373.5242, Val Loss=3.2993
Epoch [2/5]: Train Loss=25.8594, Val Loss=3.0303
Epoch [3/5]: Train Loss=19.1240, Val Loss=2.9294
Epoch [4/5]: Train Loss=15.5933, Val Loss=2.9575
Epoch [5/5]: Train Loss=12.9890, Val Loss=2.9365
GPT2 Test CPC Loss: 2.9259
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1648, Val Loss=1.4354
Epoch [2/5]: Train Loss=0.8621, Val Loss=0.6832
Epoch [3/5]: Train Loss=0.2373, Val Loss=0.1049
Epoch [4/5]: Train Loss=0.0389, Val Loss=0.0321
Epoch [5/5]: Train Loss=0.0091, Val Loss=0.0182
LSTM Test CPC Loss: 0.0814
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.1331, Val Loss=12.0527
Epoch [2/5]: Train Loss=8.5319, Val Loss=6.8920
Epoch [3/5]: Train Loss=4.6986, Val Loss=4.3448
Epoch [4/5]: Train Loss=2.8292, Val Loss=3.0614
Epoch [5/5]: Train Loss=1.8244, Val Loss=2.3081
Reservoir Test CPC Loss: 2.8486
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4223, Val Loss=2.9929
Epoch [2/5]: Train Loss=4.6799, Val Loss=2.9924
Epoch [3/5]: Train Loss=3.9123, Val Loss=2.9925
Epoch [4/5]: Train Loss=3.4414, Val Loss=2.9924
Epoch [5/5]: Train Loss=3.2002, Val Loss=2.9928
BERT Test CPC Loss: 2.9927

--- Fish 11: Run 10 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=397.0780, Val Loss=2.0152
Epoch [2/5]: Train Loss=30.6839, Val Loss=1.7755
Epoch [3/5]: Train Loss=20.0900, Val Loss=1.7168
Epoch [4/5]: Train Loss=15.3283, Val Loss=1.7341
Epoch [5/5]: Train Loss=12.2875, Val Loss=1.6424
GPT2 Test CPC Loss: 1.6458
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7053, Val Loss=0.1216
Epoch [2/5]: Train Loss=0.0212, Val Loss=0.0055
Epoch [3/5]: Train Loss=0.0025, Val Loss=0.0096
Epoch [4/5]: Train Loss=0.0029, Val Loss=0.0008
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0004
LSTM Test CPC Loss: 0.0013
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.6749, Val Loss=4.3753
Epoch [2/5]: Train Loss=2.1517, Val Loss=2.5985
Epoch [3/5]: Train Loss=1.0230, Val Loss=1.7048
Epoch [4/5]: Train Loss=0.5942, Val Loss=1.4366
Epoch [5/5]: Train Loss=0.3778, Val Loss=1.2968
Reservoir Test CPC Loss: 1.4262
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7620, Val Loss=1.5465
Epoch [2/5]: Train Loss=4.9130, Val Loss=1.5579
Epoch [3/5]: Train Loss=3.9314, Val Loss=1.5908
Epoch [4/5]: Train Loss=3.1653, Val Loss=1.5826
Epoch [5/5]: Train Loss=2.6234, Val Loss=1.5241
BERT Test CPC Loss: 1.5335

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=357.0039, Val Loss=3.1065
Epoch [2/5]: Train Loss=21.3328, Val Loss=2.7195
Epoch [3/5]: Train Loss=15.6118, Val Loss=3.0145
Epoch [4/5]: Train Loss=12.3970, Val Loss=2.8803
Epoch [5/5]: Train Loss=10.2744, Val Loss=2.6590
GPT2 Test CPC Loss: 2.6428
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3763, Val Loss=0.4941
Epoch [2/5]: Train Loss=0.1984, Val Loss=0.0525
Epoch [3/5]: Train Loss=0.0205, Val Loss=0.0176
Epoch [4/5]: Train Loss=0.0097, Val Loss=0.0099
Epoch [5/5]: Train Loss=0.0033, Val Loss=0.0089
LSTM Test CPC Loss: 0.0431
[Model: Reservoir]
Epoch [1/5]: Train Loss=14.5355, Val Loss=8.3223
Epoch [2/5]: Train Loss=5.8515, Val Loss=4.5917
Epoch [3/5]: Train Loss=3.2754, Val Loss=3.0497
Epoch [4/5]: Train Loss=2.0469, Val Loss=2.2019
Epoch [5/5]: Train Loss=1.3566, Val Loss=1.7297
Reservoir Test CPC Loss: 2.2194
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9248, Val Loss=2.2814
Epoch [2/5]: Train Loss=4.7272, Val Loss=2.2816
Epoch [3/5]: Train Loss=3.8013, Val Loss=2.2842
Epoch [4/5]: Train Loss=3.1166, Val Loss=2.2854
Epoch [5/5]: Train Loss=2.6723, Val Loss=2.2876
BERT Test CPC Loss: 2.2870

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=471.5152, Val Loss=2.6924
Epoch [2/5]: Train Loss=35.5454, Val Loss=2.6164
Epoch [3/5]: Train Loss=22.9619, Val Loss=2.6207
Epoch [4/5]: Train Loss=16.8830, Val Loss=2.6279
Epoch [5/5]: Train Loss=13.7971, Val Loss=2.6253
GPT2 Test CPC Loss: 2.6176
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6659, Val Loss=0.7623
Epoch [2/5]: Train Loss=0.3689, Val Loss=0.1525
Epoch [3/5]: Train Loss=0.0489, Val Loss=0.0496
Epoch [4/5]: Train Loss=0.0133, Val Loss=0.0170
Epoch [5/5]: Train Loss=0.0044, Val Loss=0.0096
LSTM Test CPC Loss: 0.0478
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.7514, Val Loss=11.5204
Epoch [2/5]: Train Loss=8.7084, Val Loss=6.7709
Epoch [3/5]: Train Loss=5.0219, Val Loss=4.5206
Epoch [4/5]: Train Loss=3.1203, Val Loss=3.2228
Epoch [5/5]: Train Loss=2.0627, Val Loss=2.4841
Reservoir Test CPC Loss: 2.8265
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6359, Val Loss=2.6945
Epoch [2/5]: Train Loss=4.7063, Val Loss=2.6969
Epoch [3/5]: Train Loss=3.8295, Val Loss=2.6997
Epoch [4/5]: Train Loss=3.2786, Val Loss=2.7007
Epoch [5/5]: Train Loss=2.9844, Val Loss=2.7014
BERT Test CPC Loss: 2.7012

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=318.8452, Val Loss=2.8587
Epoch [2/5]: Train Loss=18.1857, Val Loss=2.8706
Epoch [3/5]: Train Loss=13.4835, Val Loss=2.8793
Epoch [4/5]: Train Loss=11.0845, Val Loss=2.9036
Epoch [5/5]: Train Loss=9.4225, Val Loss=2.9189
GPT2 Test CPC Loss: 2.9067
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7432, Val Loss=1.0412
Epoch [2/5]: Train Loss=0.5561, Val Loss=0.4198
Epoch [3/5]: Train Loss=0.1058, Val Loss=0.1048
Epoch [4/5]: Train Loss=0.0175, Val Loss=0.0288
Epoch [5/5]: Train Loss=0.0055, Val Loss=0.0125
LSTM Test CPC Loss: 0.0614
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.4669, Val Loss=11.9359
Epoch [2/5]: Train Loss=8.8511, Val Loss=6.8692
Epoch [3/5]: Train Loss=4.8735, Val Loss=4.3882
Epoch [4/5]: Train Loss=2.9412, Val Loss=3.0612
Epoch [5/5]: Train Loss=1.9146, Val Loss=2.2677
Reservoir Test CPC Loss: 2.8031
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3330, Val Loss=2.9926
Epoch [2/5]: Train Loss=4.8856, Val Loss=2.9926
Epoch [3/5]: Train Loss=4.0619, Val Loss=2.9924
Epoch [4/5]: Train Loss=3.5311, Val Loss=2.9925
Epoch [5/5]: Train Loss=3.2446, Val Loss=2.9925
BERT Test CPC Loss: 2.9923

========== Processing Fish 12 ==========
Fish 12: Neural data shape: (2793, 10581)

--- Fish 12: Run 1 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=311.0145, Val Loss=6.6734
Epoch [2/5]: Train Loss=24.2562, Val Loss=4.5997
Epoch [3/5]: Train Loss=15.3876, Val Loss=3.5191
Epoch [4/5]: Train Loss=11.4521, Val Loss=2.3508
Epoch [5/5]: Train Loss=8.9776, Val Loss=1.8681
GPT2 Test CPC Loss: 1.8217
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5388, Val Loss=0.0248
Epoch [2/5]: Train Loss=0.0042, Val Loss=0.0031
Epoch [3/5]: Train Loss=0.0008, Val Loss=0.0014
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0010
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0007
LSTM Test CPC Loss: 0.0016
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.0450, Val Loss=4.5172
Epoch [2/5]: Train Loss=2.7504, Val Loss=2.7272
Epoch [3/5]: Train Loss=1.4490, Val Loss=1.9369
Epoch [4/5]: Train Loss=0.8723, Val Loss=1.5351
Epoch [5/5]: Train Loss=0.5488, Val Loss=1.2817
Reservoir Test CPC Loss: 1.3594
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1853, Val Loss=1.5261
Epoch [2/5]: Train Loss=4.9766, Val Loss=1.5412
Epoch [3/5]: Train Loss=3.9295, Val Loss=1.5595
Epoch [4/5]: Train Loss=3.1338, Val Loss=1.5681
Epoch [5/5]: Train Loss=2.5225, Val Loss=1.5293
BERT Test CPC Loss: 1.5310

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=471.3825, Val Loss=2.5331
Epoch [2/5]: Train Loss=33.1772, Val Loss=2.2806
Epoch [3/5]: Train Loss=18.1163, Val Loss=2.1809
Epoch [4/5]: Train Loss=12.5659, Val Loss=2.1699
Epoch [5/5]: Train Loss=10.0996, Val Loss=2.1678
GPT2 Test CPC Loss: 2.1634
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2083, Val Loss=0.4592
Epoch [2/5]: Train Loss=0.1234, Val Loss=0.0693
Epoch [3/5]: Train Loss=0.0105, Val Loss=0.0281
Epoch [4/5]: Train Loss=0.0031, Val Loss=0.0186
Epoch [5/5]: Train Loss=0.0016, Val Loss=0.0139
LSTM Test CPC Loss: 0.0222
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.4224, Val Loss=10.0166
Epoch [2/5]: Train Loss=7.6035, Val Loss=6.0114
Epoch [3/5]: Train Loss=4.4147, Val Loss=4.1748
Epoch [4/5]: Train Loss=2.7740, Val Loss=3.1247
Epoch [5/5]: Train Loss=1.8452, Val Loss=2.4709
Reservoir Test CPC Loss: 2.1850
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0328, Val Loss=2.2844
Epoch [2/5]: Train Loss=4.7666, Val Loss=2.2843
Epoch [3/5]: Train Loss=3.8153, Val Loss=2.2854
Epoch [4/5]: Train Loss=3.0961, Val Loss=2.2863
Epoch [5/5]: Train Loss=2.6626, Val Loss=2.2886
BERT Test CPC Loss: 2.2880

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=567.4636, Val Loss=8.3909
Epoch [2/5]: Train Loss=48.1430, Val Loss=3.6715
Epoch [3/5]: Train Loss=29.9318, Val Loss=2.8878
Epoch [4/5]: Train Loss=21.2382, Val Loss=2.7021
Epoch [5/5]: Train Loss=16.1151, Val Loss=2.6611
GPT2 Test CPC Loss: 2.6676
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4453, Val Loss=0.7544
Epoch [2/5]: Train Loss=0.2616, Val Loss=0.1753
Epoch [3/5]: Train Loss=0.0199, Val Loss=0.0316
Epoch [4/5]: Train Loss=0.0041, Val Loss=0.0225
Epoch [5/5]: Train Loss=0.0019, Val Loss=0.0169
LSTM Test CPC Loss: 0.0106
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.4509, Val Loss=11.4277
Epoch [2/5]: Train Loss=8.1982, Val Loss=6.9150
Epoch [3/5]: Train Loss=4.8583, Val Loss=4.6808
Epoch [4/5]: Train Loss=3.0577, Val Loss=3.3245
Epoch [5/5]: Train Loss=2.0307, Val Loss=2.5396
Reservoir Test CPC Loss: 3.0314
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7818, Val Loss=2.7042
Epoch [2/5]: Train Loss=4.6949, Val Loss=2.7028
Epoch [3/5]: Train Loss=3.8283, Val Loss=2.7032
Epoch [4/5]: Train Loss=3.2631, Val Loss=2.7032
Epoch [5/5]: Train Loss=2.9652, Val Loss=2.7037
BERT Test CPC Loss: 2.7034

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=573.1228, Val Loss=7.2884
Epoch [2/5]: Train Loss=27.1294, Val Loss=4.0418
Epoch [3/5]: Train Loss=19.9668, Val Loss=3.3880
Epoch [4/5]: Train Loss=16.1771, Val Loss=3.2113
Epoch [5/5]: Train Loss=13.5595, Val Loss=3.2502
GPT2 Test CPC Loss: 3.2335
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9022, Val Loss=1.3267
Epoch [2/5]: Train Loss=0.6984, Val Loss=0.6305
Epoch [3/5]: Train Loss=0.1659, Val Loss=0.1590
Epoch [4/5]: Train Loss=0.0214, Val Loss=0.0471
Epoch [5/5]: Train Loss=0.0047, Val Loss=0.0248
LSTM Test CPC Loss: 0.0243
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.8964, Val Loss=13.0416
Epoch [2/5]: Train Loss=9.1081, Val Loss=7.6946
Epoch [3/5]: Train Loss=5.1472, Val Loss=4.9813
Epoch [4/5]: Train Loss=3.1404, Val Loss=3.5431
Epoch [5/5]: Train Loss=2.0268, Val Loss=2.6896
Reservoir Test CPC Loss: 2.8776
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5693, Val Loss=2.9906
Epoch [2/5]: Train Loss=4.7073, Val Loss=2.9912
Epoch [3/5]: Train Loss=3.9318, Val Loss=2.9916
Epoch [4/5]: Train Loss=3.4730, Val Loss=2.9917
Epoch [5/5]: Train Loss=3.2317, Val Loss=2.9920
BERT Test CPC Loss: 2.9914

--- Fish 12: Run 2 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=445.8195, Val Loss=1.7303
Epoch [2/5]: Train Loss=30.0876, Val Loss=1.8560
Epoch [3/5]: Train Loss=20.5965, Val Loss=1.9166
Epoch [4/5]: Train Loss=15.6290, Val Loss=2.0085
Epoch [5/5]: Train Loss=12.5030, Val Loss=1.9835
GPT2 Test CPC Loss: 1.9886
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5539, Val Loss=0.0357
Epoch [2/5]: Train Loss=0.0060, Val Loss=0.0028
Epoch [3/5]: Train Loss=0.0008, Val Loss=0.0017
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0011
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0008
LSTM Test CPC Loss: 0.0015
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.2136, Val Loss=4.5961
Epoch [2/5]: Train Loss=2.7276, Val Loss=3.0281
Epoch [3/5]: Train Loss=1.4751, Val Loss=2.2435
Epoch [4/5]: Train Loss=0.8667, Val Loss=1.8285
Epoch [5/5]: Train Loss=0.5260, Val Loss=1.5473
Reservoir Test CPC Loss: 1.5178
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5850, Val Loss=1.5202
Epoch [2/5]: Train Loss=4.7946, Val Loss=1.5618
Epoch [3/5]: Train Loss=3.7467, Val Loss=1.5874
Epoch [4/5]: Train Loss=2.9771, Val Loss=1.5600
Epoch [5/5]: Train Loss=2.3763, Val Loss=1.4912
BERT Test CPC Loss: 1.4923

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=380.3433, Val Loss=2.9955
Epoch [2/5]: Train Loss=29.9237, Val Loss=2.3183
Epoch [3/5]: Train Loss=18.8079, Val Loss=2.2714
Epoch [4/5]: Train Loss=14.1676, Val Loss=2.3030
Epoch [5/5]: Train Loss=11.4412, Val Loss=2.3011
GPT2 Test CPC Loss: 2.3144
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1456, Val Loss=0.4381
Epoch [2/5]: Train Loss=0.1354, Val Loss=0.0763
Epoch [3/5]: Train Loss=0.0110, Val Loss=0.0276
Epoch [4/5]: Train Loss=0.0032, Val Loss=0.0166
Epoch [5/5]: Train Loss=0.0015, Val Loss=0.0112
LSTM Test CPC Loss: 0.0112
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.5208, Val Loss=10.9275
Epoch [2/5]: Train Loss=7.5426, Val Loss=6.6005
Epoch [3/5]: Train Loss=4.3771, Val Loss=4.5815
Epoch [4/5]: Train Loss=2.7218, Val Loss=3.4265
Epoch [5/5]: Train Loss=1.7977, Val Loss=2.7149
Reservoir Test CPC Loss: 3.0434
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9070, Val Loss=2.2829
Epoch [2/5]: Train Loss=4.7441, Val Loss=2.2841
Epoch [3/5]: Train Loss=3.7843, Val Loss=2.2864
Epoch [4/5]: Train Loss=3.0995, Val Loss=2.2877
Epoch [5/5]: Train Loss=2.6839, Val Loss=2.2876
BERT Test CPC Loss: 2.2871

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=505.2049, Val Loss=2.6233
Epoch [2/5]: Train Loss=24.6741, Val Loss=2.7139
Epoch [3/5]: Train Loss=17.6882, Val Loss=2.6931
Epoch [4/5]: Train Loss=14.2618, Val Loss=2.7291
Epoch [5/5]: Train Loss=11.8102, Val Loss=2.7211
GPT2 Test CPC Loss: 2.7191
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5769, Val Loss=1.0692
Epoch [2/5]: Train Loss=0.3883, Val Loss=0.2292
Epoch [3/5]: Train Loss=0.0587, Val Loss=0.0731
Epoch [4/5]: Train Loss=0.0104, Val Loss=0.0403
Epoch [5/5]: Train Loss=0.0042, Val Loss=0.0356
LSTM Test CPC Loss: 0.0235
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.1868, Val Loss=13.1242
Epoch [2/5]: Train Loss=9.1706, Val Loss=7.7112
Epoch [3/5]: Train Loss=5.2539, Val Loss=5.2068
Epoch [4/5]: Train Loss=3.2285, Val Loss=3.7536
Epoch [5/5]: Train Loss=2.1022, Val Loss=2.8840
Reservoir Test CPC Loss: 2.5449
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9597, Val Loss=2.7014
Epoch [2/5]: Train Loss=4.6931, Val Loss=2.7016
Epoch [3/5]: Train Loss=3.7910, Val Loss=2.7030
Epoch [4/5]: Train Loss=3.2163, Val Loss=2.7034
Epoch [5/5]: Train Loss=2.9319, Val Loss=2.7041
BERT Test CPC Loss: 2.7038

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=324.2259, Val Loss=3.0136
Epoch [2/5]: Train Loss=25.6309, Val Loss=2.9567
Epoch [3/5]: Train Loss=17.5210, Val Loss=2.9353
Epoch [4/5]: Train Loss=13.2944, Val Loss=2.9362
Epoch [5/5]: Train Loss=10.6002, Val Loss=2.9433
GPT2 Test CPC Loss: 2.9411
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9445, Val Loss=1.3230
Epoch [2/5]: Train Loss=0.7873, Val Loss=0.6641
Epoch [3/5]: Train Loss=0.2699, Val Loss=0.3032
Epoch [4/5]: Train Loss=0.0561, Val Loss=0.0721
Epoch [5/5]: Train Loss=0.0120, Val Loss=0.0498
LSTM Test CPC Loss: 0.0288
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.7201, Val Loss=11.9967
Epoch [2/5]: Train Loss=9.0127, Val Loss=6.8401
Epoch [3/5]: Train Loss=4.9802, Val Loss=4.2175
Epoch [4/5]: Train Loss=2.9831, Val Loss=2.8675
Epoch [5/5]: Train Loss=1.9260, Val Loss=2.0771
Reservoir Test CPC Loss: 2.1850
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6664, Val Loss=2.9876
Epoch [2/5]: Train Loss=4.7270, Val Loss=2.9891
Epoch [3/5]: Train Loss=3.8975, Val Loss=2.9898
Epoch [4/5]: Train Loss=3.4223, Val Loss=2.9907
Epoch [5/5]: Train Loss=3.2064, Val Loss=2.9913
BERT Test CPC Loss: 2.9907

--- Fish 12: Run 3 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=548.8361, Val Loss=1.4652
Epoch [2/5]: Train Loss=32.8599, Val Loss=1.5020
Epoch [3/5]: Train Loss=22.3421, Val Loss=1.5273
Epoch [4/5]: Train Loss=16.9234, Val Loss=1.6016
Epoch [5/5]: Train Loss=13.4665, Val Loss=1.6184
GPT2 Test CPC Loss: 1.6127
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6957, Val Loss=0.0545
Epoch [2/5]: Train Loss=0.0112, Val Loss=0.0047
Epoch [3/5]: Train Loss=0.0013, Val Loss=0.0027
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0018
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0014
LSTM Test CPC Loss: 0.0012
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.0359, Val Loss=4.1991
Epoch [2/5]: Train Loss=2.4644, Val Loss=2.3492
Epoch [3/5]: Train Loss=1.3123, Val Loss=1.6658
Epoch [4/5]: Train Loss=0.7901, Val Loss=1.2588
Epoch [5/5]: Train Loss=0.5134, Val Loss=1.0482
Reservoir Test CPC Loss: 1.3606
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6796, Val Loss=1.5174
Epoch [2/5]: Train Loss=4.8290, Val Loss=1.5347
Epoch [3/5]: Train Loss=3.8181, Val Loss=1.5540
Epoch [4/5]: Train Loss=3.0355, Val Loss=1.5520
Epoch [5/5]: Train Loss=2.3975, Val Loss=1.5061
BERT Test CPC Loss: 1.5073

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=488.8663, Val Loss=2.3146
Epoch [2/5]: Train Loss=30.1027, Val Loss=2.3078
Epoch [3/5]: Train Loss=20.5004, Val Loss=2.3546
Epoch [4/5]: Train Loss=15.8057, Val Loss=2.3253
Epoch [5/5]: Train Loss=12.9502, Val Loss=2.3076
GPT2 Test CPC Loss: 2.3048
[Model: LSTM]
Epoch [1/5]: Train Loss=1.0735, Val Loss=0.3958
Epoch [2/5]: Train Loss=0.0871, Val Loss=0.1120
Epoch [3/5]: Train Loss=0.0077, Val Loss=0.0519
Epoch [4/5]: Train Loss=0.0024, Val Loss=0.0412
Epoch [5/5]: Train Loss=0.0013, Val Loss=0.0355
LSTM Test CPC Loss: 0.0082
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.5429, Val Loss=10.9196
Epoch [2/5]: Train Loss=8.0470, Val Loss=6.8609
Epoch [3/5]: Train Loss=4.7884, Val Loss=4.7566
Epoch [4/5]: Train Loss=3.0831, Val Loss=3.5840
Epoch [5/5]: Train Loss=2.0758, Val Loss=2.9121
Reservoir Test CPC Loss: 2.8403
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5309, Val Loss=2.2731
Epoch [2/5]: Train Loss=4.6935, Val Loss=2.2757
Epoch [3/5]: Train Loss=3.7487, Val Loss=2.2791
Epoch [4/5]: Train Loss=3.0386, Val Loss=2.2816
Epoch [5/5]: Train Loss=2.6158, Val Loss=2.2844
BERT Test CPC Loss: 2.2840

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=423.6947, Val Loss=3.8023
Epoch [2/5]: Train Loss=28.9395, Val Loss=4.8426
Epoch [3/5]: Train Loss=20.4802, Val Loss=3.8231
Epoch [4/5]: Train Loss=15.8751, Val Loss=3.3009
Epoch [5/5]: Train Loss=13.2568, Val Loss=3.2055
GPT2 Test CPC Loss: 3.2290
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6112, Val Loss=0.9728
Epoch [2/5]: Train Loss=0.3843, Val Loss=0.1880
Epoch [3/5]: Train Loss=0.0432, Val Loss=0.0489
Epoch [4/5]: Train Loss=0.0079, Val Loss=0.0280
Epoch [5/5]: Train Loss=0.0033, Val Loss=0.0243
LSTM Test CPC Loss: 0.0247
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.9002, Val Loss=13.8591
Epoch [2/5]: Train Loss=9.3825, Val Loss=8.0354
Epoch [3/5]: Train Loss=5.2019, Val Loss=5.1389
Epoch [4/5]: Train Loss=3.1452, Val Loss=3.5687
Epoch [5/5]: Train Loss=2.0284, Val Loss=2.7215
Reservoir Test CPC Loss: 2.6357
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9250, Val Loss=2.6971
Epoch [2/5]: Train Loss=4.7402, Val Loss=2.6967
Epoch [3/5]: Train Loss=3.8811, Val Loss=2.6967
Epoch [4/5]: Train Loss=3.3273, Val Loss=2.6975
Epoch [5/5]: Train Loss=3.0091, Val Loss=2.6988
BERT Test CPC Loss: 2.6982

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=1771.4589, Val Loss=9.1640
Epoch [2/5]: Train Loss=117.5624, Val Loss=2.5321
Epoch [3/5]: Train Loss=54.8162, Val Loss=3.4243
Epoch [4/5]: Train Loss=38.2556, Val Loss=4.2875
Epoch [5/5]: Train Loss=30.0885, Val Loss=4.7984
GPT2 Test CPC Loss: 4.8364
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0161, Val Loss=1.4663
Epoch [2/5]: Train Loss=0.8411, Val Loss=0.7020
Epoch [3/5]: Train Loss=0.2505, Val Loss=0.1933
Epoch [4/5]: Train Loss=0.0378, Val Loss=0.0551
Epoch [5/5]: Train Loss=0.0079, Val Loss=0.0358
LSTM Test CPC Loss: 0.0387
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.1927, Val Loss=15.2056
Epoch [2/5]: Train Loss=10.0031, Val Loss=9.3853
Epoch [3/5]: Train Loss=5.8105, Val Loss=6.5278
Epoch [4/5]: Train Loss=3.6466, Val Loss=4.8397
Epoch [5/5]: Train Loss=2.4280, Val Loss=3.7300
Reservoir Test CPC Loss: 3.5495
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.2782, Val Loss=2.9910
Epoch [2/5]: Train Loss=4.6823, Val Loss=2.9910
Epoch [3/5]: Train Loss=3.9162, Val Loss=2.9917
Epoch [4/5]: Train Loss=3.4599, Val Loss=2.9923
Epoch [5/5]: Train Loss=3.2175, Val Loss=2.9926
BERT Test CPC Loss: 2.9924

--- Fish 12: Run 4 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=628.3555, Val Loss=2.3697
Epoch [2/5]: Train Loss=43.1478, Val Loss=1.5594
Epoch [3/5]: Train Loss=29.8355, Val Loss=1.5574
Epoch [4/5]: Train Loss=22.6602, Val Loss=1.5982
Epoch [5/5]: Train Loss=17.9509, Val Loss=1.6502
GPT2 Test CPC Loss: 1.6516
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6128, Val Loss=0.0941
Epoch [2/5]: Train Loss=0.0061, Val Loss=0.0038
Epoch [3/5]: Train Loss=0.0007, Val Loss=0.0024
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0014
Epoch [5/5]: Train Loss=0.0002, Val Loss=0.0010
LSTM Test CPC Loss: 0.0005
[Model: Reservoir]
Epoch [1/5]: Train Loss=6.6405, Val Loss=4.4673
Epoch [2/5]: Train Loss=2.2605, Val Loss=2.9775
Epoch [3/5]: Train Loss=1.2780, Val Loss=2.2081
Epoch [4/5]: Train Loss=0.7815, Val Loss=1.7739
Epoch [5/5]: Train Loss=0.5048, Val Loss=1.5030
Reservoir Test CPC Loss: 1.4792
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8213, Val Loss=1.5041
Epoch [2/5]: Train Loss=4.8047, Val Loss=1.5146
Epoch [3/5]: Train Loss=3.7159, Val Loss=1.5475
Epoch [4/5]: Train Loss=2.9259, Val Loss=1.5181
Epoch [5/5]: Train Loss=2.3514, Val Loss=1.4823
BERT Test CPC Loss: 1.4833

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=347.4392, Val Loss=2.4293
Epoch [2/5]: Train Loss=23.6182, Val Loss=2.2935
Epoch [3/5]: Train Loss=17.1843, Val Loss=2.2628
Epoch [4/5]: Train Loss=13.6290, Val Loss=2.2504
Epoch [5/5]: Train Loss=11.3129, Val Loss=2.2525
GPT2 Test CPC Loss: 2.2550
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1988, Val Loss=0.5060
Epoch [2/5]: Train Loss=0.1350, Val Loss=0.0738
Epoch [3/5]: Train Loss=0.0088, Val Loss=0.0334
Epoch [4/5]: Train Loss=0.0021, Val Loss=0.0210
Epoch [5/5]: Train Loss=0.0011, Val Loss=0.0184
LSTM Test CPC Loss: 0.0079
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.0615, Val Loss=10.6348
Epoch [2/5]: Train Loss=7.6178, Val Loss=6.6553
Epoch [3/5]: Train Loss=4.6426, Val Loss=4.5658
Epoch [4/5]: Train Loss=3.0225, Val Loss=3.4491
Epoch [5/5]: Train Loss=2.0495, Val Loss=2.6952
Reservoir Test CPC Loss: 2.3913
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8758, Val Loss=2.2787
Epoch [2/5]: Train Loss=4.7339, Val Loss=2.2791
Epoch [3/5]: Train Loss=3.7975, Val Loss=2.2782
Epoch [4/5]: Train Loss=3.1442, Val Loss=2.2775
Epoch [5/5]: Train Loss=2.7349, Val Loss=2.2793
BERT Test CPC Loss: 2.2786

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=391.5629, Val Loss=3.9800
Epoch [2/5]: Train Loss=25.7125, Val Loss=3.4570
Epoch [3/5]: Train Loss=18.3866, Val Loss=3.3888
Epoch [4/5]: Train Loss=14.4816, Val Loss=2.9972
Epoch [5/5]: Train Loss=11.7112, Val Loss=2.9525
GPT2 Test CPC Loss: 2.9828
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7531, Val Loss=0.9958
Epoch [2/5]: Train Loss=0.4631, Val Loss=0.3488
Epoch [3/5]: Train Loss=0.0599, Val Loss=0.1152
Epoch [4/5]: Train Loss=0.0085, Val Loss=0.0542
Epoch [5/5]: Train Loss=0.0030, Val Loss=0.0411
LSTM Test CPC Loss: 0.0336
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.6913, Val Loss=13.2174
Epoch [2/5]: Train Loss=8.7138, Val Loss=7.7045
Epoch [3/5]: Train Loss=4.9635, Val Loss=5.0959
Epoch [4/5]: Train Loss=3.0603, Val Loss=3.6210
Epoch [5/5]: Train Loss=2.0183, Val Loss=2.7734
Reservoir Test CPC Loss: 2.6436
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7695, Val Loss=2.6923
Epoch [2/5]: Train Loss=4.6993, Val Loss=2.6958
Epoch [3/5]: Train Loss=3.8086, Val Loss=2.6983
Epoch [4/5]: Train Loss=3.2240, Val Loss=2.6999
Epoch [5/5]: Train Loss=2.9364, Val Loss=2.7007
BERT Test CPC Loss: 2.7004

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=677.6720, Val Loss=9.3553
Epoch [2/5]: Train Loss=38.1524, Val Loss=4.9605
Epoch [3/5]: Train Loss=26.5572, Val Loss=4.2652
Epoch [4/5]: Train Loss=20.8098, Val Loss=3.4613
Epoch [5/5]: Train Loss=17.4348, Val Loss=3.4892
GPT2 Test CPC Loss: 3.5152
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1355, Val Loss=1.5520
Epoch [2/5]: Train Loss=0.8287, Val Loss=0.7896
Epoch [3/5]: Train Loss=0.2491, Val Loss=0.2684
Epoch [4/5]: Train Loss=0.0409, Val Loss=0.0782
Epoch [5/5]: Train Loss=0.0089, Val Loss=0.0338
LSTM Test CPC Loss: 0.0331
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.5932, Val Loss=13.8135
Epoch [2/5]: Train Loss=9.5584, Val Loss=7.5715
Epoch [3/5]: Train Loss=5.2967, Val Loss=4.8591
Epoch [4/5]: Train Loss=3.2273, Val Loss=3.4414
Epoch [5/5]: Train Loss=2.1109, Val Loss=2.5769
Reservoir Test CPC Loss: 2.6824
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4138, Val Loss=2.9919
Epoch [2/5]: Train Loss=4.6854, Val Loss=2.9914
Epoch [3/5]: Train Loss=3.8567, Val Loss=2.9915
Epoch [4/5]: Train Loss=3.3779, Val Loss=2.9919
Epoch [5/5]: Train Loss=3.1739, Val Loss=2.9920
BERT Test CPC Loss: 2.9914

--- Fish 12: Run 5 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=614.1201, Val Loss=1.5315
Epoch [2/5]: Train Loss=40.7897, Val Loss=1.6753
Epoch [3/5]: Train Loss=27.7384, Val Loss=1.5751
Epoch [4/5]: Train Loss=21.0632, Val Loss=1.6045
Epoch [5/5]: Train Loss=17.0359, Val Loss=1.6804
GPT2 Test CPC Loss: 1.6793
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7448, Val Loss=0.0766
Epoch [2/5]: Train Loss=0.0120, Val Loss=0.0052
Epoch [3/5]: Train Loss=0.0011, Val Loss=0.0023
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0015
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0011
LSTM Test CPC Loss: 0.0007
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.8507, Val Loss=4.4780
Epoch [2/5]: Train Loss=2.8035, Val Loss=2.7624
Epoch [3/5]: Train Loss=1.5948, Val Loss=2.0380
Epoch [4/5]: Train Loss=1.0113, Val Loss=1.6851
Epoch [5/5]: Train Loss=0.6696, Val Loss=1.3963
Reservoir Test CPC Loss: 1.4780
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5040, Val Loss=1.5122
Epoch [2/5]: Train Loss=4.7264, Val Loss=1.5379
Epoch [3/5]: Train Loss=3.7294, Val Loss=1.5798
Epoch [4/5]: Train Loss=2.9255, Val Loss=1.5419
Epoch [5/5]: Train Loss=2.3516, Val Loss=1.4747
BERT Test CPC Loss: 1.4754

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=489.7420, Val Loss=2.4328
Epoch [2/5]: Train Loss=27.5105, Val Loss=2.3853
Epoch [3/5]: Train Loss=19.8713, Val Loss=2.3694
Epoch [4/5]: Train Loss=15.9557, Val Loss=2.3085
Epoch [5/5]: Train Loss=13.4826, Val Loss=2.2845
GPT2 Test CPC Loss: 2.2811
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2284, Val Loss=0.4420
Epoch [2/5]: Train Loss=0.1525, Val Loss=0.0697
Epoch [3/5]: Train Loss=0.0123, Val Loss=0.0460
Epoch [4/5]: Train Loss=0.0030, Val Loss=0.0214
Epoch [5/5]: Train Loss=0.0015, Val Loss=0.0205
LSTM Test CPC Loss: 0.0168
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.0033, Val Loss=9.8737
Epoch [2/5]: Train Loss=7.6261, Val Loss=6.1476
Epoch [3/5]: Train Loss=4.5419, Val Loss=4.3162
Epoch [4/5]: Train Loss=2.9046, Val Loss=3.3281
Epoch [5/5]: Train Loss=1.9747, Val Loss=2.6788
Reservoir Test CPC Loss: 2.7123
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0758, Val Loss=2.2765
Epoch [2/5]: Train Loss=4.8145, Val Loss=2.2786
Epoch [3/5]: Train Loss=3.8625, Val Loss=2.2798
Epoch [4/5]: Train Loss=3.1957, Val Loss=2.2798
Epoch [5/5]: Train Loss=2.7590, Val Loss=2.2815
BERT Test CPC Loss: 2.2809

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=363.8368, Val Loss=4.1069
Epoch [2/5]: Train Loss=21.0932, Val Loss=3.0053
Epoch [3/5]: Train Loss=15.3737, Val Loss=3.0851
Epoch [4/5]: Train Loss=12.6149, Val Loss=2.8313
Epoch [5/5]: Train Loss=10.6804, Val Loss=2.8274
GPT2 Test CPC Loss: 2.7790
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8085, Val Loss=1.0327
Epoch [2/5]: Train Loss=0.5365, Val Loss=0.3118
Epoch [3/5]: Train Loss=0.0782, Val Loss=0.0626
Epoch [4/5]: Train Loss=0.0106, Val Loss=0.0240
Epoch [5/5]: Train Loss=0.0036, Val Loss=0.0156
LSTM Test CPC Loss: 0.0241
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.0229, Val Loss=14.3638
Epoch [2/5]: Train Loss=10.1487, Val Loss=8.4415
Epoch [3/5]: Train Loss=5.6098, Val Loss=5.4989
Epoch [4/5]: Train Loss=3.3361, Val Loss=3.8665
Epoch [5/5]: Train Loss=2.1234, Val Loss=2.8980
Reservoir Test CPC Loss: 2.9763
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.2195, Val Loss=2.6985
Epoch [2/5]: Train Loss=4.5872, Val Loss=2.7011
Epoch [3/5]: Train Loss=3.7185, Val Loss=2.7021
Epoch [4/5]: Train Loss=3.1733, Val Loss=2.7025
Epoch [5/5]: Train Loss=2.9171, Val Loss=2.7031
BERT Test CPC Loss: 2.7029

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=485.1762, Val Loss=3.0532
Epoch [2/5]: Train Loss=23.1411, Val Loss=2.9659
Epoch [3/5]: Train Loss=16.6197, Val Loss=2.9488
Epoch [4/5]: Train Loss=13.6091, Val Loss=2.9503
Epoch [5/5]: Train Loss=11.3317, Val Loss=2.9435
GPT2 Test CPC Loss: 2.9429
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9251, Val Loss=1.3657
Epoch [2/5]: Train Loss=0.7652, Val Loss=0.6351
Epoch [3/5]: Train Loss=0.2250, Val Loss=0.2410
Epoch [4/5]: Train Loss=0.0542, Val Loss=0.0778
Epoch [5/5]: Train Loss=0.0240, Val Loss=0.0623
LSTM Test CPC Loss: 0.0349
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.8905, Val Loss=13.2339
Epoch [2/5]: Train Loss=9.8026, Val Loss=8.1934
Epoch [3/5]: Train Loss=5.7274, Val Loss=5.7056
Epoch [4/5]: Train Loss=3.6098, Val Loss=4.1807
Epoch [5/5]: Train Loss=2.4217, Val Loss=3.2976
Reservoir Test CPC Loss: 2.8405
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5636, Val Loss=2.9880
Epoch [2/5]: Train Loss=4.7040, Val Loss=2.9897
Epoch [3/5]: Train Loss=3.8875, Val Loss=2.9908
Epoch [4/5]: Train Loss=3.4104, Val Loss=2.9915
Epoch [5/5]: Train Loss=3.2007, Val Loss=2.9922
BERT Test CPC Loss: 2.9919

--- Fish 12: Run 6 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=382.8357, Val Loss=5.1830
Epoch [2/5]: Train Loss=27.7477, Val Loss=4.1901
Epoch [3/5]: Train Loss=18.0496, Val Loss=3.5713
Epoch [4/5]: Train Loss=13.1508, Val Loss=2.6517
Epoch [5/5]: Train Loss=10.3904, Val Loss=1.9068
GPT2 Test CPC Loss: 1.7993
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6704, Val Loss=0.0646
Epoch [2/5]: Train Loss=0.0075, Val Loss=0.0048
Epoch [3/5]: Train Loss=0.0010, Val Loss=0.0027
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0017
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0011
LSTM Test CPC Loss: 0.0008
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.3705, Val Loss=3.9305
Epoch [2/5]: Train Loss=2.7208, Val Loss=2.1613
Epoch [3/5]: Train Loss=1.3834, Val Loss=1.5753
Epoch [4/5]: Train Loss=0.8138, Val Loss=1.2969
Epoch [5/5]: Train Loss=0.5184, Val Loss=1.1134
Reservoir Test CPC Loss: 1.0589
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8925, Val Loss=1.5136
Epoch [2/5]: Train Loss=4.7692, Val Loss=1.5444
Epoch [3/5]: Train Loss=3.7488, Val Loss=1.5783
Epoch [4/5]: Train Loss=2.9964, Val Loss=1.5598
Epoch [5/5]: Train Loss=2.4407, Val Loss=1.4843
BERT Test CPC Loss: 1.4860

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=337.5340, Val Loss=2.7831
Epoch [2/5]: Train Loss=28.5783, Val Loss=2.2168
Epoch [3/5]: Train Loss=18.7049, Val Loss=2.1880
Epoch [4/5]: Train Loss=13.9533, Val Loss=2.1882
Epoch [5/5]: Train Loss=11.1830, Val Loss=2.1799
GPT2 Test CPC Loss: 2.1759
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2139, Val Loss=0.5082
Epoch [2/5]: Train Loss=0.1404, Val Loss=0.0811
Epoch [3/5]: Train Loss=0.0118, Val Loss=0.0464
Epoch [4/5]: Train Loss=0.0034, Val Loss=0.0215
Epoch [5/5]: Train Loss=0.0017, Val Loss=0.0201
LSTM Test CPC Loss: 0.0164
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.5702, Val Loss=9.4942
Epoch [2/5]: Train Loss=7.5740, Val Loss=6.0059
Epoch [3/5]: Train Loss=4.4322, Val Loss=4.1556
Epoch [4/5]: Train Loss=2.7844, Val Loss=3.0568
Epoch [5/5]: Train Loss=1.8548, Val Loss=2.4749
Reservoir Test CPC Loss: 2.6150
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.0828, Val Loss=2.2842
Epoch [2/5]: Train Loss=4.5675, Val Loss=2.2830
Epoch [3/5]: Train Loss=3.6299, Val Loss=2.2829
Epoch [4/5]: Train Loss=2.9490, Val Loss=2.2831
Epoch [5/5]: Train Loss=2.5942, Val Loss=2.2840
BERT Test CPC Loss: 2.2835

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=377.4019, Val Loss=2.7652
Epoch [2/5]: Train Loss=28.6540, Val Loss=2.6214
Epoch [3/5]: Train Loss=19.1553, Val Loss=2.6261
Epoch [4/5]: Train Loss=14.3773, Val Loss=2.6299
Epoch [5/5]: Train Loss=11.7132, Val Loss=2.6320
GPT2 Test CPC Loss: 2.6330
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8701, Val Loss=1.1711
Epoch [2/5]: Train Loss=0.6179, Val Loss=0.4070
Epoch [3/5]: Train Loss=0.1075, Val Loss=0.1008
Epoch [4/5]: Train Loss=0.0139, Val Loss=0.0568
Epoch [5/5]: Train Loss=0.0038, Val Loss=0.0394
LSTM Test CPC Loss: 0.0259
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.8807, Val Loss=12.8227
Epoch [2/5]: Train Loss=9.1907, Val Loss=7.8616
Epoch [3/5]: Train Loss=5.4277, Val Loss=5.3628
Epoch [4/5]: Train Loss=3.4227, Val Loss=3.9140
Epoch [5/5]: Train Loss=2.2843, Val Loss=2.9626
Reservoir Test CPC Loss: 3.1940
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5654, Val Loss=2.6925
Epoch [2/5]: Train Loss=4.6672, Val Loss=2.6950
Epoch [3/5]: Train Loss=3.7301, Val Loss=2.6976
Epoch [4/5]: Train Loss=3.1648, Val Loss=2.6991
Epoch [5/5]: Train Loss=2.9183, Val Loss=2.7002
BERT Test CPC Loss: 2.6998

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=437.3297, Val Loss=4.0615
Epoch [2/5]: Train Loss=30.9402, Val Loss=2.9389
Epoch [3/5]: Train Loss=21.1247, Val Loss=2.8918
Epoch [4/5]: Train Loss=16.5180, Val Loss=2.8877
Epoch [5/5]: Train Loss=13.2849, Val Loss=2.9008
GPT2 Test CPC Loss: 2.9052
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7726, Val Loss=1.3489
Epoch [2/5]: Train Loss=0.7204, Val Loss=0.6579
Epoch [3/5]: Train Loss=0.2079, Val Loss=0.2873
Epoch [4/5]: Train Loss=0.0300, Val Loss=0.1275
Epoch [5/5]: Train Loss=0.0087, Val Loss=0.0883
LSTM Test CPC Loss: 0.0582
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.3554, Val Loss=13.5897
Epoch [2/5]: Train Loss=9.0155, Val Loss=7.9407
Epoch [3/5]: Train Loss=5.1326, Val Loss=5.0420
Epoch [4/5]: Train Loss=3.1566, Val Loss=3.5218
Epoch [5/5]: Train Loss=2.0671, Val Loss=2.5660
Reservoir Test CPC Loss: 2.6274
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.3506, Val Loss=2.9901
Epoch [2/5]: Train Loss=4.6787, Val Loss=2.9905
Epoch [3/5]: Train Loss=3.8943, Val Loss=2.9906
Epoch [4/5]: Train Loss=3.4456, Val Loss=2.9913
Epoch [5/5]: Train Loss=3.2191, Val Loss=2.9917
BERT Test CPC Loss: 2.9913

--- Fish 12: Run 7 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=417.6193, Val Loss=2.9487
Epoch [2/5]: Train Loss=35.9962, Val Loss=1.7982
Epoch [3/5]: Train Loss=24.9211, Val Loss=1.4769
Epoch [4/5]: Train Loss=19.0335, Val Loss=1.4174
Epoch [5/5]: Train Loss=14.8929, Val Loss=1.4089
GPT2 Test CPC Loss: 1.4106
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6054, Val Loss=0.0239
Epoch [2/5]: Train Loss=0.0074, Val Loss=0.0027
Epoch [3/5]: Train Loss=0.0011, Val Loss=0.0013
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0009
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0006
LSTM Test CPC Loss: 0.0017
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.2135, Val Loss=3.6486
Epoch [2/5]: Train Loss=2.3325, Val Loss=2.2014
Epoch [3/5]: Train Loss=1.2569, Val Loss=1.6956
Epoch [4/5]: Train Loss=0.7627, Val Loss=1.3808
Epoch [5/5]: Train Loss=0.4789, Val Loss=1.1925
Reservoir Test CPC Loss: 0.8109
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9202, Val Loss=1.5204
Epoch [2/5]: Train Loss=4.8599, Val Loss=1.5428
Epoch [3/5]: Train Loss=3.8337, Val Loss=1.6067
Epoch [4/5]: Train Loss=3.0803, Val Loss=1.5762
Epoch [5/5]: Train Loss=2.5593, Val Loss=1.5130
BERT Test CPC Loss: 1.5174

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=240.0291, Val Loss=2.3194
Epoch [2/5]: Train Loss=16.9692, Val Loss=2.2480
Epoch [3/5]: Train Loss=12.0100, Val Loss=2.2197
Epoch [4/5]: Train Loss=9.5645, Val Loss=2.2238
Epoch [5/5]: Train Loss=8.0549, Val Loss=2.2268
GPT2 Test CPC Loss: 2.2251
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1924, Val Loss=0.4654
Epoch [2/5]: Train Loss=0.1297, Val Loss=0.0951
Epoch [3/5]: Train Loss=0.0119, Val Loss=0.0437
Epoch [4/5]: Train Loss=0.0029, Val Loss=0.0389
Epoch [5/5]: Train Loss=0.0014, Val Loss=0.0312
LSTM Test CPC Loss: 0.0198
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.9554, Val Loss=10.5311
Epoch [2/5]: Train Loss=7.8077, Val Loss=6.0989
Epoch [3/5]: Train Loss=4.4015, Val Loss=4.0608
Epoch [4/5]: Train Loss=2.7064, Val Loss=3.0197
Epoch [5/5]: Train Loss=1.7667, Val Loss=2.3151
Reservoir Test CPC Loss: 2.6723
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6542, Val Loss=2.2807
Epoch [2/5]: Train Loss=4.7156, Val Loss=2.2809
Epoch [3/5]: Train Loss=3.7420, Val Loss=2.2799
Epoch [4/5]: Train Loss=3.0601, Val Loss=2.2812
Epoch [5/5]: Train Loss=2.6494, Val Loss=2.2809
BERT Test CPC Loss: 2.2804

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=622.2379, Val Loss=2.7210
Epoch [2/5]: Train Loss=26.8889, Val Loss=2.6694
Epoch [3/5]: Train Loss=18.4993, Val Loss=2.6573
Epoch [4/5]: Train Loss=14.8700, Val Loss=2.6678
Epoch [5/5]: Train Loss=12.2216, Val Loss=2.6788
GPT2 Test CPC Loss: 2.6817
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6938, Val Loss=1.0038
Epoch [2/5]: Train Loss=0.4753, Val Loss=0.2677
Epoch [3/5]: Train Loss=0.0632, Val Loss=0.0604
Epoch [4/5]: Train Loss=0.0093, Val Loss=0.0318
Epoch [5/5]: Train Loss=0.0033, Val Loss=0.0214
LSTM Test CPC Loss: 0.0161
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.9985, Val Loss=13.3518
Epoch [2/5]: Train Loss=9.5712, Val Loss=8.0820
Epoch [3/5]: Train Loss=5.5622, Val Loss=5.4803
Epoch [4/5]: Train Loss=3.4948, Val Loss=3.9405
Epoch [5/5]: Train Loss=2.3145, Val Loss=3.0186
Reservoir Test CPC Loss: 2.8470
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5886, Val Loss=2.6935
Epoch [2/5]: Train Loss=4.6755, Val Loss=2.6939
Epoch [3/5]: Train Loss=3.7594, Val Loss=2.6957
Epoch [4/5]: Train Loss=3.2000, Val Loss=2.6968
Epoch [5/5]: Train Loss=2.9385, Val Loss=2.6980
BERT Test CPC Loss: 2.6977

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=400.4528, Val Loss=4.7347
Epoch [2/5]: Train Loss=22.5690, Val Loss=3.8409
Epoch [3/5]: Train Loss=16.3950, Val Loss=3.2124
Epoch [4/5]: Train Loss=12.8416, Val Loss=3.1534
Epoch [5/5]: Train Loss=10.9215, Val Loss=3.1377
GPT2 Test CPC Loss: 3.1517
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0526, Val Loss=1.4611
Epoch [2/5]: Train Loss=0.8358, Val Loss=0.7550
Epoch [3/5]: Train Loss=0.2647, Val Loss=0.2459
Epoch [4/5]: Train Loss=0.0592, Val Loss=0.0899
Epoch [5/5]: Train Loss=0.0146, Val Loss=0.0640
LSTM Test CPC Loss: 0.0395
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.2695, Val Loss=16.5907
Epoch [2/5]: Train Loss=10.5445, Val Loss=9.7557
Epoch [3/5]: Train Loss=6.0218, Val Loss=6.3308
Epoch [4/5]: Train Loss=3.6958, Val Loss=4.4842
Epoch [5/5]: Train Loss=2.4076, Val Loss=3.3411
Reservoir Test CPC Loss: 2.7399
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5437, Val Loss=2.9910
Epoch [2/5]: Train Loss=4.6702, Val Loss=2.9914
Epoch [3/5]: Train Loss=3.8956, Val Loss=2.9922
Epoch [4/5]: Train Loss=3.4312, Val Loss=2.9925
Epoch [5/5]: Train Loss=3.1965, Val Loss=2.9927
BERT Test CPC Loss: 2.9924

--- Fish 12: Run 8 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=415.8390, Val Loss=7.9190
Epoch [2/5]: Train Loss=28.3245, Val Loss=4.9696
Epoch [3/5]: Train Loss=18.2861, Val Loss=4.5098
Epoch [4/5]: Train Loss=13.9003, Val Loss=3.4939
Epoch [5/5]: Train Loss=10.9457, Val Loss=3.0613
GPT2 Test CPC Loss: 3.0220
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7681, Val Loss=0.0717
Epoch [2/5]: Train Loss=0.0181, Val Loss=0.0063
Epoch [3/5]: Train Loss=0.0013, Val Loss=0.0037
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0027
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0021
LSTM Test CPC Loss: 0.0012
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.6979, Val Loss=3.2880
Epoch [2/5]: Train Loss=2.3806, Val Loss=1.9206
Epoch [3/5]: Train Loss=1.2848, Val Loss=1.3971
Epoch [4/5]: Train Loss=0.7909, Val Loss=1.0528
Epoch [5/5]: Train Loss=0.5131, Val Loss=0.9497
Reservoir Test CPC Loss: 1.0096
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9786, Val Loss=1.5433
Epoch [2/5]: Train Loss=4.9166, Val Loss=1.5476
Epoch [3/5]: Train Loss=3.8362, Val Loss=1.5698
Epoch [4/5]: Train Loss=3.0217, Val Loss=1.5420
Epoch [5/5]: Train Loss=2.4199, Val Loss=1.4951
BERT Test CPC Loss: 1.4966

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=352.7311, Val Loss=2.2891
Epoch [2/5]: Train Loss=22.5116, Val Loss=2.2322
Epoch [3/5]: Train Loss=14.2209, Val Loss=2.2135
Epoch [4/5]: Train Loss=10.5603, Val Loss=2.1982
Epoch [5/5]: Train Loss=8.4108, Val Loss=2.1941
GPT2 Test CPC Loss: 2.1929
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2426, Val Loss=0.4631
Epoch [2/5]: Train Loss=0.1314, Val Loss=0.0816
Epoch [3/5]: Train Loss=0.0095, Val Loss=0.0300
Epoch [4/5]: Train Loss=0.0026, Val Loss=0.0203
Epoch [5/5]: Train Loss=0.0013, Val Loss=0.0170
LSTM Test CPC Loss: 0.0132
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.3526, Val Loss=11.9065
Epoch [2/5]: Train Loss=9.0954, Val Loss=6.9625
Epoch [3/5]: Train Loss=5.2131, Val Loss=4.6414
Epoch [4/5]: Train Loss=3.2466, Val Loss=3.3906
Epoch [5/5]: Train Loss=2.1464, Val Loss=2.6409
Reservoir Test CPC Loss: 3.0025
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7697, Val Loss=2.2773
Epoch [2/5]: Train Loss=4.6718, Val Loss=2.2805
Epoch [3/5]: Train Loss=3.6888, Val Loss=2.2808
Epoch [4/5]: Train Loss=3.0041, Val Loss=2.2823
Epoch [5/5]: Train Loss=2.6207, Val Loss=2.2842
BERT Test CPC Loss: 2.2837

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=497.0201, Val Loss=3.5731
Epoch [2/5]: Train Loss=34.3373, Val Loss=2.8398
Epoch [3/5]: Train Loss=22.7729, Val Loss=2.6900
Epoch [4/5]: Train Loss=16.9394, Val Loss=2.6446
Epoch [5/5]: Train Loss=13.4516, Val Loss=2.6344
GPT2 Test CPC Loss: 2.6346
[Model: LSTM]
Epoch [1/5]: Train Loss=1.5422, Val Loss=0.8693
Epoch [2/5]: Train Loss=0.3429, Val Loss=0.2310
Epoch [3/5]: Train Loss=0.0368, Val Loss=0.0614
Epoch [4/5]: Train Loss=0.0058, Val Loss=0.0324
Epoch [5/5]: Train Loss=0.0025, Val Loss=0.0310
LSTM Test CPC Loss: 0.0186
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.2152, Val Loss=14.3924
Epoch [2/5]: Train Loss=9.6269, Val Loss=8.3874
Epoch [3/5]: Train Loss=5.6165, Val Loss=5.5282
Epoch [4/5]: Train Loss=3.5122, Val Loss=3.8801
Epoch [5/5]: Train Loss=2.3307, Val Loss=2.9392
Reservoir Test CPC Loss: 3.0674
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5349, Val Loss=2.6974
Epoch [2/5]: Train Loss=4.6769, Val Loss=2.6998
Epoch [3/5]: Train Loss=3.7931, Val Loss=2.7010
Epoch [4/5]: Train Loss=3.2586, Val Loss=2.7013
Epoch [5/5]: Train Loss=2.9759, Val Loss=2.7016
BERT Test CPC Loss: 2.7015

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=652.8951, Val Loss=4.6151
Epoch [2/5]: Train Loss=32.3244, Val Loss=3.1952
Epoch [3/5]: Train Loss=20.4915, Val Loss=2.9621
Epoch [4/5]: Train Loss=14.8814, Val Loss=2.9324
Epoch [5/5]: Train Loss=12.3024, Val Loss=2.9345
GPT2 Test CPC Loss: 2.9398
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7855, Val Loss=1.2364
Epoch [2/5]: Train Loss=0.6824, Val Loss=0.5523
Epoch [3/5]: Train Loss=0.1748, Val Loss=0.1810
Epoch [4/5]: Train Loss=0.0262, Val Loss=0.0808
Epoch [5/5]: Train Loss=0.0081, Val Loss=0.0444
LSTM Test CPC Loss: 0.0406
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.1287, Val Loss=14.5193
Epoch [2/5]: Train Loss=9.8105, Val Loss=8.2644
Epoch [3/5]: Train Loss=5.2405, Val Loss=5.1401
Epoch [4/5]: Train Loss=3.0824, Val Loss=3.6362
Epoch [5/5]: Train Loss=1.9610, Val Loss=2.6741
Reservoir Test CPC Loss: 2.6323
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9726, Val Loss=2.9897
Epoch [2/5]: Train Loss=4.7884, Val Loss=2.9901
Epoch [3/5]: Train Loss=3.9890, Val Loss=2.9911
Epoch [4/5]: Train Loss=3.4963, Val Loss=2.9912
Epoch [5/5]: Train Loss=3.2319, Val Loss=2.9919
BERT Test CPC Loss: 2.9914

--- Fish 12: Run 9 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=486.6108, Val Loss=2.1114
Epoch [2/5]: Train Loss=32.2052, Val Loss=1.9163
Epoch [3/5]: Train Loss=21.5470, Val Loss=1.9436
Epoch [4/5]: Train Loss=17.0273, Val Loss=1.8864
Epoch [5/5]: Train Loss=13.9409, Val Loss=1.8832
GPT2 Test CPC Loss: 1.8364
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6618, Val Loss=0.0531
Epoch [2/5]: Train Loss=0.0086, Val Loss=0.0026
Epoch [3/5]: Train Loss=0.0008, Val Loss=0.0013
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0009
Epoch [5/5]: Train Loss=0.0002, Val Loss=0.0007
LSTM Test CPC Loss: 0.0005
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.2718, Val Loss=3.8666
Epoch [2/5]: Train Loss=2.4513, Val Loss=2.2128
Epoch [3/5]: Train Loss=1.2468, Val Loss=1.5416
Epoch [4/5]: Train Loss=0.7223, Val Loss=1.1931
Epoch [5/5]: Train Loss=0.4358, Val Loss=1.0054
Reservoir Test CPC Loss: 1.0505
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2120, Val Loss=1.5216
Epoch [2/5]: Train Loss=4.8571, Val Loss=1.5393
Epoch [3/5]: Train Loss=3.8855, Val Loss=1.5699
Epoch [4/5]: Train Loss=3.1489, Val Loss=1.5684
Epoch [5/5]: Train Loss=2.5789, Val Loss=1.5108
BERT Test CPC Loss: 1.5132

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=364.4083, Val Loss=8.2732
Epoch [2/5]: Train Loss=25.2074, Val Loss=3.2701
Epoch [3/5]: Train Loss=17.9411, Val Loss=3.0391
Epoch [4/5]: Train Loss=13.9314, Val Loss=2.8130
Epoch [5/5]: Train Loss=11.2855, Val Loss=2.7436
GPT2 Test CPC Loss: 2.7037
[Model: LSTM]
Epoch [1/5]: Train Loss=0.9685, Val Loss=0.3358
Epoch [2/5]: Train Loss=0.0893, Val Loss=0.0743
Epoch [3/5]: Train Loss=0.0087, Val Loss=0.0352
Epoch [4/5]: Train Loss=0.0025, Val Loss=0.0200
Epoch [5/5]: Train Loss=0.0012, Val Loss=0.0182
LSTM Test CPC Loss: 0.0329
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.7871, Val Loss=10.7096
Epoch [2/5]: Train Loss=7.1113, Val Loss=6.2822
Epoch [3/5]: Train Loss=3.9448, Val Loss=4.1469
Epoch [4/5]: Train Loss=2.4058, Val Loss=2.9762
Epoch [5/5]: Train Loss=1.5659, Val Loss=2.3260
Reservoir Test CPC Loss: 2.7942
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8292, Val Loss=2.2766
Epoch [2/5]: Train Loss=4.6878, Val Loss=2.2785
Epoch [3/5]: Train Loss=3.7453, Val Loss=2.2793
Epoch [4/5]: Train Loss=3.1004, Val Loss=2.2812
Epoch [5/5]: Train Loss=2.7007, Val Loss=2.2816
BERT Test CPC Loss: 2.2809

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=397.6453, Val Loss=2.7902
Epoch [2/5]: Train Loss=21.1704, Val Loss=2.6544
Epoch [3/5]: Train Loss=15.0425, Val Loss=2.6169
Epoch [4/5]: Train Loss=12.0218, Val Loss=2.6216
Epoch [5/5]: Train Loss=10.2688, Val Loss=2.6953
GPT2 Test CPC Loss: 2.6946
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7938, Val Loss=1.0046
Epoch [2/5]: Train Loss=0.5076, Val Loss=0.3003
Epoch [3/5]: Train Loss=0.0699, Val Loss=0.0687
Epoch [4/5]: Train Loss=0.0097, Val Loss=0.0372
Epoch [5/5]: Train Loss=0.0034, Val Loss=0.0195
LSTM Test CPC Loss: 0.0138
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.2542, Val Loss=13.6936
Epoch [2/5]: Train Loss=9.4948, Val Loss=7.9531
Epoch [3/5]: Train Loss=5.2709, Val Loss=5.1471
Epoch [4/5]: Train Loss=3.1894, Val Loss=3.6458
Epoch [5/5]: Train Loss=2.0554, Val Loss=2.6738
Reservoir Test CPC Loss: 2.7789
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5021, Val Loss=2.6971
Epoch [2/5]: Train Loss=4.7141, Val Loss=2.6970
Epoch [3/5]: Train Loss=3.8554, Val Loss=2.6968
Epoch [4/5]: Train Loss=3.3188, Val Loss=2.6975
Epoch [5/5]: Train Loss=3.0229, Val Loss=2.6975
BERT Test CPC Loss: 2.6973

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=256.5374, Val Loss=3.0673
Epoch [2/5]: Train Loss=17.6425, Val Loss=3.0052
Epoch [3/5]: Train Loss=11.9135, Val Loss=2.9669
Epoch [4/5]: Train Loss=9.3262, Val Loss=2.9578
Epoch [5/5]: Train Loss=7.6937, Val Loss=2.9512
GPT2 Test CPC Loss: 2.9492
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0351, Val Loss=1.4197
Epoch [2/5]: Train Loss=0.7568, Val Loss=0.7059
Epoch [3/5]: Train Loss=0.2416, Val Loss=0.2348
Epoch [4/5]: Train Loss=0.0476, Val Loss=0.0880
Epoch [5/5]: Train Loss=0.0081, Val Loss=0.0276
LSTM Test CPC Loss: 0.0219
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.1058, Val Loss=14.9572
Epoch [2/5]: Train Loss=9.7599, Val Loss=8.4628
Epoch [3/5]: Train Loss=5.3844, Val Loss=5.3415
Epoch [4/5]: Train Loss=3.2101, Val Loss=3.7078
Epoch [5/5]: Train Loss=2.0615, Val Loss=2.7534
Reservoir Test CPC Loss: 2.9521
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.7084, Val Loss=2.9868
Epoch [2/5]: Train Loss=4.6929, Val Loss=2.9890
Epoch [3/5]: Train Loss=3.8958, Val Loss=2.9907
Epoch [4/5]: Train Loss=3.4067, Val Loss=2.9912
Epoch [5/5]: Train Loss=3.1801, Val Loss=2.9922
BERT Test CPC Loss: 2.9921

--- Fish 12: Run 10 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=515.0665, Val Loss=2.1837
Epoch [2/5]: Train Loss=39.2899, Val Loss=3.8671
Epoch [3/5]: Train Loss=25.0114, Val Loss=3.5736
Epoch [4/5]: Train Loss=17.8947, Val Loss=2.6781
Epoch [5/5]: Train Loss=13.5053, Val Loss=2.7823
GPT2 Test CPC Loss: 2.7810
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7624, Val Loss=0.0948
Epoch [2/5]: Train Loss=0.0205, Val Loss=0.0099
Epoch [3/5]: Train Loss=0.0015, Val Loss=0.0025
Epoch [4/5]: Train Loss=0.0007, Val Loss=0.0017
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0014
LSTM Test CPC Loss: 0.0019
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.7509, Val Loss=3.9158
Epoch [2/5]: Train Loss=2.3293, Val Loss=2.4516
Epoch [3/5]: Train Loss=1.2442, Val Loss=1.8982
Epoch [4/5]: Train Loss=0.7721, Val Loss=1.6082
Epoch [5/5]: Train Loss=0.5068, Val Loss=1.4324
Reservoir Test CPC Loss: 1.0891
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2536, Val Loss=1.5113
Epoch [2/5]: Train Loss=4.8662, Val Loss=1.5531
Epoch [3/5]: Train Loss=3.8677, Val Loss=1.6354
Epoch [4/5]: Train Loss=3.1550, Val Loss=1.6101
Epoch [5/5]: Train Loss=2.6475, Val Loss=1.5366
BERT Test CPC Loss: 1.5428

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=266.1851, Val Loss=2.2622
Epoch [2/5]: Train Loss=17.8267, Val Loss=2.2355
Epoch [3/5]: Train Loss=12.6517, Val Loss=2.2261
Epoch [4/5]: Train Loss=9.9721, Val Loss=2.2246
Epoch [5/5]: Train Loss=8.0617, Val Loss=2.2250
GPT2 Test CPC Loss: 2.2239
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3791, Val Loss=0.6152
Epoch [2/5]: Train Loss=0.2051, Val Loss=0.1339
Epoch [3/5]: Train Loss=0.0229, Val Loss=0.0494
Epoch [4/5]: Train Loss=0.0044, Val Loss=0.0244
Epoch [5/5]: Train Loss=0.0021, Val Loss=0.0225
LSTM Test CPC Loss: 0.0163
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.0873, Val Loss=10.4395
Epoch [2/5]: Train Loss=7.9004, Val Loss=6.5019
Epoch [3/5]: Train Loss=4.6061, Val Loss=4.3495
Epoch [4/5]: Train Loss=2.9057, Val Loss=3.1894
Epoch [5/5]: Train Loss=1.9374, Val Loss=2.4870
Reservoir Test CPC Loss: 2.5857
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.5474, Val Loss=2.2807
Epoch [2/5]: Train Loss=4.6785, Val Loss=2.2805
Epoch [3/5]: Train Loss=3.7501, Val Loss=2.2796
Epoch [4/5]: Train Loss=3.0759, Val Loss=2.2776
Epoch [5/5]: Train Loss=2.6823, Val Loss=2.2780
BERT Test CPC Loss: 2.2774

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=802.4212, Val Loss=13.5755
Epoch [2/5]: Train Loss=42.3498, Val Loss=8.8836
Epoch [3/5]: Train Loss=27.8669, Val Loss=7.0150
Epoch [4/5]: Train Loss=21.6917, Val Loss=7.0839
Epoch [5/5]: Train Loss=17.9992, Val Loss=7.9865
GPT2 Test CPC Loss: 9.3958
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7099, Val Loss=1.0778
Epoch [2/5]: Train Loss=0.5290, Val Loss=0.3067
Epoch [3/5]: Train Loss=0.0819, Val Loss=0.0961
Epoch [4/5]: Train Loss=0.0107, Val Loss=0.0487
Epoch [5/5]: Train Loss=0.0037, Val Loss=0.0336
LSTM Test CPC Loss: 0.0265
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.0945, Val Loss=13.6211
Epoch [2/5]: Train Loss=9.6356, Val Loss=7.7859
Epoch [3/5]: Train Loss=5.4104, Val Loss=5.0343
Epoch [4/5]: Train Loss=3.3383, Val Loss=3.5414
Epoch [5/5]: Train Loss=2.1777, Val Loss=2.6513
Reservoir Test CPC Loss: 3.0037
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.6855, Val Loss=2.6927
Epoch [2/5]: Train Loss=4.7433, Val Loss=2.6936
Epoch [3/5]: Train Loss=3.8288, Val Loss=2.6953
Epoch [4/5]: Train Loss=3.2581, Val Loss=2.6964
Epoch [5/5]: Train Loss=2.9712, Val Loss=2.6977
BERT Test CPC Loss: 2.6972

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=341.1473, Val Loss=3.1947
Epoch [2/5]: Train Loss=20.7452, Val Loss=2.9360
Epoch [3/5]: Train Loss=14.1993, Val Loss=2.9216
Epoch [4/5]: Train Loss=11.1352, Val Loss=2.9066
Epoch [5/5]: Train Loss=9.2055, Val Loss=2.9146
GPT2 Test CPC Loss: 2.9081
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8081, Val Loss=1.3104
Epoch [2/5]: Train Loss=0.6535, Val Loss=0.4996
Epoch [3/5]: Train Loss=0.1274, Val Loss=0.1293
Epoch [4/5]: Train Loss=0.0184, Val Loss=0.0589
Epoch [5/5]: Train Loss=0.0051, Val Loss=0.0440
LSTM Test CPC Loss: 0.0391
[Model: Reservoir]
Epoch [1/5]: Train Loss=26.0568, Val Loss=16.4817
Epoch [2/5]: Train Loss=11.6205, Val Loss=10.2064
Epoch [3/5]: Train Loss=6.6747, Val Loss=6.7470
Epoch [4/5]: Train Loss=4.0920, Val Loss=4.8574
Epoch [5/5]: Train Loss=2.6625, Val Loss=3.6106
Reservoir Test CPC Loss: 3.2734
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.4602, Val Loss=2.9889
Epoch [2/5]: Train Loss=4.6907, Val Loss=2.9895
Epoch [3/5]: Train Loss=3.8523, Val Loss=2.9906
Epoch [4/5]: Train Loss=3.3720, Val Loss=2.9914
Epoch [5/5]: Train Loss=3.1692, Val Loss=2.9917
BERT Test CPC Loss: 2.9914

========== Processing Fish 13 ==========
Fish 13: Neural data shape: (2793, 9336)

--- Fish 13: Run 1 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=433.1274, Val Loss=5.4601
Epoch [2/5]: Train Loss=33.2159, Val Loss=2.4732
Epoch [3/5]: Train Loss=17.3949, Val Loss=1.7980
Epoch [4/5]: Train Loss=11.7596, Val Loss=1.5899
Epoch [5/5]: Train Loss=9.2238, Val Loss=1.4952
GPT2 Test CPC Loss: 1.4487
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5857, Val Loss=0.0349
Epoch [2/5]: Train Loss=0.0070, Val Loss=0.0066
Epoch [3/5]: Train Loss=0.0010, Val Loss=0.0032
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0024
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0020
LSTM Test CPC Loss: 0.0013
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.0199, Val Loss=3.6792
Epoch [2/5]: Train Loss=2.5277, Val Loss=1.7542
Epoch [3/5]: Train Loss=1.3493, Val Loss=1.1360
Epoch [4/5]: Train Loss=0.8415, Val Loss=0.8116
Epoch [5/5]: Train Loss=0.5530, Val Loss=0.6795
Reservoir Test CPC Loss: 1.4027
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.6071, Val Loss=1.6153
Epoch [2/5]: Train Loss=4.8736, Val Loss=1.7320
Epoch [3/5]: Train Loss=3.8069, Val Loss=1.7759
Epoch [4/5]: Train Loss=3.0545, Val Loss=1.7159
Epoch [5/5]: Train Loss=2.4867, Val Loss=1.5349
BERT Test CPC Loss: 1.5186

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=484.4493, Val Loss=9.3764
Epoch [2/5]: Train Loss=35.1647, Val Loss=3.2208
Epoch [3/5]: Train Loss=22.3816, Val Loss=2.3629
Epoch [4/5]: Train Loss=16.4655, Val Loss=2.2535
Epoch [5/5]: Train Loss=13.0280, Val Loss=2.2323
GPT2 Test CPC Loss: 2.2161
[Model: LSTM]
Epoch [1/5]: Train Loss=1.4172, Val Loss=0.6074
Epoch [2/5]: Train Loss=0.1902, Val Loss=0.0864
Epoch [3/5]: Train Loss=0.0170, Val Loss=0.0299
Epoch [4/5]: Train Loss=0.0042, Val Loss=0.0210
Epoch [5/5]: Train Loss=0.0019, Val Loss=0.0149
LSTM Test CPC Loss: 0.0286
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.3034, Val Loss=10.6946
Epoch [2/5]: Train Loss=7.2234, Val Loss=5.8722
Epoch [3/5]: Train Loss=3.8475, Val Loss=3.7384
Epoch [4/5]: Train Loss=2.2977, Val Loss=2.6286
Epoch [5/5]: Train Loss=1.4604, Val Loss=2.0177
Reservoir Test CPC Loss: 2.4375
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9781, Val Loss=2.2769
Epoch [2/5]: Train Loss=4.7340, Val Loss=2.2767
Epoch [3/5]: Train Loss=3.8242, Val Loss=2.2790
Epoch [4/5]: Train Loss=3.1760, Val Loss=2.2796
Epoch [5/5]: Train Loss=2.7389, Val Loss=2.2810
BERT Test CPC Loss: 2.2823

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=363.3503, Val Loss=2.7209
Epoch [2/5]: Train Loss=21.6078, Val Loss=2.6179
Epoch [3/5]: Train Loss=15.5054, Val Loss=2.6361
Epoch [4/5]: Train Loss=12.4800, Val Loss=2.6320
Epoch [5/5]: Train Loss=10.5319, Val Loss=2.6304
GPT2 Test CPC Loss: 2.6223
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7566, Val Loss=1.0310
Epoch [2/5]: Train Loss=0.4800, Val Loss=0.2706
Epoch [3/5]: Train Loss=0.0679, Val Loss=0.0881
Epoch [4/5]: Train Loss=0.0101, Val Loss=0.0431
Epoch [5/5]: Train Loss=0.0037, Val Loss=0.0294
LSTM Test CPC Loss: 0.0402
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.1502, Val Loss=15.4062
Epoch [2/5]: Train Loss=9.2409, Val Loss=8.7631
Epoch [3/5]: Train Loss=4.9977, Val Loss=5.6233
Epoch [4/5]: Train Loss=2.9492, Val Loss=3.8877
Epoch [5/5]: Train Loss=1.8705, Val Loss=2.8749
Reservoir Test CPC Loss: 3.4338
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8817, Val Loss=2.6987
Epoch [2/5]: Train Loss=4.6889, Val Loss=2.6969
Epoch [3/5]: Train Loss=3.8491, Val Loss=2.6956
Epoch [4/5]: Train Loss=3.3327, Val Loss=2.6950
Epoch [5/5]: Train Loss=3.0349, Val Loss=2.6950
BERT Test CPC Loss: 2.6957

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=332.9822, Val Loss=3.0446
Epoch [2/5]: Train Loss=18.9923, Val Loss=2.9448
Epoch [3/5]: Train Loss=13.5743, Val Loss=2.9693
Epoch [4/5]: Train Loss=11.0373, Val Loss=2.9493
Epoch [5/5]: Train Loss=9.2658, Val Loss=2.9327
GPT2 Test CPC Loss: 2.9068
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9997, Val Loss=1.3239
Epoch [2/5]: Train Loss=0.6943, Val Loss=0.5139
Epoch [3/5]: Train Loss=0.1368, Val Loss=0.1321
Epoch [4/5]: Train Loss=0.0204, Val Loss=0.0594
Epoch [5/5]: Train Loss=0.0063, Val Loss=0.0380
LSTM Test CPC Loss: 0.0822
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.4591, Val Loss=16.6640
Epoch [2/5]: Train Loss=10.4559, Val Loss=8.5367
Epoch [3/5]: Train Loss=5.3736, Val Loss=4.9405
Epoch [4/5]: Train Loss=3.0566, Val Loss=3.1627
Epoch [5/5]: Train Loss=1.9017, Val Loss=2.2662
Reservoir Test CPC Loss: 3.0573
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0345, Val Loss=2.9885
Epoch [2/5]: Train Loss=4.8042, Val Loss=2.9900
Epoch [3/5]: Train Loss=4.0113, Val Loss=2.9912
Epoch [4/5]: Train Loss=3.5101, Val Loss=2.9912
Epoch [5/5]: Train Loss=3.2356, Val Loss=2.9913
BERT Test CPC Loss: 2.9914

--- Fish 13: Run 2 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=426.2771, Val Loss=1.5530
Epoch [2/5]: Train Loss=25.1402, Val Loss=1.5760
Epoch [3/5]: Train Loss=17.0510, Val Loss=1.9305
Epoch [4/5]: Train Loss=12.8235, Val Loss=1.9435
Epoch [5/5]: Train Loss=10.2658, Val Loss=2.0015
GPT2 Test CPC Loss: 1.9716
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7447, Val Loss=0.0807
Epoch [2/5]: Train Loss=0.0131, Val Loss=0.0072
Epoch [3/5]: Train Loss=0.0013, Val Loss=0.0038
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0028
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0021
LSTM Test CPC Loss: 0.0022
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.0071, Val Loss=4.3970
Epoch [2/5]: Train Loss=2.8199, Val Loss=2.2945
Epoch [3/5]: Train Loss=1.4953, Val Loss=1.5037
Epoch [4/5]: Train Loss=0.8715, Val Loss=1.1307
Epoch [5/5]: Train Loss=0.5334, Val Loss=0.9639
Reservoir Test CPC Loss: 2.0098
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1042, Val Loss=1.5131
Epoch [2/5]: Train Loss=4.8537, Val Loss=1.6166
Epoch [3/5]: Train Loss=3.8322, Val Loss=1.6752
Epoch [4/5]: Train Loss=3.1207, Val Loss=1.6678
Epoch [5/5]: Train Loss=2.5625, Val Loss=1.5547
BERT Test CPC Loss: 1.5336

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=443.3654, Val Loss=13.8310
Epoch [2/5]: Train Loss=28.8460, Val Loss=11.2468
Epoch [3/5]: Train Loss=19.5693, Val Loss=12.1785
Epoch [4/5]: Train Loss=15.3236, Val Loss=10.3318
Epoch [5/5]: Train Loss=12.1360, Val Loss=12.4764
GPT2 Test CPC Loss: 10.4260
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3833, Val Loss=0.5914
Epoch [2/5]: Train Loss=0.1905, Val Loss=0.0920
Epoch [3/5]: Train Loss=0.0173, Val Loss=0.0661
Epoch [4/5]: Train Loss=0.0041, Val Loss=0.0525
Epoch [5/5]: Train Loss=0.0021, Val Loss=0.0316
LSTM Test CPC Loss: 0.0399
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.7413, Val Loss=11.1667
Epoch [2/5]: Train Loss=7.9143, Val Loss=6.0391
Epoch [3/5]: Train Loss=4.2036, Val Loss=3.8310
Epoch [4/5]: Train Loss=2.4678, Val Loss=2.7589
Epoch [5/5]: Train Loss=1.5639, Val Loss=2.0914
Reservoir Test CPC Loss: 2.6977
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2764, Val Loss=2.2693
Epoch [2/5]: Train Loss=4.7974, Val Loss=2.2740
Epoch [3/5]: Train Loss=3.8239, Val Loss=2.2757
Epoch [4/5]: Train Loss=3.0829, Val Loss=2.2747
Epoch [5/5]: Train Loss=2.6431, Val Loss=2.2760
BERT Test CPC Loss: 2.2775

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=345.4824, Val Loss=5.2736
Epoch [2/5]: Train Loss=19.3928, Val Loss=4.2093
Epoch [3/5]: Train Loss=13.3261, Val Loss=3.9415
Epoch [4/5]: Train Loss=10.5375, Val Loss=3.7113
Epoch [5/5]: Train Loss=8.8119, Val Loss=3.8142
GPT2 Test CPC Loss: 3.3394
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6385, Val Loss=0.7958
Epoch [2/5]: Train Loss=0.3333, Val Loss=0.1951
Epoch [3/5]: Train Loss=0.0421, Val Loss=0.0572
Epoch [4/5]: Train Loss=0.0090, Val Loss=0.0237
Epoch [5/5]: Train Loss=0.0033, Val Loss=0.0198
LSTM Test CPC Loss: 0.0433
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.9818, Val Loss=15.3197
Epoch [2/5]: Train Loss=8.8703, Val Loss=8.3548
Epoch [3/5]: Train Loss=4.7663, Val Loss=5.1017
Epoch [4/5]: Train Loss=2.8118, Val Loss=3.4775
Epoch [5/5]: Train Loss=1.7761, Val Loss=2.5400
Reservoir Test CPC Loss: 3.1376
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9743, Val Loss=2.6895
Epoch [2/5]: Train Loss=4.6954, Val Loss=2.6893
Epoch [3/5]: Train Loss=3.8300, Val Loss=2.6926
Epoch [4/5]: Train Loss=3.2611, Val Loss=2.6937
Epoch [5/5]: Train Loss=2.9698, Val Loss=2.6956
BERT Test CPC Loss: 2.6965

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=305.2770, Val Loss=2.9821
Epoch [2/5]: Train Loss=19.6329, Val Loss=2.9261
Epoch [3/5]: Train Loss=13.5348, Val Loss=2.9275
Epoch [4/5]: Train Loss=10.5916, Val Loss=2.9282
Epoch [5/5]: Train Loss=8.8011, Val Loss=2.9337
GPT2 Test CPC Loss: 2.9172
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9443, Val Loss=1.3295
Epoch [2/5]: Train Loss=0.7051, Val Loss=0.4363
Epoch [3/5]: Train Loss=0.1491, Val Loss=0.1055
Epoch [4/5]: Train Loss=0.0274, Val Loss=0.0425
Epoch [5/5]: Train Loss=0.0078, Val Loss=0.0259
LSTM Test CPC Loss: 0.0404
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.1490, Val Loss=14.5880
Epoch [2/5]: Train Loss=9.7525, Val Loss=7.7456
Epoch [3/5]: Train Loss=5.1949, Val Loss=4.6722
Epoch [4/5]: Train Loss=3.0179, Val Loss=3.1260
Epoch [5/5]: Train Loss=1.8978, Val Loss=2.2212
Reservoir Test CPC Loss: 2.5890
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0643, Val Loss=2.9852
Epoch [2/5]: Train Loss=4.8107, Val Loss=2.9853
Epoch [3/5]: Train Loss=4.0151, Val Loss=2.9863
Epoch [4/5]: Train Loss=3.5410, Val Loss=2.9866
Epoch [5/5]: Train Loss=3.2728, Val Loss=2.9875
BERT Test CPC Loss: 2.9878

--- Fish 13: Run 3 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=297.6666, Val Loss=8.1918
Epoch [2/5]: Train Loss=24.3995, Val Loss=6.6168
Epoch [3/5]: Train Loss=15.2574, Val Loss=5.5471
Epoch [4/5]: Train Loss=11.3777, Val Loss=5.3287
Epoch [5/5]: Train Loss=8.6949, Val Loss=2.8072
GPT2 Test CPC Loss: 2.6338
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5863, Val Loss=0.0635
Epoch [2/5]: Train Loss=0.0083, Val Loss=0.0086
Epoch [3/5]: Train Loss=0.0023, Val Loss=0.0037
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0027
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0021
LSTM Test CPC Loss: 0.0046
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.5819, Val Loss=2.5775
Epoch [2/5]: Train Loss=2.1444, Val Loss=1.0144
Epoch [3/5]: Train Loss=0.9887, Val Loss=0.6926
Epoch [4/5]: Train Loss=0.5477, Val Loss=0.5039
Epoch [5/5]: Train Loss=0.3069, Val Loss=0.4606
Reservoir Test CPC Loss: 0.8860
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3469, Val Loss=1.5687
Epoch [2/5]: Train Loss=4.8540, Val Loss=1.6802
Epoch [3/5]: Train Loss=3.8674, Val Loss=1.7825
Epoch [4/5]: Train Loss=3.1669, Val Loss=1.7228
Epoch [5/5]: Train Loss=2.6569, Val Loss=1.5785
BERT Test CPC Loss: 1.5540

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=420.9040, Val Loss=3.0956
Epoch [2/5]: Train Loss=26.5842, Val Loss=2.2986
Epoch [3/5]: Train Loss=14.6346, Val Loss=2.2220
Epoch [4/5]: Train Loss=10.5046, Val Loss=2.2018
Epoch [5/5]: Train Loss=8.3656, Val Loss=2.1977
GPT2 Test CPC Loss: 2.1945
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2660, Val Loss=0.4648
Epoch [2/5]: Train Loss=0.1635, Val Loss=0.0885
Epoch [3/5]: Train Loss=0.0162, Val Loss=0.0301
Epoch [4/5]: Train Loss=0.0046, Val Loss=0.0174
Epoch [5/5]: Train Loss=0.0022, Val Loss=0.0128
LSTM Test CPC Loss: 0.0401
[Model: Reservoir]
Epoch [1/5]: Train Loss=15.6602, Val Loss=11.0026
Epoch [2/5]: Train Loss=6.5833, Val Loss=5.8426
Epoch [3/5]: Train Loss=3.6039, Val Loss=3.6331
Epoch [4/5]: Train Loss=2.1260, Val Loss=2.5041
Epoch [5/5]: Train Loss=1.3604, Val Loss=1.8514
Reservoir Test CPC Loss: 2.8351
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.4669, Val Loss=2.2714
Epoch [2/5]: Train Loss=4.8798, Val Loss=2.2743
Epoch [3/5]: Train Loss=3.8999, Val Loss=2.2763
Epoch [4/5]: Train Loss=3.1657, Val Loss=2.2783
Epoch [5/5]: Train Loss=2.6954, Val Loss=2.2805
BERT Test CPC Loss: 2.2817

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=323.6206, Val Loss=6.6566
Epoch [2/5]: Train Loss=19.8975, Val Loss=3.6884
Epoch [3/5]: Train Loss=14.1430, Val Loss=3.1586
Epoch [4/5]: Train Loss=11.2257, Val Loss=2.8870
Epoch [5/5]: Train Loss=9.5305, Val Loss=2.8016
GPT2 Test CPC Loss: 2.8018
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8248, Val Loss=0.9708
Epoch [2/5]: Train Loss=0.5016, Val Loss=0.2305
Epoch [3/5]: Train Loss=0.0621, Val Loss=0.0428
Epoch [4/5]: Train Loss=0.0078, Val Loss=0.0208
Epoch [5/5]: Train Loss=0.0029, Val Loss=0.0141
LSTM Test CPC Loss: 0.0392
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.2794, Val Loss=13.5155
Epoch [2/5]: Train Loss=8.6580, Val Loss=7.2711
Epoch [3/5]: Train Loss=4.5852, Val Loss=4.4434
Epoch [4/5]: Train Loss=2.6759, Val Loss=2.9927
Epoch [5/5]: Train Loss=1.6907, Val Loss=2.1856
Reservoir Test CPC Loss: 3.4891
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1391, Val Loss=2.6935
Epoch [2/5]: Train Loss=4.7600, Val Loss=2.6948
Epoch [3/5]: Train Loss=3.8560, Val Loss=2.6957
Epoch [4/5]: Train Loss=3.2803, Val Loss=2.6972
Epoch [5/5]: Train Loss=2.9817, Val Loss=2.6977
BERT Test CPC Loss: 2.6984

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=358.5532, Val Loss=2.9157
Epoch [2/5]: Train Loss=17.1430, Val Loss=2.9286
Epoch [3/5]: Train Loss=12.6284, Val Loss=2.9583
Epoch [4/5]: Train Loss=10.2540, Val Loss=2.9467
Epoch [5/5]: Train Loss=8.8649, Val Loss=2.9928
GPT2 Test CPC Loss: 2.9621
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9477, Val Loss=1.3798
Epoch [2/5]: Train Loss=0.7267, Val Loss=0.4219
Epoch [3/5]: Train Loss=0.1394, Val Loss=0.0905
Epoch [4/5]: Train Loss=0.0194, Val Loss=0.0356
Epoch [5/5]: Train Loss=0.0060, Val Loss=0.0228
LSTM Test CPC Loss: 0.0647
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.8347, Val Loss=18.1483
Epoch [2/5]: Train Loss=9.9304, Val Loss=9.5304
Epoch [3/5]: Train Loss=5.0890, Val Loss=5.8175
Epoch [4/5]: Train Loss=2.9077, Val Loss=3.7275
Epoch [5/5]: Train Loss=1.8178, Val Loss=2.7186
Reservoir Test CPC Loss: 3.5506
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8904, Val Loss=2.9837
Epoch [2/5]: Train Loss=4.7605, Val Loss=2.9849
Epoch [3/5]: Train Loss=3.9581, Val Loss=2.9859
Epoch [4/5]: Train Loss=3.4809, Val Loss=2.9869
Epoch [5/5]: Train Loss=3.2382, Val Loss=2.9874
BERT Test CPC Loss: 2.9878

--- Fish 13: Run 4 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=334.4291, Val Loss=18.2662
Epoch [2/5]: Train Loss=29.9840, Val Loss=3.0926
Epoch [3/5]: Train Loss=18.6366, Val Loss=1.4288
Epoch [4/5]: Train Loss=14.1578, Val Loss=1.3712
Epoch [5/5]: Train Loss=10.9526, Val Loss=1.3699
GPT2 Test CPC Loss: 1.3749
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7858, Val Loss=0.1082
Epoch [2/5]: Train Loss=0.0228, Val Loss=0.0112
Epoch [3/5]: Train Loss=0.0020, Val Loss=0.0051
Epoch [4/5]: Train Loss=0.0008, Val Loss=0.0041
Epoch [5/5]: Train Loss=0.0005, Val Loss=0.0028
LSTM Test CPC Loss: 0.0018
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.6012, Val Loss=3.6878
Epoch [2/5]: Train Loss=2.2364, Val Loss=1.8675
Epoch [3/5]: Train Loss=1.0801, Val Loss=1.1914
Epoch [4/5]: Train Loss=0.6230, Val Loss=0.9756
Epoch [5/5]: Train Loss=0.3758, Val Loss=0.8291
Reservoir Test CPC Loss: 1.3192
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.9411, Val Loss=1.5605
Epoch [2/5]: Train Loss=4.9286, Val Loss=1.5981
Epoch [3/5]: Train Loss=3.9085, Val Loss=1.6845
Epoch [4/5]: Train Loss=3.2063, Val Loss=1.6680
Epoch [5/5]: Train Loss=2.6300, Val Loss=1.5562
BERT Test CPC Loss: 1.5364

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=361.0224, Val Loss=2.7961
Epoch [2/5]: Train Loss=20.4114, Val Loss=2.3291
Epoch [3/5]: Train Loss=14.3322, Val Loss=2.2613
Epoch [4/5]: Train Loss=11.4988, Val Loss=2.2818
Epoch [5/5]: Train Loss=9.5032, Val Loss=2.2549
GPT2 Test CPC Loss: 2.2530
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2065, Val Loss=0.4570
Epoch [2/5]: Train Loss=0.1393, Val Loss=0.0757
Epoch [3/5]: Train Loss=0.0133, Val Loss=0.0287
Epoch [4/5]: Train Loss=0.0034, Val Loss=0.0186
Epoch [5/5]: Train Loss=0.0017, Val Loss=0.0142
LSTM Test CPC Loss: 0.0160
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.0217, Val Loss=13.0479
Epoch [2/5]: Train Loss=7.9340, Val Loss=6.9346
Epoch [3/5]: Train Loss=4.3635, Val Loss=4.2625
Epoch [4/5]: Train Loss=2.6249, Val Loss=2.8274
Epoch [5/5]: Train Loss=1.6842, Val Loss=2.0570
Reservoir Test CPC Loss: 2.8782
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0354, Val Loss=2.2717
Epoch [2/5]: Train Loss=4.7442, Val Loss=2.2720
Epoch [3/5]: Train Loss=3.8519, Val Loss=2.2738
Epoch [4/5]: Train Loss=3.1846, Val Loss=2.2741
Epoch [5/5]: Train Loss=2.7400, Val Loss=2.2741
BERT Test CPC Loss: 2.2753

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=420.8202, Val Loss=3.0103
Epoch [2/5]: Train Loss=21.0900, Val Loss=2.8258
Epoch [3/5]: Train Loss=15.4386, Val Loss=2.7390
Epoch [4/5]: Train Loss=12.6146, Val Loss=2.7313
Epoch [5/5]: Train Loss=10.8143, Val Loss=2.7195
GPT2 Test CPC Loss: 2.7045
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6230, Val Loss=0.8965
Epoch [2/5]: Train Loss=0.3728, Val Loss=0.1891
Epoch [3/5]: Train Loss=0.0400, Val Loss=0.0484
Epoch [4/5]: Train Loss=0.0069, Val Loss=0.0290
Epoch [5/5]: Train Loss=0.0027, Val Loss=0.0283
LSTM Test CPC Loss: 0.0405
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.1207, Val Loss=16.1488
Epoch [2/5]: Train Loss=9.6438, Val Loss=7.9995
Epoch [3/5]: Train Loss=4.9545, Val Loss=4.6172
Epoch [4/5]: Train Loss=2.8316, Val Loss=3.0908
Epoch [5/5]: Train Loss=1.7646, Val Loss=2.2568
Reservoir Test CPC Loss: 2.7148
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9667, Val Loss=2.6933
Epoch [2/5]: Train Loss=4.7616, Val Loss=2.6960
Epoch [3/5]: Train Loss=3.8748, Val Loss=2.6971
Epoch [4/5]: Train Loss=3.3182, Val Loss=2.6979
Epoch [5/5]: Train Loss=3.0035, Val Loss=2.6990
BERT Test CPC Loss: 2.6996

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=499.1075, Val Loss=3.0851
Epoch [2/5]: Train Loss=22.1204, Val Loss=3.0019
Epoch [3/5]: Train Loss=15.7625, Val Loss=3.0028
Epoch [4/5]: Train Loss=12.8024, Val Loss=2.9779
Epoch [5/5]: Train Loss=10.9858, Val Loss=2.9742
GPT2 Test CPC Loss: 2.9523
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6915, Val Loss=1.0530
Epoch [2/5]: Train Loss=0.5111, Val Loss=0.3063
Epoch [3/5]: Train Loss=0.0842, Val Loss=0.0768
Epoch [4/5]: Train Loss=0.0138, Val Loss=0.0381
Epoch [5/5]: Train Loss=0.0051, Val Loss=0.0267
LSTM Test CPC Loss: 0.0470
[Model: Reservoir]
Epoch [1/5]: Train Loss=24.2840, Val Loss=16.1497
Epoch [2/5]: Train Loss=9.4180, Val Loss=8.1286
Epoch [3/5]: Train Loss=4.8488, Val Loss=4.7288
Epoch [4/5]: Train Loss=2.7814, Val Loss=3.1016
Epoch [5/5]: Train Loss=1.7341, Val Loss=2.1899
Reservoir Test CPC Loss: 3.1068
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8094, Val Loss=2.9890
Epoch [2/5]: Train Loss=4.7350, Val Loss=2.9897
Epoch [3/5]: Train Loss=3.9454, Val Loss=2.9908
Epoch [4/5]: Train Loss=3.4647, Val Loss=2.9913
Epoch [5/5]: Train Loss=3.2189, Val Loss=2.9913
BERT Test CPC Loss: 2.9916

--- Fish 13: Run 5 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=415.5522, Val Loss=3.2400
Epoch [2/5]: Train Loss=35.3965, Val Loss=1.7757
Epoch [3/5]: Train Loss=23.5655, Val Loss=1.5883
Epoch [4/5]: Train Loss=17.5294, Val Loss=1.5635
Epoch [5/5]: Train Loss=13.9025, Val Loss=1.5236
GPT2 Test CPC Loss: 1.5106
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5792, Val Loss=0.0363
Epoch [2/5]: Train Loss=0.0065, Val Loss=0.0045
Epoch [3/5]: Train Loss=0.0009, Val Loss=0.0025
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0018
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0014
LSTM Test CPC Loss: 0.0026
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.8586, Val Loss=2.8486
Epoch [2/5]: Train Loss=2.2285, Val Loss=1.3646
Epoch [3/5]: Train Loss=1.1107, Val Loss=0.8392
Epoch [4/5]: Train Loss=0.6286, Val Loss=0.6328
Epoch [5/5]: Train Loss=0.3797, Val Loss=0.4973
Reservoir Test CPC Loss: 1.5689
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.7359, Val Loss=1.5767
Epoch [2/5]: Train Loss=5.0230, Val Loss=1.6260
Epoch [3/5]: Train Loss=4.0112, Val Loss=1.7065
Epoch [4/5]: Train Loss=3.2898, Val Loss=1.7147
Epoch [5/5]: Train Loss=2.7098, Val Loss=1.6096
BERT Test CPC Loss: 1.5845

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=411.3894, Val Loss=24.8057
Epoch [2/5]: Train Loss=32.8860, Val Loss=14.3976
Epoch [3/5]: Train Loss=21.9250, Val Loss=13.5643
Epoch [4/5]: Train Loss=16.6035, Val Loss=8.3268
Epoch [5/5]: Train Loss=13.0877, Val Loss=8.2115
GPT2 Test CPC Loss: 6.5187
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1915, Val Loss=0.3802
Epoch [2/5]: Train Loss=0.1149, Val Loss=0.0612
Epoch [3/5]: Train Loss=0.0092, Val Loss=0.0240
Epoch [4/5]: Train Loss=0.0025, Val Loss=0.0196
Epoch [5/5]: Train Loss=0.0014, Val Loss=0.0138
LSTM Test CPC Loss: 0.0189
[Model: Reservoir]
Epoch [1/5]: Train Loss=19.5093, Val Loss=11.4121
Epoch [2/5]: Train Loss=7.9239, Val Loss=6.1261
Epoch [3/5]: Train Loss=4.2856, Val Loss=3.6918
Epoch [4/5]: Train Loss=2.5359, Val Loss=2.5378
Epoch [5/5]: Train Loss=1.6048, Val Loss=1.8731
Reservoir Test CPC Loss: 2.6781
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0451, Val Loss=2.2687
Epoch [2/5]: Train Loss=4.7506, Val Loss=2.2700
Epoch [3/5]: Train Loss=3.8077, Val Loss=2.2686
Epoch [4/5]: Train Loss=3.1402, Val Loss=2.2654
Epoch [5/5]: Train Loss=2.7226, Val Loss=2.2648
BERT Test CPC Loss: 2.2662

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=501.6683, Val Loss=7.2911
Epoch [2/5]: Train Loss=29.1353, Val Loss=4.5361
Epoch [3/5]: Train Loss=20.5336, Val Loss=3.2565
Epoch [4/5]: Train Loss=15.6804, Val Loss=3.0352
Epoch [5/5]: Train Loss=12.9602, Val Loss=2.9452
GPT2 Test CPC Loss: 2.9038
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7740, Val Loss=0.9311
Epoch [2/5]: Train Loss=0.4017, Val Loss=0.2371
Epoch [3/5]: Train Loss=0.0486, Val Loss=0.0822
Epoch [4/5]: Train Loss=0.0086, Val Loss=0.0482
Epoch [5/5]: Train Loss=0.0034, Val Loss=0.0323
LSTM Test CPC Loss: 0.0431
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.0126, Val Loss=15.2608
Epoch [2/5]: Train Loss=9.0639, Val Loss=8.1109
Epoch [3/5]: Train Loss=4.7117, Val Loss=4.9814
Epoch [4/5]: Train Loss=2.7156, Val Loss=3.4057
Epoch [5/5]: Train Loss=1.7100, Val Loss=2.5746
Reservoir Test CPC Loss: 2.9346
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0855, Val Loss=2.6920
Epoch [2/5]: Train Loss=4.8157, Val Loss=2.6920
Epoch [3/5]: Train Loss=3.9298, Val Loss=2.6932
Epoch [4/5]: Train Loss=3.3772, Val Loss=2.6939
Epoch [5/5]: Train Loss=3.0520, Val Loss=2.6949
BERT Test CPC Loss: 2.6959

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=368.7146, Val Loss=3.8814
Epoch [2/5]: Train Loss=21.9265, Val Loss=3.0672
Epoch [3/5]: Train Loss=16.4126, Val Loss=2.8976
Epoch [4/5]: Train Loss=13.6480, Val Loss=2.9045
Epoch [5/5]: Train Loss=11.5547, Val Loss=2.9068
GPT2 Test CPC Loss: 2.8859
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8692, Val Loss=1.1774
Epoch [2/5]: Train Loss=0.6095, Val Loss=0.4043
Epoch [3/5]: Train Loss=0.1099, Val Loss=0.1167
Epoch [4/5]: Train Loss=0.0153, Val Loss=0.0516
Epoch [5/5]: Train Loss=0.0053, Val Loss=0.0412
LSTM Test CPC Loss: 0.0621
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.2238, Val Loss=17.1690
Epoch [2/5]: Train Loss=9.6027, Val Loss=8.3724
Epoch [3/5]: Train Loss=4.7371, Val Loss=4.6544
Epoch [4/5]: Train Loss=2.6604, Val Loss=3.0477
Epoch [5/5]: Train Loss=1.6468, Val Loss=2.1274
Reservoir Test CPC Loss: 3.2632
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.8616, Val Loss=2.9896
Epoch [2/5]: Train Loss=4.7079, Val Loss=2.9888
Epoch [3/5]: Train Loss=3.9124, Val Loss=2.9893
Epoch [4/5]: Train Loss=3.4388, Val Loss=2.9901
Epoch [5/5]: Train Loss=3.2054, Val Loss=2.9907
BERT Test CPC Loss: 2.9909

--- Fish 13: Run 6 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=348.4253, Val Loss=3.7661
Epoch [2/5]: Train Loss=23.5651, Val Loss=2.5833
Epoch [3/5]: Train Loss=16.0169, Val Loss=2.5441
Epoch [4/5]: Train Loss=11.2235, Val Loss=1.7622
Epoch [5/5]: Train Loss=9.0212, Val Loss=1.9676
GPT2 Test CPC Loss: 1.9727
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6107, Val Loss=0.0579
Epoch [2/5]: Train Loss=0.0061, Val Loss=0.0095
Epoch [3/5]: Train Loss=0.0008, Val Loss=0.0063
Epoch [4/5]: Train Loss=0.0004, Val Loss=0.0044
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0039
LSTM Test CPC Loss: 0.0022
[Model: Reservoir]
Epoch [1/5]: Train Loss=10.4544, Val Loss=4.4243
Epoch [2/5]: Train Loss=2.6042, Val Loss=1.9366
Epoch [3/5]: Train Loss=1.2954, Val Loss=1.2859
Epoch [4/5]: Train Loss=0.7376, Val Loss=0.9816
Epoch [5/5]: Train Loss=0.4388, Val Loss=0.7980
Reservoir Test CPC Loss: 1.9253
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2088, Val Loss=1.6908
Epoch [2/5]: Train Loss=4.8107, Val Loss=1.8151
Epoch [3/5]: Train Loss=3.8209, Val Loss=1.7625
Epoch [4/5]: Train Loss=3.0800, Val Loss=1.7174
Epoch [5/5]: Train Loss=2.4823, Val Loss=1.5677
BERT Test CPC Loss: 1.5487

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=358.5497, Val Loss=2.3077
Epoch [2/5]: Train Loss=24.5585, Val Loss=2.2521
Epoch [3/5]: Train Loss=16.3743, Val Loss=2.2398
Epoch [4/5]: Train Loss=12.5955, Val Loss=2.2222
Epoch [5/5]: Train Loss=10.0128, Val Loss=2.2147
GPT2 Test CPC Loss: 2.2118
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3396, Val Loss=0.5536
Epoch [2/5]: Train Loss=0.1825, Val Loss=0.0887
Epoch [3/5]: Train Loss=0.0191, Val Loss=0.0365
Epoch [4/5]: Train Loss=0.0046, Val Loss=0.0226
Epoch [5/5]: Train Loss=0.0021, Val Loss=0.0190
LSTM Test CPC Loss: 0.0840
[Model: Reservoir]
Epoch [1/5]: Train Loss=17.7302, Val Loss=11.5958
Epoch [2/5]: Train Loss=6.8126, Val Loss=6.3381
Epoch [3/5]: Train Loss=3.6513, Val Loss=4.1545
Epoch [4/5]: Train Loss=2.1691, Val Loss=2.9820
Epoch [5/5]: Train Loss=1.3839, Val Loss=2.3171
Reservoir Test CPC Loss: 3.6221
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0197, Val Loss=2.2727
Epoch [2/5]: Train Loss=4.7255, Val Loss=2.2742
Epoch [3/5]: Train Loss=3.7723, Val Loss=2.2743
Epoch [4/5]: Train Loss=3.0395, Val Loss=2.2756
Epoch [5/5]: Train Loss=2.6372, Val Loss=2.2779
BERT Test CPC Loss: 2.2792

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=348.0389, Val Loss=2.9354
Epoch [2/5]: Train Loss=21.8491, Val Loss=2.6658
Epoch [3/5]: Train Loss=14.5116, Val Loss=2.6435
Epoch [4/5]: Train Loss=11.1622, Val Loss=2.6607
Epoch [5/5]: Train Loss=9.1859, Val Loss=2.6803
GPT2 Test CPC Loss: 2.6654
[Model: LSTM]
Epoch [1/5]: Train Loss=1.8232, Val Loss=0.9696
Epoch [2/5]: Train Loss=0.4846, Val Loss=0.2564
Epoch [3/5]: Train Loss=0.0703, Val Loss=0.0770
Epoch [4/5]: Train Loss=0.0130, Val Loss=0.0352
Epoch [5/5]: Train Loss=0.0045, Val Loss=0.0220
LSTM Test CPC Loss: 0.0451
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.2770, Val Loss=16.2883
Epoch [2/5]: Train Loss=9.2435, Val Loss=8.7784
Epoch [3/5]: Train Loss=4.7613, Val Loss=5.2959
Epoch [4/5]: Train Loss=2.7056, Val Loss=3.5556
Epoch [5/5]: Train Loss=1.6753, Val Loss=2.6388
Reservoir Test CPC Loss: 3.3550
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.5591, Val Loss=2.6937
Epoch [2/5]: Train Loss=4.8760, Val Loss=2.6932
Epoch [3/5]: Train Loss=3.9850, Val Loss=2.6935
Epoch [4/5]: Train Loss=3.3958, Val Loss=2.6929
Epoch [5/5]: Train Loss=3.0494, Val Loss=2.6933
BERT Test CPC Loss: 2.6942

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=544.1248, Val Loss=6.5794
Epoch [2/5]: Train Loss=25.3155, Val Loss=4.5583
Epoch [3/5]: Train Loss=17.7275, Val Loss=4.1910
Epoch [4/5]: Train Loss=14.5340, Val Loss=4.0646
Epoch [5/5]: Train Loss=12.2519, Val Loss=3.4001
GPT2 Test CPC Loss: 3.2933
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1314, Val Loss=1.4742
Epoch [2/5]: Train Loss=0.7988, Val Loss=0.5051
Epoch [3/5]: Train Loss=0.1483, Val Loss=0.1103
Epoch [4/5]: Train Loss=0.0175, Val Loss=0.0367
Epoch [5/5]: Train Loss=0.0053, Val Loss=0.0253
LSTM Test CPC Loss: 0.0543
[Model: Reservoir]
Epoch [1/5]: Train Loss=26.0008, Val Loss=16.8292
Epoch [2/5]: Train Loss=9.7053, Val Loss=7.8942
Epoch [3/5]: Train Loss=4.7349, Val Loss=4.3480
Epoch [4/5]: Train Loss=2.6232, Val Loss=2.7125
Epoch [5/5]: Train Loss=1.6105, Val Loss=1.9546
Reservoir Test CPC Loss: 2.5833
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0127, Val Loss=2.9849
Epoch [2/5]: Train Loss=4.8135, Val Loss=2.9885
Epoch [3/5]: Train Loss=3.9582, Val Loss=2.9908
Epoch [4/5]: Train Loss=3.4280, Val Loss=2.9909
Epoch [5/5]: Train Loss=3.1928, Val Loss=2.9911
BERT Test CPC Loss: 2.9912

--- Fish 13: Run 7 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=427.6563, Val Loss=20.2473
Epoch [2/5]: Train Loss=38.9155, Val Loss=3.5374
Epoch [3/5]: Train Loss=23.1857, Val Loss=1.7255
Epoch [4/5]: Train Loss=16.3377, Val Loss=1.4502
Epoch [5/5]: Train Loss=12.4269, Val Loss=1.3941
GPT2 Test CPC Loss: 1.3886
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6908, Val Loss=0.0565
Epoch [2/5]: Train Loss=0.0096, Val Loss=0.0090
Epoch [3/5]: Train Loss=0.0014, Val Loss=0.0029
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0019
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0015
LSTM Test CPC Loss: 0.0015
[Model: Reservoir]
Epoch [1/5]: Train Loss=8.8564, Val Loss=3.0599
Epoch [2/5]: Train Loss=2.2999, Val Loss=1.4545
Epoch [3/5]: Train Loss=1.2076, Val Loss=1.0135
Epoch [4/5]: Train Loss=0.6957, Val Loss=0.7435
Epoch [5/5]: Train Loss=0.4333, Val Loss=0.6407
Reservoir Test CPC Loss: 0.8851
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1994, Val Loss=1.6476
Epoch [2/5]: Train Loss=4.8679, Val Loss=1.8179
Epoch [3/5]: Train Loss=3.8121, Val Loss=1.8282
Epoch [4/5]: Train Loss=3.0858, Val Loss=1.7271
Epoch [5/5]: Train Loss=2.5466, Val Loss=1.5539
BERT Test CPC Loss: 1.5358

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=668.2326, Val Loss=41.0030
Epoch [2/5]: Train Loss=35.6364, Val Loss=36.3341
Epoch [3/5]: Train Loss=25.5909, Val Loss=28.7258
Epoch [4/5]: Train Loss=20.3190, Val Loss=22.9627
Epoch [5/5]: Train Loss=16.8902, Val Loss=21.1154
GPT2 Test CPC Loss: 17.7759
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3137, Val Loss=0.7029
Epoch [2/5]: Train Loss=0.1835, Val Loss=0.0918
Epoch [3/5]: Train Loss=0.0178, Val Loss=0.0521
Epoch [4/5]: Train Loss=0.0054, Val Loss=0.0248
Epoch [5/5]: Train Loss=0.0018, Val Loss=0.0164
LSTM Test CPC Loss: 0.0225
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.2562, Val Loss=10.1678
Epoch [2/5]: Train Loss=7.2332, Val Loss=5.5210
Epoch [3/5]: Train Loss=3.9655, Val Loss=3.4968
Epoch [4/5]: Train Loss=2.4126, Val Loss=2.3635
Epoch [5/5]: Train Loss=1.5715, Val Loss=1.7274
Reservoir Test CPC Loss: 2.6206
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0433, Val Loss=2.2738
Epoch [2/5]: Train Loss=4.8149, Val Loss=2.2722
Epoch [3/5]: Train Loss=3.8679, Val Loss=2.2741
Epoch [4/5]: Train Loss=3.1828, Val Loss=2.2735
Epoch [5/5]: Train Loss=2.7402, Val Loss=2.2726
BERT Test CPC Loss: 2.2742

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=453.8898, Val Loss=7.6944
Epoch [2/5]: Train Loss=32.4162, Val Loss=4.1638
Epoch [3/5]: Train Loss=17.9164, Val Loss=3.0106
Epoch [4/5]: Train Loss=12.6787, Val Loss=2.7054
Epoch [5/5]: Train Loss=10.0295, Val Loss=2.6533
GPT2 Test CPC Loss: 2.6236
[Model: LSTM]
Epoch [1/5]: Train Loss=1.6702, Val Loss=0.8684
Epoch [2/5]: Train Loss=0.3862, Val Loss=0.2563
Epoch [3/5]: Train Loss=0.0453, Val Loss=0.0811
Epoch [4/5]: Train Loss=0.0076, Val Loss=0.0403
Epoch [5/5]: Train Loss=0.0030, Val Loss=0.0247
LSTM Test CPC Loss: 0.0480
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.9650, Val Loss=16.3717
Epoch [2/5]: Train Loss=9.1708, Val Loss=8.1522
Epoch [3/5]: Train Loss=4.6464, Val Loss=4.7741
Epoch [4/5]: Train Loss=2.6516, Val Loss=3.0966
Epoch [5/5]: Train Loss=1.6700, Val Loss=2.3187
Reservoir Test CPC Loss: 3.1398
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9923, Val Loss=2.7005
Epoch [2/5]: Train Loss=4.6561, Val Loss=2.7008
Epoch [3/5]: Train Loss=3.8031, Val Loss=2.7010
Epoch [4/5]: Train Loss=3.2584, Val Loss=2.7017
Epoch [5/5]: Train Loss=2.9686, Val Loss=2.7021
BERT Test CPC Loss: 2.7025

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=531.7745, Val Loss=3.1531
Epoch [2/5]: Train Loss=24.0571, Val Loss=2.8888
Epoch [3/5]: Train Loss=17.4888, Val Loss=2.8928
Epoch [4/5]: Train Loss=14.1333, Val Loss=2.8971
Epoch [5/5]: Train Loss=12.0001, Val Loss=2.9162
GPT2 Test CPC Loss: 2.8959
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7912, Val Loss=1.2144
Epoch [2/5]: Train Loss=0.6193, Val Loss=0.4051
Epoch [3/5]: Train Loss=0.1116, Val Loss=0.0673
Epoch [4/5]: Train Loss=0.0145, Val Loss=0.0282
Epoch [5/5]: Train Loss=0.0044, Val Loss=0.0198
LSTM Test CPC Loss: 0.0333
[Model: Reservoir]
Epoch [1/5]: Train Loss=25.7347, Val Loss=17.4975
Epoch [2/5]: Train Loss=10.2178, Val Loss=8.7844
Epoch [3/5]: Train Loss=5.1385, Val Loss=5.1258
Epoch [4/5]: Train Loss=2.8792, Val Loss=3.4055
Epoch [5/5]: Train Loss=1.7782, Val Loss=2.4665
Reservoir Test CPC Loss: 3.4168
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1249, Val Loss=2.9858
Epoch [2/5]: Train Loss=4.8213, Val Loss=2.9861
Epoch [3/5]: Train Loss=4.0220, Val Loss=2.9878
Epoch [4/5]: Train Loss=3.5245, Val Loss=2.9883
Epoch [5/5]: Train Loss=3.2575, Val Loss=2.9893
BERT Test CPC Loss: 2.9895

--- Fish 13: Run 8 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=349.2991, Val Loss=1.7673
Epoch [2/5]: Train Loss=21.7006, Val Loss=1.6450
Epoch [3/5]: Train Loss=15.3869, Val Loss=1.7613
Epoch [4/5]: Train Loss=11.8700, Val Loss=1.7906
Epoch [5/5]: Train Loss=9.8037, Val Loss=1.8277
GPT2 Test CPC Loss: 1.7961
[Model: LSTM]
Epoch [1/5]: Train Loss=0.7447, Val Loss=0.0685
Epoch [2/5]: Train Loss=0.0133, Val Loss=0.0057
Epoch [3/5]: Train Loss=0.0009, Val Loss=0.0031
Epoch [4/5]: Train Loss=0.0005, Val Loss=0.0022
Epoch [5/5]: Train Loss=0.0003, Val Loss=0.0017
LSTM Test CPC Loss: 0.0025
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.4442, Val Loss=3.3390
Epoch [2/5]: Train Loss=2.3450, Val Loss=1.4574
Epoch [3/5]: Train Loss=1.1107, Val Loss=0.8566
Epoch [4/5]: Train Loss=0.6237, Val Loss=0.5898
Epoch [5/5]: Train Loss=0.3675, Val Loss=0.4865
Reservoir Test CPC Loss: 1.3339
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2281, Val Loss=1.5849
Epoch [2/5]: Train Loss=4.8289, Val Loss=1.7200
Epoch [3/5]: Train Loss=3.8391, Val Loss=1.7884
Epoch [4/5]: Train Loss=3.1404, Val Loss=1.6972
Epoch [5/5]: Train Loss=2.5720, Val Loss=1.5751
BERT Test CPC Loss: 1.5555

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=404.6876, Val Loss=9.1267
Epoch [2/5]: Train Loss=25.2075, Val Loss=3.8758
Epoch [3/5]: Train Loss=17.8189, Val Loss=2.9344
Epoch [4/5]: Train Loss=14.4746, Val Loss=2.8397
Epoch [5/5]: Train Loss=11.9194, Val Loss=2.7067
GPT2 Test CPC Loss: 2.6932
[Model: LSTM]
Epoch [1/5]: Train Loss=1.1830, Val Loss=0.5150
Epoch [2/5]: Train Loss=0.1460, Val Loss=0.0789
Epoch [3/5]: Train Loss=0.0152, Val Loss=0.0319
Epoch [4/5]: Train Loss=0.0043, Val Loss=0.0170
Epoch [5/5]: Train Loss=0.0019, Val Loss=0.0135
LSTM Test CPC Loss: 0.0262
[Model: Reservoir]
Epoch [1/5]: Train Loss=18.3467, Val Loss=10.6646
Epoch [2/5]: Train Loss=7.2350, Val Loss=5.6874
Epoch [3/5]: Train Loss=3.9570, Val Loss=3.5554
Epoch [4/5]: Train Loss=2.3574, Val Loss=2.3947
Epoch [5/5]: Train Loss=1.4968, Val Loss=1.8031
Reservoir Test CPC Loss: 2.7871
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.2447, Val Loss=2.2762
Epoch [2/5]: Train Loss=4.7927, Val Loss=2.2732
Epoch [3/5]: Train Loss=3.8392, Val Loss=2.2715
Epoch [4/5]: Train Loss=3.1723, Val Loss=2.2719
Epoch [5/5]: Train Loss=2.7234, Val Loss=2.2709
BERT Test CPC Loss: 2.2726

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=326.1095, Val Loss=6.2824
Epoch [2/5]: Train Loss=20.3099, Val Loss=4.4570
Epoch [3/5]: Train Loss=14.6005, Val Loss=3.3672
Epoch [4/5]: Train Loss=11.6011, Val Loss=3.0066
Epoch [5/5]: Train Loss=9.5737, Val Loss=2.9855
GPT2 Test CPC Loss: 2.9428
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7537, Val Loss=1.0639
Epoch [2/5]: Train Loss=0.4562, Val Loss=0.2436
Epoch [3/5]: Train Loss=0.0643, Val Loss=0.0655
Epoch [4/5]: Train Loss=0.0096, Val Loss=0.0296
Epoch [5/5]: Train Loss=0.0034, Val Loss=0.0215
LSTM Test CPC Loss: 0.0384
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.8979, Val Loss=18.2325
Epoch [2/5]: Train Loss=9.5755, Val Loss=10.0620
Epoch [3/5]: Train Loss=5.1440, Val Loss=6.3486
Epoch [4/5]: Train Loss=3.0197, Val Loss=4.2330
Epoch [5/5]: Train Loss=1.9173, Val Loss=3.0618
Reservoir Test CPC Loss: 3.8192
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9713, Val Loss=2.6947
Epoch [2/5]: Train Loss=4.7340, Val Loss=2.6960
Epoch [3/5]: Train Loss=3.8685, Val Loss=2.6957
Epoch [4/5]: Train Loss=3.3083, Val Loss=2.6952
Epoch [5/5]: Train Loss=2.9757, Val Loss=2.6963
BERT Test CPC Loss: 2.6971

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=353.0058, Val Loss=2.9803
Epoch [2/5]: Train Loss=21.4048, Val Loss=2.8947
Epoch [3/5]: Train Loss=15.2789, Val Loss=2.9117
Epoch [4/5]: Train Loss=12.3098, Val Loss=2.9591
Epoch [5/5]: Train Loss=10.4783, Val Loss=2.9309
GPT2 Test CPC Loss: 2.9102
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0642, Val Loss=1.3969
Epoch [2/5]: Train Loss=0.7174, Val Loss=0.4203
Epoch [3/5]: Train Loss=0.0983, Val Loss=0.0831
Epoch [4/5]: Train Loss=0.0121, Val Loss=0.0543
Epoch [5/5]: Train Loss=0.0040, Val Loss=0.0334
LSTM Test CPC Loss: 0.0473
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.7206, Val Loss=17.1364
Epoch [2/5]: Train Loss=9.5529, Val Loss=9.2514
Epoch [3/5]: Train Loss=4.9536, Val Loss=5.6404
Epoch [4/5]: Train Loss=2.8441, Val Loss=3.8487
Epoch [5/5]: Train Loss=1.7825, Val Loss=2.7938
Reservoir Test CPC Loss: 3.4706
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3924, Val Loss=2.9850
Epoch [2/5]: Train Loss=4.7971, Val Loss=2.9862
Epoch [3/5]: Train Loss=4.0055, Val Loss=2.9877
Epoch [4/5]: Train Loss=3.5402, Val Loss=2.9877
Epoch [5/5]: Train Loss=3.2854, Val Loss=2.9884
BERT Test CPC Loss: 2.9888

--- Fish 13: Run 9 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=440.2579, Val Loss=2.3511
Epoch [2/5]: Train Loss=33.3042, Val Loss=1.6132
Epoch [3/5]: Train Loss=20.5142, Val Loss=1.4715
Epoch [4/5]: Train Loss=14.6665, Val Loss=1.4546
Epoch [5/5]: Train Loss=11.5729, Val Loss=1.4690
GPT2 Test CPC Loss: 1.4550
[Model: LSTM]
Epoch [1/5]: Train Loss=0.5963, Val Loss=0.0277
Epoch [2/5]: Train Loss=0.0064, Val Loss=0.0023
Epoch [3/5]: Train Loss=0.0006, Val Loss=0.0018
Epoch [4/5]: Train Loss=0.0003, Val Loss=0.0015
Epoch [5/5]: Train Loss=0.0002, Val Loss=0.0012
LSTM Test CPC Loss: 0.0013
[Model: Reservoir]
Epoch [1/5]: Train Loss=7.9184, Val Loss=3.1292
Epoch [2/5]: Train Loss=2.4319, Val Loss=1.7944
Epoch [3/5]: Train Loss=1.3224, Val Loss=1.2004
Epoch [4/5]: Train Loss=0.7884, Val Loss=0.9148
Epoch [5/5]: Train Loss=0.4892, Val Loss=0.7667
Reservoir Test CPC Loss: 1.2091
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1455, Val Loss=1.6443
Epoch [2/5]: Train Loss=4.7508, Val Loss=1.8827
Epoch [3/5]: Train Loss=3.7451, Val Loss=1.8966
Epoch [4/5]: Train Loss=3.0535, Val Loss=1.6876
Epoch [5/5]: Train Loss=2.4802, Val Loss=1.5474
BERT Test CPC Loss: 1.5289

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=393.5757, Val Loss=31.4266
Epoch [2/5]: Train Loss=25.6359, Val Loss=18.8960
Epoch [3/5]: Train Loss=18.1941, Val Loss=18.3240
Epoch [4/5]: Train Loss=14.0992, Val Loss=14.5191
Epoch [5/5]: Train Loss=11.5883, Val Loss=10.8899
GPT2 Test CPC Loss: 9.0898
[Model: LSTM]
Epoch [1/5]: Train Loss=1.2275, Val Loss=0.5974
Epoch [2/5]: Train Loss=0.1443, Val Loss=0.0750
Epoch [3/5]: Train Loss=0.0128, Val Loss=0.0330
Epoch [4/5]: Train Loss=0.0030, Val Loss=0.0210
Epoch [5/5]: Train Loss=0.0016, Val Loss=0.0181
LSTM Test CPC Loss: 0.0207
[Model: Reservoir]
Epoch [1/5]: Train Loss=16.4017, Val Loss=9.5983
Epoch [2/5]: Train Loss=6.5714, Val Loss=5.1970
Epoch [3/5]: Train Loss=3.7514, Val Loss=3.3038
Epoch [4/5]: Train Loss=2.3270, Val Loss=2.2916
Epoch [5/5]: Train Loss=1.5188, Val Loss=1.7467
Reservoir Test CPC Loss: 3.0113
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.1884, Val Loss=2.2713
Epoch [2/5]: Train Loss=4.8077, Val Loss=2.2748
Epoch [3/5]: Train Loss=3.8827, Val Loss=2.2758
Epoch [4/5]: Train Loss=3.1988, Val Loss=2.2767
Epoch [5/5]: Train Loss=2.7602, Val Loss=2.2764
BERT Test CPC Loss: 2.2776

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=422.1421, Val Loss=5.0552
Epoch [2/5]: Train Loss=32.5398, Val Loss=2.8589
Epoch [3/5]: Train Loss=17.2473, Val Loss=2.7029
Epoch [4/5]: Train Loss=11.1488, Val Loss=2.6587
Epoch [5/5]: Train Loss=8.4067, Val Loss=2.6428
GPT2 Test CPC Loss: 2.6386
[Model: LSTM]
Epoch [1/5]: Train Loss=1.9231, Val Loss=1.2234
Epoch [2/5]: Train Loss=0.6591, Val Loss=0.4061
Epoch [3/5]: Train Loss=0.1255, Val Loss=0.0933
Epoch [4/5]: Train Loss=0.0184, Val Loss=0.0458
Epoch [5/5]: Train Loss=0.0048, Val Loss=0.0304
LSTM Test CPC Loss: 0.0514
[Model: Reservoir]
Epoch [1/5]: Train Loss=21.5117, Val Loss=15.2628
Epoch [2/5]: Train Loss=8.5210, Val Loss=7.9373
Epoch [3/5]: Train Loss=4.3521, Val Loss=4.7241
Epoch [4/5]: Train Loss=2.4706, Val Loss=3.2400
Epoch [5/5]: Train Loss=1.5388, Val Loss=2.4075
Reservoir Test CPC Loss: 2.8216
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9767, Val Loss=2.6969
Epoch [2/5]: Train Loss=4.7677, Val Loss=2.6968
Epoch [3/5]: Train Loss=3.9023, Val Loss=2.6979
Epoch [4/5]: Train Loss=3.3185, Val Loss=2.6975
Epoch [5/5]: Train Loss=2.9973, Val Loss=2.6980
BERT Test CPC Loss: 2.6987

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=465.5620, Val Loss=12.2416
Epoch [2/5]: Train Loss=25.2027, Val Loss=6.6167
Epoch [3/5]: Train Loss=17.6798, Val Loss=5.0091
Epoch [4/5]: Train Loss=14.0165, Val Loss=3.6837
Epoch [5/5]: Train Loss=11.7737, Val Loss=3.3088
GPT2 Test CPC Loss: 3.2138
[Model: LSTM]
Epoch [1/5]: Train Loss=2.0428, Val Loss=1.3905
Epoch [2/5]: Train Loss=0.7407, Val Loss=0.5114
Epoch [3/5]: Train Loss=0.1768, Val Loss=0.1283
Epoch [4/5]: Train Loss=0.0284, Val Loss=0.0459
Epoch [5/5]: Train Loss=0.0079, Val Loss=0.0255
LSTM Test CPC Loss: 0.0450
[Model: Reservoir]
Epoch [1/5]: Train Loss=23.0064, Val Loss=16.4279
Epoch [2/5]: Train Loss=9.2162, Val Loss=8.7070
Epoch [3/5]: Train Loss=4.7034, Val Loss=5.1890
Epoch [4/5]: Train Loss=2.6910, Val Loss=3.4810
Epoch [5/5]: Train Loss=1.6778, Val Loss=2.5106
Reservoir Test CPC Loss: 2.9728
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.5100, Val Loss=2.9853
Epoch [2/5]: Train Loss=4.8542, Val Loss=2.9874
Epoch [3/5]: Train Loss=4.0411, Val Loss=2.9881
Epoch [4/5]: Train Loss=3.5195, Val Loss=2.9891
Epoch [5/5]: Train Loss=3.2372, Val Loss=2.9896
BERT Test CPC Loss: 2.9900

--- Fish 13: Run 10 of 10 ---

Sequence Length = 5
[Model: GPT2]
Epoch [1/5]: Train Loss=359.3150, Val Loss=1.5747
Epoch [2/5]: Train Loss=23.7345, Val Loss=1.4585
Epoch [3/5]: Train Loss=15.2729, Val Loss=1.4148
Epoch [4/5]: Train Loss=11.4448, Val Loss=1.4011
Epoch [5/5]: Train Loss=9.0252, Val Loss=1.4029
GPT2 Test CPC Loss: 1.3995
[Model: LSTM]
Epoch [1/5]: Train Loss=0.6026, Val Loss=0.0495
Epoch [2/5]: Train Loss=0.0060, Val Loss=0.0080
Epoch [3/5]: Train Loss=0.0012, Val Loss=0.0051
Epoch [4/5]: Train Loss=0.0006, Val Loss=0.0038
Epoch [5/5]: Train Loss=0.0004, Val Loss=0.0027
LSTM Test CPC Loss: 0.0039
[Model: Reservoir]
Epoch [1/5]: Train Loss=9.6227, Val Loss=4.3951
Epoch [2/5]: Train Loss=2.5173, Val Loss=2.3073
Epoch [3/5]: Train Loss=1.2157, Val Loss=1.4270
Epoch [4/5]: Train Loss=0.6737, Val Loss=1.0733
Epoch [5/5]: Train Loss=0.3922, Val Loss=0.9507
Reservoir Test CPC Loss: 1.3467
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0369, Val Loss=1.5577
Epoch [2/5]: Train Loss=4.8977, Val Loss=1.6314
Epoch [3/5]: Train Loss=3.8739, Val Loss=1.6801
Epoch [4/5]: Train Loss=3.1025, Val Loss=1.6887
Epoch [5/5]: Train Loss=2.4907, Val Loss=1.5460
BERT Test CPC Loss: 1.5303

Sequence Length = 10
[Model: GPT2]
Epoch [1/5]: Train Loss=438.8964, Val Loss=5.2413
Epoch [2/5]: Train Loss=27.3473, Val Loss=3.3873
Epoch [3/5]: Train Loss=19.9008, Val Loss=3.3107
Epoch [4/5]: Train Loss=15.4085, Val Loss=3.0558
Epoch [5/5]: Train Loss=12.5164, Val Loss=2.9674
GPT2 Test CPC Loss: 2.9911
[Model: LSTM]
Epoch [1/5]: Train Loss=1.3407, Val Loss=0.5331
Epoch [2/5]: Train Loss=0.1991, Val Loss=0.1065
Epoch [3/5]: Train Loss=0.0184, Val Loss=0.0320
Epoch [4/5]: Train Loss=0.0040, Val Loss=0.0196
Epoch [5/5]: Train Loss=0.0021, Val Loss=0.0168
LSTM Test CPC Loss: 0.0181
[Model: Reservoir]
Epoch [1/5]: Train Loss=20.8867, Val Loss=14.6025
Epoch [2/5]: Train Loss=8.0536, Val Loss=7.9497
Epoch [3/5]: Train Loss=4.2986, Val Loss=4.9215
Epoch [4/5]: Train Loss=2.5606, Val Loss=3.4648
Epoch [5/5]: Train Loss=1.6285, Val Loss=2.5903
Reservoir Test CPC Loss: 2.9300
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.3482, Val Loss=2.2822
Epoch [2/5]: Train Loss=4.7574, Val Loss=2.2792
Epoch [3/5]: Train Loss=3.8274, Val Loss=2.2730
Epoch [4/5]: Train Loss=3.1390, Val Loss=2.2713
Epoch [5/5]: Train Loss=2.7077, Val Loss=2.2704
BERT Test CPC Loss: 2.2720

Sequence Length = 15
[Model: GPT2]
Epoch [1/5]: Train Loss=348.2549, Val Loss=4.0372
Epoch [2/5]: Train Loss=19.3620, Val Loss=2.7955
Epoch [3/5]: Train Loss=14.0272, Val Loss=2.7915
Epoch [4/5]: Train Loss=11.0162, Val Loss=2.7314
Epoch [5/5]: Train Loss=9.4542, Val Loss=2.7320
GPT2 Test CPC Loss: 2.7090
[Model: LSTM]
Epoch [1/5]: Train Loss=1.7967, Val Loss=0.9658
Epoch [2/5]: Train Loss=0.4103, Val Loss=0.1854
Epoch [3/5]: Train Loss=0.0438, Val Loss=0.0547
Epoch [4/5]: Train Loss=0.0089, Val Loss=0.0358
Epoch [5/5]: Train Loss=0.0039, Val Loss=0.0221
LSTM Test CPC Loss: 0.0391
[Model: Reservoir]
Epoch [1/5]: Train Loss=22.7871, Val Loss=15.6088
Epoch [2/5]: Train Loss=9.1322, Val Loss=8.7799
Epoch [3/5]: Train Loss=4.7443, Val Loss=5.4161
Epoch [4/5]: Train Loss=2.7219, Val Loss=3.7513
Epoch [5/5]: Train Loss=1.6956, Val Loss=2.7737
Reservoir Test CPC Loss: 3.7187
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=10.9552, Val Loss=2.6922
Epoch [2/5]: Train Loss=4.6931, Val Loss=2.6940
Epoch [3/5]: Train Loss=3.8211, Val Loss=2.6954
Epoch [4/5]: Train Loss=3.2473, Val Loss=2.6964
Epoch [5/5]: Train Loss=2.9472, Val Loss=2.6975
BERT Test CPC Loss: 2.6983

Sequence Length = 20
[Model: GPT2]
Epoch [1/5]: Train Loss=485.6202, Val Loss=6.9973
Epoch [2/5]: Train Loss=23.6762, Val Loss=4.5203
Epoch [3/5]: Train Loss=16.5993, Val Loss=3.5178
Epoch [4/5]: Train Loss=13.4317, Val Loss=3.2097
Epoch [5/5]: Train Loss=11.2179, Val Loss=3.1587
GPT2 Test CPC Loss: 3.1077
[Model: LSTM]
Epoch [1/5]: Train Loss=2.1475, Val Loss=1.5058
Epoch [2/5]: Train Loss=0.9181, Val Loss=0.7562
Epoch [3/5]: Train Loss=0.2547, Val Loss=0.1750
Epoch [4/5]: Train Loss=0.0336, Val Loss=0.0512
Epoch [5/5]: Train Loss=0.0077, Val Loss=0.0317
LSTM Test CPC Loss: 0.0541
[Model: Reservoir]
Epoch [1/5]: Train Loss=27.2860, Val Loss=20.6831
Epoch [2/5]: Train Loss=10.9073, Val Loss=10.8085
Epoch [3/5]: Train Loss=5.5287, Val Loss=6.3312
Epoch [4/5]: Train Loss=3.1020, Val Loss=4.0883
Epoch [5/5]: Train Loss=1.9116, Val Loss=2.9099
Reservoir Test CPC Loss: 3.7142
[Model: DeepSeek]
DeepSeek model failed to load/train. Recording NaN for CPC loss and predictions.
[Model: BERT]
Epoch [1/5]: Train Loss=11.0416, Val Loss=2.9874
Epoch [2/5]: Train Loss=4.7654, Val Loss=2.9871
Epoch [3/5]: Train Loss=3.9683, Val Loss=2.9876
Epoch [4/5]: Train Loss=3.4852, Val Loss=2.9880
Epoch [5/5]: Train Loss=3.2360, Val Loss=2.9889
BERT Test CPC Loss: 2.9890

=== CPC Loss Results for seq_len=5 ===
GPT2: mean=1.8871, std=1.1341
LSTM: mean=0.0029, std=0.0039
Reservoir: mean=1.3356, std=0.3319
DeepSeek: mean=nan, std=nan
BERT: mean=1.5163, std=0.0242

Pairwise Significance Tests (Mann–Whitney U):
  GPT2 vs LSTM: p-value = 7.0661e-18
  GPT2 vs Reservoir: p-value = 1.0751e-06
  GPT2 vs DeepSeek: p-value = nan
  GPT2 vs BERT: p-value = 8.8217e-01
  LSTM vs Reservoir: p-value = 7.0661e-18
  LSTM vs DeepSeek: p-value = nan
  LSTM vs BERT: p-value = 7.0661e-18
  Reservoir vs DeepSeek: p-value = nan
  Reservoir vs BERT: p-value = 3.7950e-06
  DeepSeek vs BERT: p-value = nan

=== CPC Loss Results for seq_len=10 ===
GPT2: mean=3.1609, std=2.6929
LSTM: mean=0.0348, std=0.0218
Reservoir: mean=2.8231, std=0.3459
DeepSeek: mean=nan, std=nan
BERT: mean=2.2843, std=0.0064

Pairwise Significance Tests (Mann–Whitney U):
  GPT2 vs LSTM: p-value = 7.0661e-18
  GPT2 vs Reservoir: p-value = 5.2794e-06
  GPT2 vs DeepSeek: p-value = nan
  GPT2 vs BERT: p-value = 4.5960e-02
  LSTM vs Reservoir: p-value = 7.0661e-18
  LSTM vs DeepSeek: p-value = nan
  LSTM vs BERT: p-value = 7.0661e-18
  Reservoir vs DeepSeek: p-value = nan
  Reservoir vs BERT: p-value = 3.4621e-14
  DeepSeek vs BERT: p-value = nan

=== CPC Loss Results for seq_len=15 ===
GPT2: mean=2.9241, std=1.0131
LSTM: mean=0.0507, std=0.0240
Reservoir: mean=3.0194, std=0.3469
DeepSeek: mean=nan, std=nan
BERT: mean=2.7009, std=0.0029

Pairwise Significance Tests (Mann–Whitney U):
  GPT2 vs LSTM: p-value = 7.0661e-18
  GPT2 vs Reservoir: p-value = 2.7300e-05
  GPT2 vs DeepSeek: p-value = nan
  GPT2 vs BERT: p-value = 1.3556e-01
  LSTM vs Reservoir: p-value = 7.0661e-18
  LSTM vs DeepSeek: p-value = nan
  LSTM vs BERT: p-value = 7.0661e-18
  Reservoir vs DeepSeek: p-value = nan
  Reservoir vs BERT: p-value = 3.5557e-08
  DeepSeek vs BERT: p-value = nan

=== CPC Loss Results for seq_len=20 ===
GPT2: mean=3.1351, std=0.5019
LSTM: mean=0.0688, std=0.0300
Reservoir: mean=3.0764, std=0.4361
DeepSeek: mean=nan, std=nan
BERT: mean=2.9917, std=0.0015

Pairwise Significance Tests (Mann–Whitney U):
  GPT2 vs LSTM: p-value = 7.0661e-18
  GPT2 vs Reservoir: p-value = 7.7481e-01
  GPT2 vs DeepSeek: p-value = nan
  GPT2 vs BERT: p-value = 4.2159e-04
  LSTM vs Reservoir: p-value = 7.0661e-18
  LSTM vs DeepSeek: p-value = nan
  LSTM vs BERT: p-value = 7.0661e-18
  Reservoir vs DeepSeek: p-value = nan
  Reservoir vs BERT: p-value = 6.6156e-01
  DeepSeek vs BERT: p-value = nan
Bar plot saved to /hpc/group/naumannlab/jjm132/nlp4neuro/results/experiment_5/cpc_loss_comparison_seq5.png
Bar plot saved to /hpc/group/naumannlab/jjm132/nlp4neuro/results/experiment_5/cpc_loss_comparison_seq10.png
Bar plot saved to /hpc/group/naumannlab/jjm132/nlp4neuro/results/experiment_5/cpc_loss_comparison_seq15.png
Bar plot saved to /hpc/group/naumannlab/jjm132/nlp4neuro/results/experiment_5/cpc_loss_comparison_seq20.png
Self-supervised CPC experiment complete!
