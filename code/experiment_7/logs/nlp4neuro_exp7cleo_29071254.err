Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:00<02:00, 120.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:10<00:00, 90.63s/it] Loading checkpoint shards: 100%|██████████| 2/2 [03:10<00:00, 95.18s/it]
/hpc/group/naumannlab/jjm132/miniconda3/envs/jjmenv_nlp/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
Traceback (most recent call last):
  File "/hpc/home/jjm132/jjm132/nlp4neuro/code/experiment_7/experiment_7_cleo.py", line 236, in <module>
    run_pipeline(Xtr, Xva, Xte,
  File "/hpc/home/jjm132/jjm132/nlp4neuro/code/experiment_7/experiment_7_cleo.py", line 200, in run_pipeline
    wi = (xb.grad * xb).abs().cpu().numpy()   # (B,L,N)
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
