{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f835d2e-70c7-44a3-b94c-4ff265ddcee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\OneDrive\\Documents\\GitHub\\nlp4neuro\\code\\plot_results\\..\\..\\..\\external_data\\data\\gt_data\n",
      "C:\\Users\\jacob\\OneDrive\\Documents\\GitHub\\nlp4neuro\\code\\plot_results\\..\\..\\..\\external_data\\data\n",
      "Computing centroids for Linear...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     83\u001b[39m base_tok  = tokens(keep0)\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# instantiate embedding and PCA basis\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m E     = \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeep0\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m[emb_name].eval()\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     88\u001b[39m     Zb = E(base_tok).squeeze(\u001b[32m1\u001b[39m).cpu().numpy()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mget_embeddings\u001b[39m\u001b[34m(D)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embeddings\u001b[39m(D):\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     50\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLinear\u001b[39m\u001b[33m\"\u001b[39m:   Vanilla(D,hidden_size),\n\u001b[32m     51\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPosEnc\u001b[39m\u001b[33m\"\u001b[39m:   PosEnc(D,hidden_size),\n\u001b[32m     52\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRelPos\u001b[39m\u001b[33m\"\u001b[39m:   RelPos(D,hidden_size),\n\u001b[32m     53\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSpectral\u001b[39m\u001b[33m\"\u001b[39m: Spectral(D,hidden_size),\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSparseAE\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mSparseAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mSparseAE.__init__\u001b[39m\u001b[34m(self, D, H)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,D,H): \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(); \u001b[38;5;28mself\u001b[39m.enc=\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\jupyterlab-desktop\\envs\\fconn-holo\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:112\u001b[39m, in \u001b[36mLinear.__init__\u001b[39m\u001b[34m(self, in_features, out_features, bias, device, dtype)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mself\u001b[39m.register_parameter(\u001b[33m\"\u001b[39m\u001b[33mbias\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\jupyterlab-desktop\\envs\\fconn-holo\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:118\u001b[39m, in \u001b[36mLinear.reset_parameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[43minit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    120\u001b[39m         fan_in, _ = init._calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m.weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\jupyterlab-desktop\\envs\\fconn-holo\\Lib\\site-packages\\torch\\nn\\init.py:518\u001b[39m, in \u001b[36mkaiming_uniform_\u001b[39m\u001b[34m(tensor, a, mode, nonlinearity, generator)\u001b[39m\n\u001b[32m    516\u001b[39m bound = math.sqrt(\u001b[32m3.0\u001b[39m) * std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os, math, csv, numpy as np, torch, torch.nn as nn\n",
    "import matplotlib.pyplot as plt, matplotlib.gridspec as gridspec\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), os.path.pardir, os.path.pardir, os.path.pardir, \"external_data\", \"data\", \"gt_data\")\n",
    "print(DATA_DIR)\n",
    "SAL_DIR = os.path.join(os.getcwd(), os.path.pardir, os.path.pardir, os.path.pardir, \"external_data\", \"data\")\n",
    "print(SAL_DIR)\n",
    "# ── CONFIGURATION ─────────────────────────────────────────────────────────\n",
    "fish_num    = 9\n",
    "hidden_size = 4096\n",
    "n_drop      = 50\n",
    "np.random.seed(0)\n",
    "\n",
    "OUT_DIR  = DATA_DIR\n",
    "coord_dir = os.path.join(OUT_DIR, 'pc_coords')\n",
    "os.makedirs(coord_dir, exist_ok=True)\n",
    "\n",
    "# ── EMBEDDING CLASSES (as before) ───────────────────────────────────────────\n",
    "class Vanilla(nn.Module):\n",
    "    def __init__(self,D,H): super().__init__(); self.l=nn.Linear(D,H)\n",
    "    def forward(self,x): return self.l(x)\n",
    "class PosEnc(nn.Module):\n",
    "    def __init__(self,D,H,L=1024):\n",
    "        super().__init__(); self.l=nn.Linear(D,H)\n",
    "        pe=torch.zeros(L,H); pos=torch.arange(L).unsqueeze(1)\n",
    "        div=torch.exp(torch.arange(0,H,2)*(-math.log(10000.0)/H))\n",
    "        pe[:,0::2],pe[:,1::2]=torch.sin(pos*div),torch.cos(pos*div)\n",
    "        self.register_buffer('pe',pe.unsqueeze(0),persistent=False)\n",
    "    def forward(self,x): z=self.l(x); return z+self.pe[:,:z.size(1)]\n",
    "class RelPos(nn.Module):\n",
    "    def __init__(self,D,H,R=32):\n",
    "        super().__init__(); self.l=nn.Linear(D,H); self.R=R; self.rel=nn.Embedding(2*R+1,H)\n",
    "    def forward(self,x):\n",
    "        z=self.l(x); B,L,_=z.shape\n",
    "        offs=torch.arange(L,device=z.device)-torch.arange(L,device=z.device)[0]\n",
    "        offs=torch.clamp(offs,-self.R,self.R)+self.R\n",
    "        return z+self.rel(offs).unsqueeze(0).expand(B,L,-1)\n",
    "class Spectral(nn.Module):\n",
    "    def __init__(self,D,H): super().__init__(); self.l=nn.Linear(D,H); nn.init.orthogonal_(self.l.weight)\n",
    "    def forward(self,x): return torch.tanh(self.l(x))\n",
    "class SparseAE(nn.Module):\n",
    "    def __init__(self,D,H): super().__init__(); self.enc=nn.Linear(D,H)\n",
    "    def forward(self,x): B,L,_=x.shape; return torch.relu(self.enc(x.view(B*L,-1))).view(B,L,-1)\n",
    "\n",
    "def get_embeddings(D):\n",
    "    return {\n",
    "        \"Linear\":   Vanilla(D,hidden_size),\n",
    "        \"PosEnc\":   PosEnc(D,hidden_size),\n",
    "        \"RelPos\":   RelPos(D,hidden_size),\n",
    "        \"Spectral\": Spectral(D,hidden_size),\n",
    "        \"SparseAE\": SparseAE(D,hidden_size)\n",
    "    }\n",
    "order = [\"Linear\",\"PosEnc\",\"RelPos\",\"Spectral\",\"SparseAE\"]\n",
    "\n",
    "# ── LOAD DATA & SALIENCY ─────────────────────────────────────────────────────\n",
    "F   = np.load(f\"{DATA_DIR}/fish{fish_num}_neural_data_matched.npy\")\n",
    "SAL = np.load(f\"{SAL_DIR}/fish{fish_num}_importance.npy\")\n",
    "all_idx       = np.arange(F.shape[0])\n",
    "sal_sorted    = SAL.argsort()[::-1]\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "# helper to tensor tokens\n",
    "def tokens(idx):\n",
    "    return torch.tensor(F[idx].T, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# ── COMPUTE OR LOAD CENTROIDS ───────────────────────────────────────────────\n",
    "centroids = {}  # embedding -> array[51×3]\n",
    "\n",
    "for emb_name in order:\n",
    "    coord_file = os.path.join(coord_dir, f\"{emb_name}_centroids.npy\")\n",
    "    if os.path.exists(coord_file):\n",
    "        centroids[emb_name] = np.load(coord_file)\n",
    "        print(f\"Loaded centroids for {emb_name} from disk.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Computing centroids for {emb_name}...\")\n",
    "    # determine baseline subset to fit PCA basis (e.g. random removal k=0)\n",
    "    rand_drop = rng.choice(all_idx, n_drop, replace=False)\n",
    "    keep0     = np.setdiff1d(all_idx, rand_drop)\n",
    "    base_tok  = tokens(keep0)\n",
    "\n",
    "    # instantiate embedding and PCA basis\n",
    "    E     = get_embeddings(keep0.size)[emb_name].eval()\n",
    "    with torch.no_grad():\n",
    "        Zb = E(base_tok).squeeze(1).cpu().numpy()\n",
    "    svd   = TruncatedSVD(n_components=3, random_state=0).fit(Zb)\n",
    "\n",
    "    # compute centroids for k=0..n_drop\n",
    "    C = np.zeros((n_drop+1, 3), dtype=float)\n",
    "    for k in range(n_drop+1):\n",
    "        drop_sal   = sal_sorted[:k]\n",
    "        candidates = np.setdiff1d(all_idx, drop_sal)\n",
    "        drop_rand  = rng.choice(candidates, n_drop-k, replace=False)\n",
    "        keep_idx   = np.setdiff1d(all_idx, np.concatenate([drop_sal, drop_rand]))\n",
    "        with torch.no_grad():\n",
    "            Zk = svd.transform(E(tokens(keep_idx)).squeeze(1).cpu().numpy())\n",
    "        C[k] = Zk.mean(0)\n",
    "    centroids[emb_name] = C\n",
    "    np.save(coord_file, C)\n",
    "    print(f\"Saved centroids for {emb_name} to {coord_file}.\")\n",
    "\n",
    "# ── PLOT CENTROIDS WITH BLUE→RED GRADIENT ───────────────────────────────────\n",
    "fig = plt.figure(figsize=(30,6), dpi=300)\n",
    "gs  = gridspec.GridSpec(1, len(order)+1, width_ratios=[1]*len(order)+[0.05], wspace=0.6)\n",
    "axes = [fig.add_subplot(gs[i], projection='3d') for i in range(len(order))]\n",
    "cax  = fig.add_axes([0.92,0.35,0.02,0.3])\n",
    "\n",
    "for idx, emb_name in enumerate(order):\n",
    "    C = centroids[emb_name]\n",
    "    ax = axes[idx]\n",
    "    for k in range(n_drop+1):\n",
    "        color = plt.cm.bwr(k/n_drop)\n",
    "        ax.scatter(*C[k], c=[color], s=60, edgecolor='k', linewidth=0.2)\n",
    "    ax.set_title(emb_name)\n",
    "    ax.set_xlabel('PC1'); ax.set_ylabel('PC2'); ax.set_zlabel('PC3')\n",
    "    pts = C\n",
    "    mr = np.ptp(pts, axis=0).max()/2.0\n",
    "    mid= pts.min(0) + np.ptp(pts,axis=0)/2.0\n",
    "    for d,m in zip('xyz', mid): getattr(ax, f'set_{d}lim')(m-mr, m+mr)\n",
    "\n",
    "import matplotlib as mpl\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=n_drop)\n",
    "cbar = mpl.colorbar.ColorbarBase(cax, cmap='bwr', norm=norm)\n",
    "cbar.set_label('# salient neurons removed')\n",
    "\n",
    "fig.subplots_adjust(left=0.04, right=0.9, top=0.95, bottom=0.05)\n",
    "out = os.path.join(OUT_DIR, 'pca_centroids_gradient.pdf')\n",
    "fig.savefig(out, transparent=True)\n",
    "print('Saved', out)\n",
    "\n",
    "# ── CSV OUTPUT ──────────────────────────────────────────────────────────────\n",
    "csv_file = os.path.join(coord_dir, 'centroid_coords.csv')\n",
    "with open(csv_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['embedding','k_salient','pc1','pc2','pc3'])\n",
    "    for emb_name in order:\n",
    "        for k,coords in enumerate(centroids[emb_name]):\n",
    "            writer.writerow([emb_name, k, *coords])\n",
    "print('Centroid coordinates saved to', csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e76f8-4b52-4988-8844-073a4624c576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
